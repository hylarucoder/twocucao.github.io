<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>从一个小问题来说 Python 的作用域 | 海拉鲁编程客</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/49455a07b6dd33600cdf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/49455a07b6dd33600cdf.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-20d43e08bea62467b090.js" defer=""></script><script src="/_next/static/chunks/framework-0441fae7fd130f37dee1.js" defer=""></script><script src="/_next/static/chunks/main-4777350f2a9ff73ea2b0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3050679c6e5142ffcaf5.js" defer=""></script><script src="/_next/static/chunks/ea88be26-9bcf6ead520f4ac26973.js" defer=""></script><script src="/_next/static/chunks/421-f2f33a86b546237f0325.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-173fe2de48c90365db9d.js" defer=""></script><script src="/_next/static/oDi_oBCBuu3qj6v7hDnrL/_buildManifest.js" defer=""></script><script src="/_next/static/oDi_oBCBuu3qj6v7hDnrL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="v-page"><nav class="shadow"><div class="flex flex-col container mx-auto h-12 px-40 md:flex-row md:items-center md:justify-between"><div class="flex justify-between items-center"><div><a class="text-gray-800 text-xl md:text-xl leading-5" href="/">海拉鲁编程客</a></div><div><button type="button" class="block text-gray-800 hover:text-gray-600 focus:text-gray-600 focus:outline-none md:hidden"><svg viewBox="0 0 24 24" class="h-6 w-6 fill-current"><path d="M4 5h16a1 1 0 0 1 0 2H4a1 1 0 1 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2z"></path></svg></button></div></div><div class="md:flex flex-col md:flex-row md:-mx-4 hidden"><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/">首页</a><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/archive">归档</a><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/about">关于我</a><button style="cursor:pointer;overflow:hidden;width:50px;height:23.5px;appearance:none;-moz-appearance:none;-webkit-appearance:none;border:none;background-color:transparent;padding:0" aria-hidden="true"><div style="display:flex;align-items:center;justify-content:center;margin-top:-28.749999999999996px;margin-left:-16px;width:82.5px;height:82.5px"><div></div></div></button></div></div></nav><div class="v-article"><div class="v-article-main" style="margin:auto;width:786px"><div><blockquote>
<p>备注，这种动态设置 module 里的方法不推荐</p>
</blockquote>
<h2 id="前言"><a class="v-toc-item" href="#前言">#</a> 前言</h2>
<p>整理工具字符类的时候，想借助正则表达式来实现一部分的文字判断抽取等操作。</p>
<p>比如实现：</p>
<ul>
<li>判断文字是否为 UUID</li>
<li>判断文字是否包含 UUID</li>
<li>抽取文字是中第一个 UUID</li>
<li>抽取文字是中所有 UUID</li>
</ul>
<!-- more -->
<h3 id="一个暴力的实现方法"><a class="v-toc-item" href="#一个暴力的实现方法">#</a> 一个暴力的实现方法</h3>
<p>如果正则表达式比较少，就只一个 UUID，我们就不需要思考什么，我们分别编写四个函数：</p>
<ul>
<li>is_uuid(_str)</li>
<li>has_uuid(_str)</li>
<li>extract_first_uuid(_str)</li>
<li>extract_all_uuid(_str)</li>
</ul>
<blockquote>
<p>没错，过早优化是万恶之源</p>
</blockquote>
<p>但很显然，手动方法显得很弱智，当我需要编写判断 QQ 号的时候，我又必须编写四个函数：</p>
<ul>
<li>is_qq_num(_str)</li>
<li>has_qq_num(_str)</li>
<li>extract_first_qq_num(_str)</li>
<li>extract_all_qq_num(_str)</li>
</ul>
<p>然而：</p>
<ul>
<li>如果，我还需要判断手机号、日期、时间等等，这手动复制粘贴的过程就比较痛苦了。</li>
<li>如果，我去要添加一个方法，给 QQ 号码，uuid 等打码 那就必须要给所有的 uuid, 手机，邮箱都添加一个 dama_xxx(_str) 方法</li>
</ul>
<p>有没有好一点的解决方法呢？</p>
<!-- more -->
<h3 id="两个方法"><a class="v-toc-item" href="#两个方法">#</a> 两个方法</h3>
<p>第一种，比如把函数修改为：</p>
<ul>
<li>is(_str,QQ_NUM_PATTEN)</li>
<li>has(_str,QQ_NUM_PATTEN)</li>
<li>extract_first(_str,QQ_NUM_PATTEN)</li>
<li>extract_all(_str,QQ_NUM_PATTEN)</li>
</ul>
<p>第二种，Python 中动态添加工具方法，我个人比较喜欢这种：</p>
<pre><code class="language-python"># 一个优雅的错误实现方式
<span class="token keyword">for</span> regex<span class="token punctuation">,</span> regex_pattern <span class="token keyword">in</span> <span class="token constant">REGEXES</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">has_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">has_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">is_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">match_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">extract_first_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">find_first_matched_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">extract_all_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">find_all_matched_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'has_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> has_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'is_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> is_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'extract_first_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> extract_first_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'extract_all_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> extract_all_regex_func<span class="token punctuation">)</span>
</code></pre>
<p>于是我添加了测试方法：</p>
<blockquote>
<p>一个不对稍微有些复杂的逻辑的程序进行测试的程序员不是一个称职的老司机。</p>
</blockquote>
<pre><code class="language-python">@pytest<span class="token punctuation">.</span>mark<span class="token punctuation">.</span><span class="token function">parametrize</span><span class="token punctuation">(</span><span class="token string">'test_input,expected'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"321323199509234453"</span><span class="token punctuation">,</span> False<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"000528-332222"</span><span class="token punctuation">,</span> False<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">,</span> True<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
def <span class="token function">test_is_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> expected<span class="token punctuation">)</span><span class="token operator">:</span>
    assert <span class="token function">is_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">)</span> <span class="token operator">==</span> expected

@pytest<span class="token punctuation">.</span>mark<span class="token punctuation">.</span><span class="token function">parametrize</span><span class="token punctuation">(</span><span class="token string">'test_input,expected'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"321323199509234453"</span><span class="token punctuation">,</span> False<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"000528-332222"</span><span class="token punctuation">,</span> False<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">,</span> True<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
def <span class="token function">test_has_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> expected<span class="token punctuation">)</span><span class="token operator">:</span>
    assert <span class="token function">has_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">)</span> <span class="token operator">==</span> expected

@pytest<span class="token punctuation">.</span>mark<span class="token punctuation">.</span><span class="token function">parametrize</span><span class="token punctuation">(</span><span class="token string">'test_input,expected'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"321323199509234453"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"000528-332222"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">,</span> <span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
def <span class="token function">test_extract_first_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> expected<span class="token punctuation">)</span><span class="token operator">:</span>
    assert <span class="token function">extract_first_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">)</span> <span class="token operator">==</span> expected

@pytest<span class="token punctuation">.</span>mark<span class="token punctuation">.</span><span class="token function">parametrize</span><span class="token punctuation">(</span><span class="token string">'test_input,expected'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"321323199509234453"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"000528-332222"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span>
            <span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">,</span>
            <span class="token punctuation">[</span><span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span> <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span>
             <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span> <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span>
            <span class="token string">"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   aslakdj 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4"</span><span class="token punctuation">,</span>
            <span class="token punctuation">[</span><span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span> <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span>
             <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">,</span> <span class="token string">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
def <span class="token function">test_extract_all_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> expected<span class="token punctuation">)</span><span class="token operator">:</span>
    assert <span class="token function">extract_all_uuid</span><span class="token punctuation">(</span>test_input<span class="token punctuation">)</span> <span class="token operator">==</span> expected
</code></pre>
<p>测试未通过：</p>
<p>怎么查看代码本身都没有什么逻辑问题，那么问题出在哪里？</p>
<p>对程序植入一些 print 代码来 Debug 一下：</p>
<pre><code class="language-python"><span class="token keyword">for</span> regex<span class="token punctuation">,</span> regex_pattern <span class="token keyword">in</span> <span class="token constant">REGEXES</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">has_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token operator">=</span>regex_pattern<span class="token punctuation">)</span><span class="token operator">:</span>
        # 当函数被调用之后，打印 regex_pattern 查看对应的字符串
        <span class="token function">print</span><span class="token punctuation">(</span>regex_pattern<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token function">has_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">is_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token operator">=</span>regex_pattern<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">match_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">extract_first_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token operator">=</span>regex_pattern<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">find_first_matched_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    def <span class="token function">extract_all_regex_func</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token operator">=</span>regex_pattern<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">find_all_matched_pattern</span><span class="token punctuation">(</span>_str<span class="token punctuation">,</span> regex_pattern<span class="token punctuation">)</span>

    # 查看是否为同一个函数
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token function">id</span><span class="token punctuation">(</span>has_regex_func<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'has_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> has_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'is_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> is_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'extract_first_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> extract_first_regex_func<span class="token punctuation">)</span>
    <span class="token function">setattr</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>modules<span class="token punctuation">[</span>__name__<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'extract_all_{regex_suffix}'</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>regex_suffix<span class="token operator">=</span>regex<span class="token punctuation">)</span><span class="token punctuation">,</span> extract_all_regex_func<span class="token punctuation">)</span>
</code></pre>
<p>于是发现问题，所有打印出来的 regex_pattern 都是一致的。也就是，不管是 has_uuid 还是 has_qq_num 还是其他，最后 regex_pattern 都是我在字典中实现的</p>
</div></div><div><ul class="v-article-toc">
<li>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a>
<ul>
<li><a href="#%E4%B8%80%E4%B8%AA%E6%9A%B4%E5%8A%9B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95">一个暴力的实现方法</a></li>
<li><a href="#%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95">两个方法</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"tags":["Python"],"path":"20170114_PythonScope.md","title":"从一个小问题来说 Python 的作用域","slug":"从一个小问题来说 Python 的作用域","date":"2017-01-14","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\u003cblockquote\u003e\n\u003cp\u003e备注，这种动态设置 module 里的方法不推荐\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"前言\"\u003e\u003ca class=\"v-toc-item\" href=\"#前言\"\u003e#\u003c/a\u003e 前言\u003c/h2\u003e\n\u003cp\u003e整理工具字符类的时候，想借助正则表达式来实现一部分的文字判断抽取等操作。\u003c/p\u003e\n\u003cp\u003e比如实现：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e判断文字是否为 UUID\u003c/li\u003e\n\u003cli\u003e判断文字是否包含 UUID\u003c/li\u003e\n\u003cli\u003e抽取文字是中第一个 UUID\u003c/li\u003e\n\u003cli\u003e抽取文字是中所有 UUID\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- more --\u003e\n\u003ch3 id=\"一个暴力的实现方法\"\u003e\u003ca class=\"v-toc-item\" href=\"#一个暴力的实现方法\"\u003e#\u003c/a\u003e 一个暴力的实现方法\u003c/h3\u003e\n\u003cp\u003e如果正则表达式比较少，就只一个 UUID，我们就不需要思考什么，我们分别编写四个函数：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eis_uuid(_str)\u003c/li\u003e\n\u003cli\u003ehas_uuid(_str)\u003c/li\u003e\n\u003cli\u003eextract_first_uuid(_str)\u003c/li\u003e\n\u003cli\u003eextract_all_uuid(_str)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e没错，过早优化是万恶之源\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e但很显然，手动方法显得很弱智，当我需要编写判断 QQ 号的时候，我又必须编写四个函数：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eis_qq_num(_str)\u003c/li\u003e\n\u003cli\u003ehas_qq_num(_str)\u003c/li\u003e\n\u003cli\u003eextract_first_qq_num(_str)\u003c/li\u003e\n\u003cli\u003eextract_all_qq_num(_str)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e然而：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e如果，我还需要判断手机号、日期、时间等等，这手动复制粘贴的过程就比较痛苦了。\u003c/li\u003e\n\u003cli\u003e如果，我去要添加一个方法，给 QQ 号码，uuid 等打码 那就必须要给所有的 uuid, 手机，邮箱都添加一个 dama_xxx(_str) 方法\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e有没有好一点的解决方法呢？\u003c/p\u003e\n\u003c!-- more --\u003e\n\u003ch3 id=\"两个方法\"\u003e\u003ca class=\"v-toc-item\" href=\"#两个方法\"\u003e#\u003c/a\u003e 两个方法\u003c/h3\u003e\n\u003cp\u003e第一种，比如把函数修改为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eis(_str,QQ_NUM_PATTEN)\u003c/li\u003e\n\u003cli\u003ehas(_str,QQ_NUM_PATTEN)\u003c/li\u003e\n\u003cli\u003eextract_first(_str,QQ_NUM_PATTEN)\u003c/li\u003e\n\u003cli\u003eextract_all(_str,QQ_NUM_PATTEN)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e第二种，Python 中动态添加工具方法，我个人比较喜欢这种：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 一个优雅的错误实现方式\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e regex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token constant\"\u003eREGEXES\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eitems\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    def \u003cspan class=\"token function\"\u003ehas_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003ehas_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eis_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003ematch_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eextract_first_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003efind_first_matched_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eextract_all_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003efind_all_matched_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'has_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e has_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'is_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e is_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'extract_first_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e extract_first_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'extract_all_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e extract_all_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e于是我添加了测试方法：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个不对稍微有些复杂的逻辑的程序进行测试的程序员不是一个称职的老司机。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@pytest\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emark\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eparametrize\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e'test_input,expected'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"321323199509234453\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e False\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"000528-332222\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e False\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e True\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndef \u003cspan class=\"token function\"\u003etest_is_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e expected\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    assert \u003cspan class=\"token function\"\u003eis_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token operator\"\u003e==\u003c/span\u003e expected\n\n@pytest\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emark\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eparametrize\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e'test_input,expected'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"321323199509234453\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e False\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"000528-332222\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e False\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e True\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndef \u003cspan class=\"token function\"\u003etest_has_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e expected\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    assert \u003cspan class=\"token function\"\u003ehas_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token operator\"\u003e==\u003c/span\u003e expected\n\n@pytest\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emark\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eparametrize\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e'test_input,expected'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"321323199509234453\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e None\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"000528-332222\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e None\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndef \u003cspan class=\"token function\"\u003etest_extract_first_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e expected\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    assert \u003cspan class=\"token function\"\u003eextract_first_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token operator\"\u003e==\u003c/span\u003e expected\n\n@pytest\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emark\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eparametrize\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e'test_input,expected'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"321323199509234453\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e None\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"000528-332222\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e None\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n             \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"token string\"\u003e\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   aslakdj 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n             \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndef \u003cspan class=\"token function\"\u003etest_extract_all_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e expected\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    assert \u003cspan class=\"token function\"\u003eextract_all_uuid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etest_input\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token operator\"\u003e==\u003c/span\u003e expected\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e测试未通过：\u003c/p\u003e\n\u003cp\u003e怎么查看代码本身都没有什么逻辑问题，那么问题出在哪里？\u003c/p\u003e\n\u003cp\u003e对程序植入一些 print 代码来 Debug 一下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e regex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token constant\"\u003eREGEXES\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eitems\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n    def \u003cspan class=\"token function\"\u003ehas_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        # 当函数被调用之后，打印 regex_pattern 查看对应的字符串\n        \u003cspan class=\"token function\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003ehas_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eis_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003ematch_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eextract_first_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003efind_first_matched_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    def \u003cspan class=\"token function\"\u003eextract_all_regex_func\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"token function\"\u003efind_all_matched_pattern\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e_str\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e regex_pattern\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    # 查看是否为同一个函数\n    \u003cspan class=\"token function\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token function\"\u003eid\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehas_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'has_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e has_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'is_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e is_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'extract_first_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e extract_first_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token function\"\u003esetattr\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003esys\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodules\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e__name__\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'extract_all_{regex_suffix}'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token function\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eregex_suffix\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eregex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e extract_all_regex_func\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e于是发现问题，所有打印出来的 regex_pattern 都是一致的。也就是，不管是 has_uuid 还是 has_qq_num 还是其他，最后 regex_pattern 都是我在字典中实现的\u003c/p\u003e\n","toc":"\u003cul class=\"v-article-toc\"\u003e\n\u003cli\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E5%89%8D%E8%A8%80\"\u003e前言\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#%E4%B8%80%E4%B8%AA%E6%9A%B4%E5%8A%9B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95\"\u003e一个暴力的实现方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95\"\u003e两个方法\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"从一个小问题来说 Python 的作用域"},"buildId":"oDi_oBCBuu3qj6v7hDnrL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>