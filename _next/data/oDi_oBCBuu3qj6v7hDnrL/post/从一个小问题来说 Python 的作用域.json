{"pageProps":{"post":{"tags":["Python"],"path":"20170114_PythonScope.md","title":"从一个小问题来说 Python 的作用域","slug":"从一个小问题来说 Python 的作用域","date":"2017-01-14","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"<blockquote>\n<p>备注，这种动态设置 module 里的方法不推荐</p>\n</blockquote>\n<h2 id=\"前言\"><a class=\"v-toc-item\" href=\"#前言\">#</a> 前言</h2>\n<p>整理工具字符类的时候，想借助正则表达式来实现一部分的文字判断抽取等操作。</p>\n<p>比如实现：</p>\n<ul>\n<li>判断文字是否为 UUID</li>\n<li>判断文字是否包含 UUID</li>\n<li>抽取文字是中第一个 UUID</li>\n<li>抽取文字是中所有 UUID</li>\n</ul>\n<!-- more -->\n<h3 id=\"一个暴力的实现方法\"><a class=\"v-toc-item\" href=\"#一个暴力的实现方法\">#</a> 一个暴力的实现方法</h3>\n<p>如果正则表达式比较少，就只一个 UUID，我们就不需要思考什么，我们分别编写四个函数：</p>\n<ul>\n<li>is_uuid(_str)</li>\n<li>has_uuid(_str)</li>\n<li>extract_first_uuid(_str)</li>\n<li>extract_all_uuid(_str)</li>\n</ul>\n<blockquote>\n<p>没错，过早优化是万恶之源</p>\n</blockquote>\n<p>但很显然，手动方法显得很弱智，当我需要编写判断 QQ 号的时候，我又必须编写四个函数：</p>\n<ul>\n<li>is_qq_num(_str)</li>\n<li>has_qq_num(_str)</li>\n<li>extract_first_qq_num(_str)</li>\n<li>extract_all_qq_num(_str)</li>\n</ul>\n<p>然而：</p>\n<ul>\n<li>如果，我还需要判断手机号、日期、时间等等，这手动复制粘贴的过程就比较痛苦了。</li>\n<li>如果，我去要添加一个方法，给 QQ 号码，uuid 等打码 那就必须要给所有的 uuid, 手机，邮箱都添加一个 dama_xxx(_str) 方法</li>\n</ul>\n<p>有没有好一点的解决方法呢？</p>\n<!-- more -->\n<h3 id=\"两个方法\"><a class=\"v-toc-item\" href=\"#两个方法\">#</a> 两个方法</h3>\n<p>第一种，比如把函数修改为：</p>\n<ul>\n<li>is(_str,QQ_NUM_PATTEN)</li>\n<li>has(_str,QQ_NUM_PATTEN)</li>\n<li>extract_first(_str,QQ_NUM_PATTEN)</li>\n<li>extract_all(_str,QQ_NUM_PATTEN)</li>\n</ul>\n<p>第二种，Python 中动态添加工具方法，我个人比较喜欢这种：</p>\n<pre><code class=\"language-python\"># 一个优雅的错误实现方式\n<span class=\"token keyword\">for</span> regex<span class=\"token punctuation\">,</span> regex_pattern <span class=\"token keyword\">in</span> <span class=\"token constant\">REGEXES</span><span class=\"token punctuation\">.</span><span class=\"token function\">items</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    def <span class=\"token function\">has_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">has_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">is_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">match_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">extract_first_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">find_first_matched_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">extract_all_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">find_all_matched_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'has_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> has_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> is_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'extract_first_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> extract_first_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'extract_all_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> extract_all_regex_func<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>于是我添加了测试方法：</p>\n<blockquote>\n<p>一个不对稍微有些复杂的逻辑的程序进行测试的程序员不是一个称职的老司机。</p>\n</blockquote>\n<pre><code class=\"language-python\">@pytest<span class=\"token punctuation\">.</span>mark<span class=\"token punctuation\">.</span><span class=\"token function\">parametrize</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test_input,expected'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"321323199509234453\"</span><span class=\"token punctuation\">,</span> False<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"000528-332222\"</span><span class=\"token punctuation\">,</span> False<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">,</span> True<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndef <span class=\"token function\">test_is_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">,</span> expected<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    assert <span class=\"token function\">is_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> expected\n\n@pytest<span class=\"token punctuation\">.</span>mark<span class=\"token punctuation\">.</span><span class=\"token function\">parametrize</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test_input,expected'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"321323199509234453\"</span><span class=\"token punctuation\">,</span> False<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"000528-332222\"</span><span class=\"token punctuation\">,</span> False<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">,</span> True<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndef <span class=\"token function\">test_has_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">,</span> expected<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    assert <span class=\"token function\">has_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> expected\n\n@pytest<span class=\"token punctuation\">.</span>mark<span class=\"token punctuation\">.</span><span class=\"token function\">parametrize</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test_input,expected'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"321323199509234453\"</span><span class=\"token punctuation\">,</span> None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"000528-332222\"</span><span class=\"token punctuation\">,</span> None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndef <span class=\"token function\">test_extract_first_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">,</span> expected<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    assert <span class=\"token function\">extract_first_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> expected\n\n@pytest<span class=\"token punctuation\">.</span>mark<span class=\"token punctuation\">.</span><span class=\"token function\">parametrize</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test_input,expected'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"321323199509234453\"</span><span class=\"token punctuation\">,</span> None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"000528-332222\"</span><span class=\"token punctuation\">,</span> None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>\n            <span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span><span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span>\n             <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>\n            <span class=\"token string\">\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   aslakdj 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span><span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span>\n             <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndef <span class=\"token function\">test_extract_all_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">,</span> expected<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    assert <span class=\"token function\">extract_all_uuid</span><span class=\"token punctuation\">(</span>test_input<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> expected\n</code></pre>\n<p>测试未通过：</p>\n<p>怎么查看代码本身都没有什么逻辑问题，那么问题出在哪里？</p>\n<p>对程序植入一些 print 代码来 Debug 一下：</p>\n<pre><code class=\"language-python\"><span class=\"token keyword\">for</span> regex<span class=\"token punctuation\">,</span> regex_pattern <span class=\"token keyword\">in</span> <span class=\"token constant\">REGEXES</span><span class=\"token punctuation\">.</span><span class=\"token function\">items</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n    def <span class=\"token function\">has_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token operator\">=</span>regex_pattern<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        # 当函数被调用之后，打印 regex_pattern 查看对应的字符串\n        <span class=\"token function\">print</span><span class=\"token punctuation\">(</span>regex_pattern<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">has_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">is_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token operator\">=</span>regex_pattern<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">match_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">extract_first_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token operator\">=</span>regex_pattern<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">find_first_matched_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    def <span class=\"token function\">extract_all_regex_func</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token operator\">=</span>regex_pattern<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">find_all_matched_pattern</span><span class=\"token punctuation\">(</span>_str<span class=\"token punctuation\">,</span> regex_pattern<span class=\"token punctuation\">)</span>\n\n    # 查看是否为同一个函数\n    <span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token function\">id</span><span class=\"token punctuation\">(</span>has_regex_func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'has_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> has_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> is_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'extract_first_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> extract_first_regex_func<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">setattr</span><span class=\"token punctuation\">(</span>sys<span class=\"token punctuation\">.</span>modules<span class=\"token punctuation\">[</span>__name__<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'extract_all_{regex_suffix}'</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span>regex_suffix<span class=\"token operator\">=</span>regex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> extract_all_regex_func<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>于是发现问题，所有打印出来的 regex_pattern 都是一致的。也就是，不管是 has_uuid 还是 has_qq_num 还是其他，最后 regex_pattern 都是我在字典中实现的</p>\n","toc":"<ul class=\"v-article-toc\">\n<li>\n<ul>\n<li><a href=\"#%E5%89%8D%E8%A8%80\">前言</a>\n<ul>\n<li><a href=\"#%E4%B8%80%E4%B8%AA%E6%9A%B4%E5%8A%9B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95\">一个暴力的实现方法</a></li>\n<li><a href=\"#%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95\">两个方法</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n"}},"__N_SSG":true}