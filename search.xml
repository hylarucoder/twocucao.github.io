<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ElasticSearch CheatSheet]]></title>
    <url>%2F2018%2F02%2F13%2FElasticSearchCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 ElasticSearch 相关和命令。 不定期更新。 最早使用 ElasticSearch 是两年前了。最近准备用 Django 写一个全栈式的应用，借用强大的 ES 来做搜索。这是我在写程序之余写这篇文章的原因。 官网介绍 ElasticSearch 不仅仅是全文搜索，也可以结构化搜索（这里用结构化查询会更准确一些），分析，处理人类语言，地理位置，以及关系。 然而，我在项目使用过程中还是主要用到了全文搜索以及推荐。 不用其他的主要原因是因为 ES 尺有所短寸有所长： geo 处理方面 postgis 完全就是神一般的存在。为什么还要用 ES 呢？ 关系型数据库的核心不就是处理关系？复杂的关系肯定还是放在关系数据库里面。 highlighted search snippets, and search-as-you-type and did-you-mean suggestions. 我对 ElasticSearch 在后台组件里的作用在于搜索与推荐： 整站的搜索功能 全文搜索 推荐 依据某几个维度的数据进行排序 0x01 安装，配置，基本 shell 命令1. 安装123456789101112131415161718# 执行如下的命令curl &apos;http://localhost:9200/?pretty&apos;# 输出结果&#123; &quot;name&quot; : &quot;XOGvo8a&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;fAwp341bQzalzBxRFyD1YA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.2.1&quot;, &quot;build_hash&quot; : &quot;7299dc3&quot;, &quot;build_date&quot; : &quot;2018-02-07T19:34:26.990113Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.2.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 2. 配置3. 插件ES 的插件有很多，比这使用现在最新的版本是 6.2.1 版本。 PS: 两年前我用的还是 2.3.3 版本。新版本有很多插件配置起来已经有所不同了。比如说 head 现在已经被独立出来作为一个单纯的网页，chrome 商店可以直接下载。 0x02 ElasticSearch 配套工具建议使用 Head 插件来进行简单的查询与调试。 0x03 ElasticSearch 基础概念3.1 Elasticsearch CRUDE 以及基本操作ES 使用的是 RESTFUL API 接口 这也就意味着： PUT 创建记录 GET 获取记录 POST 更新记录 DELETE 删除记录 HEAD 是否存在 0x04 全文搜索的基本概念4.1 全文搜索遇到的挑战在最初开源搜索引擎技术还不是很成熟的时候，我们一般都会使用 RDBMS 进行简单搜索。 简单搜索，也就是我们常常使用的 like 查询（当然，有的数据库可以使用正则表达式） 这种方式是简单暴力的查询方式，优点是实现起来简单暴力。缺点是准确度很差。 举例： 假如站点里文章数量比较大，并且文章内容比较长，则进行一次全表查询，效率可想而知。当然，做好分库分表读写分离也是能用的。 如果我要对搜索到的词语进行高亮，则实现方式就只能是把查询到的文章放在应用层里面进行批量替换。 RDBMS 似乎完全不懂各种语言之间的区别。 『停止词 / 常用词』有的字我是不需要的，比如南京的狗，其实我想搜的是南京狗，这里的『的』就不是我需要的。 『同义词』有的字我需要的是他的同义词，比如日本黄狗，其实我想搜的是柴犬。 『附加符号』假如说我们搜索一个声调 [nǐ], 总不能让用户打出 [nǐ] 进行搜索吧？总归要转为 ni 才能方便搜索 『词根形式』对于一个单词，假如是动词可能有时态上的区分，如果是名词，可能有单复数的区分。假如我搜 mice, 其实同样的 mouse 也应该被搜索出来。但有事用这种方式也会矫枉过正，比如 organizations 的 原型其实并不是 organization 而是，organ. （当然，overstemming 和 understemming 也是两个不可忽视的问题） Number: fox, foxes Tense: pay, paid, paying Gender: waiter, waitress Person: hear, hears Case: I, me, my Aspect: ate, eaten Mood: so be it, were it so PS: 万幸的是，中文处理中木词根这个概念。我也就不深入这块了。 『拼写问题』 TODO: 补充案例 『分词 / 识别词』中文不像英文，词和词之间是完全没有空格的，也就是说，中文天然要比英文多一个关于分词的步骤。 4.2 全文搜索的字段是如何存到 ES 中的？首先，要有数据，然后才是搜索。 我们先要把数据存在 ES 中， 新建并定义 index,type,document,field 在定义 field 的时候指定 analyzer, 然后赋值大行文本，这个时候 analyzer 会对这个文本做什么呢？ STEP 1: 令牌化文本为独立的词 STEP 2: 词语转小写 STEP 3: 去除常见的停止词 STEP 4: 获取词的原型 其他的大同小异，那我们常用的 https://github.com/medcl/elasticsearch-analysis-ik 的话，则也是类似的步骤（下面步骤是我拍的，没看源码） 令牌化文本为独立的词语 - 分词 出去常见的停止词 匹配同义词 …. 停止词使用停止词是减少索引大小的一种方式，那么，哪些词语可以呗当做停止词呢？ 低频词语：低频词语具备高权重高频词语：高频词语具备低权重 当然，是否是高频词语依据个人经验主要依据两点来判断： 具体情况：比如在英文中，and/the 之类的会比较多，但是中文会比较少。同样的，中文里面其他语言的东西会少一些。正文八经的文章出现不正经的词汇的概率会低。在技术问里面，『数据库』属于高频词汇，但是在比如简书之类的，可能梦想 / 鸡汤 / 超级 / 震惊会多一些。掘金的『前端』两个字绝壁是高频词。 抽样跑新词发现的程序。社区里多的是新词发现的脚本。通过机器发现，然后人工筛选，应该可以发现更多的高频和低频的词汇。 是不是用上停止词就好了呢？并不是。 比如 假如停止词里面包含了 not , 那么 happy 和 not happy 搜索出来的结果则一致。 假如停止词里面包含了或，那么，如果有个乐队名字叫做『或或』, 则搜索不出来。 假如停止词里面包含了 to / be / not / or , 则莎士比亚的名言 『To be, or not to be』 则搜索不出来。 4.2 全文搜索一般会有如下的流程，这个流程可以交给 analyzer 进行处理。 文本令牌化为独立的词。 小写 移除停止词 还原词源 而每一个 analyzer 还针对具体情况做优化。比如说，我们看上述流程的第一步，Tokenize 文本为独立的词。实际上，英文的文本分词特别容易，因为单词和单词之间存在空格，而中文则不然，中文的词和词之间无空格，总要分词。 3.3 全文搜索的 ES 解决方案 TODO: 全文搜索 RDBMS like 的效率问题。 全文搜索包含两个重要方面： 相关性：通过 TF/IDF , 距离 , 模糊相似度，以及其他算法 分析：将大片文字转为 distinct, normalized tokens Term-Based : term or fuzzy Full-Text : match or query_string TERM 查找-&gt;精确查找 加上 constant_score 和 filter 的话，就成了常亮？麻痹的，这两个又是啥 inverted index 内部过滤操作： 1. 3.4 进阶搜索所谓搜索，其实就是 4.1 Tips And Hacks0x06 Python SDK官方提供了两个 SDK 方便我们进行日常的开发： elasticsearch elasticsearch_dsl 前者偏底层一些，后者偏高层一些，高低层的有点类似于 psycopg2 和 sqlalchemy 之间的关系。 elasticsearch-analysis-ik 的配置0x07 踩坑集 序列问题 0xEE 参考链接 https://www.zhihu.com/question/19645541]]></content>
      <categories>
        <category>后台组件</category>
      </categories>
      <tags>
        <tag>CheatSheet</tag>
        <tag>ElasticSearch</tag>
        <tag>搜索排序</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker CheatSheet]]></title>
    <url>%2F2018%2F02%2F10%2FDockerCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Docker 相关和命令。 Docker 相关概念 Docker 配套工具 Django PostgreSQL RabbitMQ Redis ElasticSearch Sentry 集群 Docker 化 Docker 踩坑记录 不定期更新。 0x01 Docker 相关概念1.1 Docker 是什么？在认知 Docker 这种相对而言比较新概念的时候，只要从以往的经验中拿出一个词语来概括新词汇即可。 于是，我们便可以这么理解： Docker 是一种比虚拟机轻量的用来存放职责比较单一的应用的容器。 也就是三点： 比虚拟机轻量 用来存放职责单一的应用 容器 显然这是一种理解，而不是一种定义。 1.2 Docker 是用来做什么的？新技术本质是什么？工具也。每一个新的技术都是为了提升效率才被创造出来，那么，究竟 Docker 可以从哪些方面提升我们的效率呢？ 我们知道开发一个有些规模的网站的话，需要严格遵守如下的开发流程： 编码 测试 集成到系统中 部署 但如果人员比较多，则会出现问题，有的人喜欢用 MacOS, 有的人喜欢用 Ubuntu, 开发测试环境怎么统一呢？如果开发人员明明使用的是某个版本的 PostgreSQL, 用了最新的功能，但是测试和运维用的就是老版本的功能怎么办？ 部署环境也会有问题，比如，开发部突然想使用更高版本的软件，比如突然需要更多的 Django 应用来负担海量请求的怎么办？Hadoop 不够用怎么办？ 当然，思路很简单，开发的时候使用虚拟机，拷贝给大家一起用，部署的时候多创建一些机器，然后上 Ansible 远程操控。即可。 并不是不行，但是 Docker 由于更加轻量，操作粒度更加细腻，我可以销毁镜像，上传镜像，定制镜像，很轻松调整镜像包并且安装挂载文件。 0x02 Docker 初始配置123docker-machine create --driver=virtualbox defaultdocker-machine lseval &quot;$(docker-machine env default)&quot; 0x03 Django 技术栈 Docker 化为了理解这个过程，下面我将我 Docker 化 django 应用的流程按照一定步骤演示出来。我将我使用 Django 的部分经验搞出来，做成了一个 django-bpc ，即 django best practice。如果诸位有兴趣研究的话，拿来看看源码倒是倒是非常好。 123# 演示环境为 MAC, 在此之前，务必安装好 docker for mac 以及 virualbox# xxxxxx 为 阿里云分配的容器 registrydocker-machine create --engine-registry-mirror=https://xxxxxx.mirror.aliyuncs.com -d virtualbox default 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051├── AUTHORS.md├── HISTORY.md├── LICENSE├── MANIFEST.in├── Makefile├── README.md├── assets├── compose│ ├── django│ ├── elasticsearch│ ├── nginx│ ├── postgres│ ├── rabbitmq│ └── redis├── config│ ├── __init__.py│ ├── settings│ ├── urls.py│ └── wsgi.py├── dev.yml├── docker-compose.yml├── docs│ ├── Makefile│ ├── exts│ ├── make.bat│ ├── make_pdf.sh│ └── source├── manage.py├── pytest.ini├── requirements│ ├── base.txt│ ├── local.txt│ ├── production.txt│ └── test.txt├── scripts├── setup.cfg├── tests│ ├── __init__.py│ ├── conftest.py│ └── test_basics.py└── yadjangoblog ├── __init__.py ├── contrib ├── static ├── templates ├── yaaccounts ├── yaadmin ├── yaapi ├── yablog ├── yacommon └── yataskapp 3.1 开发时1. 运行所需组件在开发时候需要使用几个后台的组件 PostgreSQL 用于做数据存储 Redis 用于做缓存 和 Session 等等 RedditMQ 用于消息队列 ElasticSearch 用于做搜索与推荐 目录中的组件基本上都在这儿了。 1234567├── compose│ ├── django│ ├── elasticsearch│ ├── nginx│ ├── postgres│ ├── rabbitmq│ └── redis 进行初步的封装和添加脚本，不直接采用官网的配置需要是因为添加一些的定制版本。 2. Vue.JS 运行环境Vue.JS 使用 Vue-Cli 搭建的脚手架还是挺方便的，这个就无需 Docker 化了，需要注意的是，建议配置一下开发时候请求的 API 地址。 我本人用于请求本地地址的 8080 端口，并且 8080 端口映射到 Docker 容器里面的 Django App 3. Django App配置 Django, 我使用的是 ubuntu 16.04 基础镜像，然后安装必备的依赖。 接着指定 workdir 为当前目录 需要注意的是，Django App 里面需要等待 PostgreSQL 初始化完毕才能进行正常的运行接下来需要运行的命令，比如 runserver 之类的命令。 entrypoint 的左右即是放在命令执行之前，这样的话，重写掉 entrypoint 文件，就可以实现上面的功能了 1234567891011121314151617# 本段代码来自 cookiecutter Djangofunction postgres_ready()&#123;python &lt;&lt; ENDimport sysimport psycopg2try: conn = psycopg2.connect(dbname="$POSTGRES_USER", user="$POSTGRES_USER", password="$POSTGRES_PASSWORD", host="postgres")except psycopg2.OperationalError: sys.exit(-1)sys.exit(0)END&#125;until postgres_ready; do &gt;&amp;2 echo "Postgres is unavailable - sleeping" sleep 1done 最后封装一些命令到，比如启动 Celery 之类的。 4. Celery 运行环境5. 其他零散的重要配置3.2 具体开发我编写了一整套 makefile 的命令，我会先进入项目 YaDjangoBlog , 然后执行 make ; 执行 make 之后，显示了我编写的一些便于开发测试的命令如下： 1234567891011121314151617181920212223242526272829303132333435sep--sep-a ========== 开发时命令 ==============django-build-up build and compose upforce_djnago_build-up django / pg / esdjango-before-up e.g pg / es / redisdjango-runserver runserverdjango-celerybeat celerybeatdjango-celeryworker celeryworkerdjango-just-up build and updjango-manager Enter python manage.pydjango-console Enter Django Consoleshell Enter Shelldbshell Enter psql as yadjangowebsep--sep-b ========== 测试与代码质量 ==============lint check style with flake8test run tests quickly with the default Pythoncoverage check code coverage quickly with the default Pythonsep--sep-c ========== 文档生成相关 ==============docs generate Sphinx HTML documentation, including API docsservedocs compile the docs watching for changessep--sep-d ========== 程序发布相关 ==============release package and upload a releasedist builds source and wheel packageinstall install the package to the active Python&apos;s site-packagessep--sep-e ========== Docker 镜像相关 ==============build-postgres &gt; Postgresforce-build-postgres &gt; Postgresbuild-ubuntu &gt; base ubuntuforce_build-ubuntu &gt; base ubuntubuild-django &gt; base djangoforce_build-django &gt; base djangosep--sep-f ========== 文件清理相关 ==============clean remove all build, test, coverage and Python artifactsclean-build remove build artifactsclean-pyc remove Python file artifactsclean-test remove test and coverage artifacts 1. 构建镜像执行 build 命令即可。 2. 使用 Tmuxinator 批量运行命令现在，我有这么一个需求，就是在 iterm 中开启如下的终端： 第 1 个终端，运行的命令是 Vue.JS 的启动命令 npm run dev。 第 2 个终端，有两个分屏，其一用于构建 iconfont 字体文件的命令，其二用于 Gulp 动态编译 SCSS 文件的命令。 第 3 个终端，运行的命令是 Django 的 runserver 的命令。 第 4 个终端，有两个分屏，一个是 Django 容器的 bash 环境，另一个是 PostgreSQL 的 命令行环境。 第 5 个终端，有两个分屏，一者运行 Celery Beat，另一者则是运行 Celery Worker. 当然，目前没有添加 redis 和 RabbitMQ 的命令行环境 3. 使用 PyCharm 进行开发3.3 部署时Docker 部署需要解决的问题，是裸机部署的 Docker 化。 TODO: 目前 Docker 部署的脚本还在编写中，这部分的文字可能后期会调整 0. Django 生产环境和开发环境之间的区别生产环境和开发环境除了一些文字配置上的不同，还有一些不同，比如： 新增了 uwsgi / gunicorn 作为新的 web 容器 新增了 Ngnix 作为反向代理 Celery Worker 数量的变化 Supervisor 进程守护 首先说第一点带来的区别，我们使用 Django 内置的 runserver 的时候，其实这个命令可以用于做生产环境的 Web 服务器。 比如，只需如此 python manage.py runserver 0.0.0.0:8888 可以用，但不推荐用。没什么负载量。这时候就需要 gunicorn 了。你可以理解 Gunicorn 是进阶的 runserver, 可以参考：https://docs.djangoproject.com/en/2.0/howto/deployment/wsgi/gunicorn/ 同时，Gunicorn 可以进行颗粒度更细致的操作，但负载量不如 uwsgi, 毕竟前者 python 写的，后者是 C 写的。 一般 Gunicorn 也会配上 NGNIX, 简单来说，Nginx 至少可以解决下面的问题： 匹配域名 转发请求 设置请求头 转发本地的静态文件 (static / media） 映射部分请求到 gunicorn , 然后 gunicorn 开启一个线程到 Django 负载均衡 需要注意的是 gunicorn 这种关键性的进程，一定要用 Supervisor 进行守护，否则挂掉了就完蛋了， 1. 裸机部署 Django 程序2. Docker 部署0x04 Docker 踩坑记录4.1 PostgreSQL 的初始化当 Docker 化 PostgreSQL 的时候，必须要把一些初始化脚本放在 docker-entrypoint-initdb.d 中，才能初始化，笔者在进行测试的时候多次发现无法进行初始化，究其原因，经过查找，如果没有及时删除 Volume 的话，则无论怎么初始化，或者 Build, 每一次都会挂载原来的文件夹。 1ADD init_django_db.sh /docker-entrypoint-initdb.d/init_django_db.sh 4.2 清空所有 Image12345678# Delete all containersdocker rm $(docker ps -a -q)# Delete all imagesdocker rmi $(docker images -q)# Force deletedocker rmi $(docker images -q) -f# Delete Unused Volumedocker volume prune 0xEE 参考链接 https://github.com/wsargent/docker-cheat-sheet ChangeLog: 2017-01-20 初始化本文]]></content>
      <categories>
        <category>我的开源项目</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Docker</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy Cheatsheet]]></title>
    <url>%2F2018%2F02%2F03%2FNumpyCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Numpy 相关语句。 主要包含： Numpy 库0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Numpy 相关语句。 对于数据分析应用而言，最应该关注： 用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。 常用的数组算法，如排序、唯一化、集合运算等。 高效的描述统计和数据聚合 / 摘要运算。 用于异构数据集的合并 / 连接运算的数据对齐和关系型数据运算。 将条件逻辑表述为数组表达式（而不是带有 if-else-if 分支的循环） 数据的分组运算（聚合、转换、函数应用等）。 学习 Numpy 本质上是为了更好的使用 Pandas 0x01 ndarray1.1 数据类型1.2 创建 ndarray1.3 数组和标量之间的运算当我们把数组当做矢量的时候。 两个大小相同的矢量将运算到元素级 矢量和标量将作用与每一个元素 不同大小的矢量之间的运算叫做广播 1.4 索引和切片1.4.1 一般索引和一般切片对于一维数组的话，如果没有显式 copy 则会修改原来的值。 切片语法与 Python 相近 1.4.2 切片型索引12a[:2,1:]a[2,1:] 1.4.3 布尔型索引参考 pandas 语法 0xEE 参考链接 ChangeLog: 2017-06-03 初始化本文 2018-02-03 重修文字]]></content>
      <categories>
        <category>数据科学</category>
      </categories>
      <tags>
        <tag>Pandas</tag>
        <tag>效率</tag>
        <tag>Cheatsheet</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 tmux 与 tmuxinator 打造开发工作流]]></title>
    <url>%2F2018%2F01%2F28%2FTmuxWithTmuxinatorWorkflow%2F</url>
    <content type="text"><![CDATA[0x00. 前言本文就我最近开发的一个前后端的项目（名字叫做 yavueblog) 来简单介绍两个神器 一个是 tmux 一个是 tmuxinator 我在开发这个前后端的项目的时候要开启要通过不少的命令来启动服务： （前端开发）运行 npm run dev 进行开发前端页面 （前端开发）运行 npm run dev:theme , 当主题的 SCSS 发生变化的同时，编译 SCSS （前端开发）运行 npm run dev:iconfont, 当移入了新的 svg 图标的时候，自动构建出新的字体文件与 iconfont.css 。 （后端开发）运行 make dockerup 中开启 Django 应用。启动 Django 服务，PostgreSQL 数据库，Redis 等等， 我的需求如下： 一键启动这些脚本，前两个任务，放在第一个终端。 后面两个任务放在第二、三个终端里。 以前的做法都是新建三个终端选项卡，然后第一个终端分两屏，然后分别到各个终端 cd 或者 autojump 到对应的目录，然后手动运行命令。 加上运行 npm run dev:theme 的时候，我是通过 Python 的 watchdog 来实现对指定目录和指定类型文件的变化进行监听的，所以还要切换 PyEnv 自定义的 Python 的环境中。 这些命令反反复复输入还是挺麻烦的事情，为何不用工具来解决呢？ 0x01 tmux + tmuxinator先安装 123brew install tmuxbrew install rubygem install tmuxinator 什么是 tmux? 简单而言，就是一个终端复用软件。什么是 tmuxinator? 简单而言，就是为了简化 tmux 操作的软件。只需要编写 yaml 即快速开启一个比较适合你的终端窗口布局。 关于 tmux 的配置，推荐这个 repo https://github.com/gpakosz/.tmux 0x02 编写 Tmuxinator 配置文件输入 tmuxinator new yavueblog 修改文件如下 12345678910111213141516171819202122232425# ~/.tmuxinator/yavueblog.ymlname: yavueblogroot: ~/Codes/PublicRepos/YaBlogSystem/# Optional tmux socket# socket_name: foo# Runs before everything. Use it to start daemons etc.# pre: sudo /etc/rc.d/mysqld start# Runs in each window and pane before window/pane specific commands. Useful for setting up interpreter versions.pre_window: pyenv activate 3.5.2/envs/py3-dailywindows: - &quot;网站开发&quot;: layout: main-vertical # Synchronize all panes of this window, can be enabled before or after the pane commands run. # &apos;before&apos; represents legacy functionality and will be deprecated in a future release, in favour of &apos;after&apos; # synchronize: after panes: - &quot;cd ./YaVueBlog/ &amp;&amp; npm run dev&quot; - &quot;cd ./YaVueBlog/ &amp;&amp; npm run dev:theme&quot; - &quot;iconfont 构建&quot;: &quot;cd ./YaVueBlog/ &amp;&amp; npm run dev:iconfont&quot; - &quot;DockerizedDjango&quot;: &quot;cd ./YaDjangoBlog/ &amp;&amp; make docker-compose-build-up&quot; 这样的话，每次开发就只需要运行 tmuxinator start yavueblog，并且打开 IDE 直接捋起袖子就是干就好了。 0x03 玩 tmux 首先要掌握的三个小技巧如果你刚用 tmux 的话，火速掌握下面三个小技巧。要不然会抓狂的。 切换终端 c-b + 数字 c-b + n 滚屏 https://superuser.com/questions/209437/how-do-i-scroll-in-tmux 复制文字 https://superuser.com/questions/196060/selecting-text-in-tmux-copy-mode 0xEE 参考链接 我的 Github ChangeLog: 2017-03-08 09:33:37 重新润饰文字，弃用 Rails 开发一年。现在主 DjangoRestFrameWork+VueJS 2018-01-28 11:44:00 重修文字，适配本文]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>全栈开发</tag>
        <tag>Tmux</tag>
        <tag>Tmuxinator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的数据压缩和存档]]></title>
    <url>%2F2018%2F01%2F23%2FPythonCompression%2F</url>
    <content type="text"><![CDATA[0x00 前言在一次数据分析过程中，对方扔过来 40GB 的数据 – data.tar.gz . 我想着能不能直接用 pandas 直接读取这个文件呢？查找了一些资料，于是有了本文。 Python 中支持如下： 数据压缩算法：zlib, gzip, bzip2 and lzma 存档格式：zip 以及 tar 0x01 压缩是怎么回事？0x02 zlib 与 gzipgzip 依赖于 zlib 12345678910111213141516171819202122# 读取压缩文件import gzipwith gzip.open(&apos;/home/joe/file.txt.gz&apos;, &apos;rb&apos;) as f: file_content = f.read()# 写入压缩文件import gzipcontent = b&quot;Lots of content here&quot;with gzip.open(&apos;/home/joe/file.txt.gz&apos;, &apos;wb&apos;) as f: f.write(content)# 拷贝压缩文件import gzipimport shutilwith open(&apos;/home/joe/file.txt&apos;, &apos;rb&apos;) as f_in: with gzip.open(&apos;/home/joe/file.txt.gz&apos;, &apos;wb&apos;) as f_out: shutil.copyfileobj(f_in, f_out)# 压缩二进制字符串import gzips_in = b&quot;Lots of content here&quot;s_out = gzip.compress(s_in) ChangeLog: 2017-12-20 初始化本文]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>数据压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 CSS 你应该知道的一切]]></title>
    <url>%2F2017%2F12%2F28%2FAllStuffAboutCSS%2F</url>
    <content type="text"><![CDATA[0x00 前言本笔记诞生于很久前零零散散记录的笔记，拿出来发布一下。 0x01 CSS 是如何工作的？HTML 是元素的标记语言。 CSS 被用来 样式和网页布局的。 样式和布局都有哪些呢？ 字体 颜色 大小 内容间距 多列 动画 通过 DOM 树的节点和样式节点结合，生成渲染树，然后交给浏览器进行渲染从而使得外观发生变化。 0x02 CSS 基本语法CSS 基本语法有三个组成部分： 规则 选择器 属性 2.1 CSS 规则12345678910111213141516171819h1 &#123; colour: blue; background-color: yellow; border: 1px solid black;&#125;// @规则@import@charset@media@font-face/* in shorthand like padding and margin, the values are appliedin the order top, right, bottom, left (the same order as an analog clock). There are also othershorthand types, for example two values, which set for examplethe padding for top/bottom, then left/right */padding: 10px 15px 15px 5px; 2.2 选择器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// Simple selectors: Match one or more elements based on element type, class, or id./* All div elements are blue */div &#123; color: blue;&#125;h1 &#123; color: red; text-shadow: 1px 1px 1px black; background: linear-gradient(to bottom, rgba(0,0,0,0.25), rgba(0,0,0,0.1)); padding: 3px; text-align: center; box-shadow: inset 2px 2px 5px rgba(0,0,0,0.5), inset -2px -2px 5px rgba(255,255,255,0.5);&#125;// Attribute selectors: Match one or more elements based on their attributes/attribute values./* All elements with the attribute &quot;data-vegetable&quot;are given green text */[data-vegetable] &#123; color: green;&#125;/* All elements with the attribute &quot;data-vegetable&quot;with the exact value &quot;liquid&quot; are given a goldenbackground color */[data-vegetable=&quot;liquid&quot;] &#123; background-color: goldenrod;&#125;/* All elements with the attribute &quot;data-vegetable&quot;,containing the value &quot;spicy&quot;, even among others,are given a red text color */[data-vegetable~=&quot;spicy&quot;] &#123; color: red;&#125;// Pseudo-classes: Match one or more elements that exist in a certain state, such as an element that is being hovered over by the mouse pointer, or a checkbox that is currently disabled or checked, or an element that is the first child of its parent in the DOM tree.// Pseudo-elements: Match one or more parts of content that are in a certain position in relation to an element, for example the first word of each paragraph, or generated content appearing just before an element.:active:any:checked:default:dir():disabled:empty:enabled:first:first-child:first-of-type:fullscreen:focus:focus-within:hover:indeterminate:in-range:invalid:lang():last-child:last-of-type:left:link:not():nth-child():nth-last-child():nth-last-of-type():nth-of-type():only-child:only-of-type:optional:out-of-range:read-only:read-write:required:right:root:scope:target:valid:visited// Combinators: These are not exactly selectors themselves, but ways of combining two or more selectors in useful ways for very specific selections. So for example, you could select only paragraphs that are direct descendants of divs, or paragraphs that come directly after headings.A, B 匹配 A 或 BA B 匹配 A 里面的 BA &gt; B 匹配 A 里面的直属 BA + B 匹配 A 下一个兄弟节点 BA ~ B 匹配 A 的下一群兄弟节点 B// Multiple selectors: Again, these are not separate selectors; the idea is that you can put multiple selectors on the same CSS rule, separated by commas, to apply a single set of declarations to all the elements selected by those selectors. 2.3 属性Positionhttp://cssreference.io/positioning/ DisplayBox Model块级元素 (Block) 新开始一行并且尽可能撑满容器，p,form,header,footer,section 设置块级元素的 width 可以防止它从左到右撑满整个容器行内元素 (inline) 包裹一些文字，而不会打乱段落的布局，a,spannone script 默认 display:none,visibility:hidden 是占据空间 盒模型 属性 三，层叠与继承 既然是层叠，就要有层叠的规律 0x03 CSS 新语法3.1 Flex Layout https://github.com/philipwalton/solved-by-flexbox 3.2 Grid Layout0x04 SCSS这是一种兼容 CSS 语法的新语言。主要用于提升代码的可维护性。 至于其他 less 之类大同小异。只选取了功能最强大的部分进行间接。 4.1 OOCSS / BEM / 我的实践4.1 如何组织 SCSS 代码 — 布局篇4.2 如何组织 SCSS 代码 — 组件篇4.2 BEM0x05 CSS 规范 https://github.com/airbnb/css Use soft tabs (2 spaces) for indentation Prefer dashes over camelCasing in class names. Underscores and PascalCasing are okay if you are using BEM (see OOCSS and BEM below). Do not use ID selectors When using multiple selectors in a rule declaration, give each selector its own line. Put a space before the opening brace { in rule declarations In properties, put a space after, but not before, the : character. Put closing braces } of rule declarations on a new line Put blank lines between rule declarations OOCSS 与 BEM 混用 只要是可维护的好代码，并不需要拘泥于用什么风格 5.1 圣杯0xEE 参考链接 https://github.com/picturepan2/spectre ChangeLog: 2017-12-20 初始化本文]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>SASS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS 的系统与软件]]></title>
    <url>%2F2017%2F12%2F23%2FmacOSInDepth%2F</url>
    <content type="text"><![CDATA[0x00 前言折腾了 Windows 很多年，后来出于个人开发需求转投 Mac，使用起来一直很顺手。现在也开始从顺手开始到了解更深一点的东西。 0x01 系统安全架构1.1 系统架构概述非开发人员分层： User Experience Aqua Dashboard Spotlight Dock 输入法 屏保 辅助功能 语音 位置与地图 搜索 etc Application Framework Cocoa Graphics and Media 核心框架，OpenAL,Quartz,SceneKit,SpriteKit Darwin 系统内核与 Shell 环境 开发人员分层： Cocoa Layer: Cocoa 框架层 包括了用于开发界面程序的框架集合。 Foundation Layer: 提供了程序开发室使用到的基础数据类型、数值处理、网络、IO 和 日期等 Media Layer: 提供了图像、声音、视频、动画及游戏开发需要的接口 Core Service Layer: 系统安全、底层内部数据访问以及存储接口。比如 AddressBook,CoreData,QuickLook 用于快速浏览插件开发。CoreFoundation 框架也属于这一层。 Core OS Layer: 加速器，蓝牙，异常处理，网络扩展，系统配置 Kernel &amp; Driver Layer: 内核与驱动层。包括开发设备驱动程序与内核扩展所需的一些框架。 应用程序是一个 bundle 文件，一般为 xxx.app 文件夹， 1.1 一些常用软件ClangLLVM HT Editor 1brew install ht 0x02 前言0x03 前言0xEE 参考链接 macOS 软件安全和逆向分析 ChangeLog: 2017-12-20 初始化本文 2018-02-10 添加笔记]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>XCode</tag>
        <tag>App Store</tag>
        <tag>Apple Store</tag>
        <tag>iTunes Store</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次小机器的 Python 大数据分析]]></title>
    <url>%2F2017%2F12%2F07%2FANoteWithSmallMachineAndBigData%2F</url>
    <content type="text"><![CDATA[0x00 前言机缘巧合，最近公司突然要搞一波大量数据的分析。属于客流类的分析。 数据量级也还算不错，经过 gzip 压缩，接近 400 个 点位的 SQL 文件 (MySQL innoDB)，大小接近 100GB 左右，原始记录数据估测在 180 亿左右。 解压后…… 差不多一个 T 吧。 如果是人民币玩家，自然是直接购置几十台高配置机器，做个 mysql shard 或者直接上大数据全家桶比如 hadoop 和 hive 之类，让程序员去往死里折腾吧。 嗯，然而对于我这种非人民币玩家，就要用单机硬扛。 那就硬扛呗。 我手上的机器配置如下： 局域网服务器 （ Ubuntu 16.04 LTS ） Xeon(R) CPU E3-1225 v5 @ 3.30GHz 16G 内存 1T 硬盘 苹果电脑 2016 年 15 寸 最高配 1T 硬盘 i7 四核 0x01 准备数据阶段用低配机器分析大数据的首要原则，就是不要分析大数据。 何也？ 就是尽可能的抽取所得结论所需分析数据的最小超集 小机器是无法完成海量计算的，但通过一定的过滤和筛选可以将数据筛选出到一台机器能扛得住的计算量。从而达到可以可以分析海量数据的目的。 1.1 将数据导入 MySQL 中我们先不管三七二十一，既然给了 SQL 文件，肯定要入库的，那么问题来了： 将大象关进冰箱要几个步骤 将数据导入数据库中需要几个步骤 或者说，如何更快的导入 400 张不同表的数据。 大致步骤如下： 新增硬盘，并初始化 配置 MySQL 的 datadir 到新增硬盘上 导入数据 (PV &amp; MySQL) 新增硬盘，并初始化首先，购买并插入硬盘 使用 lshw 查看硬盘信息 12345678910111213141516171819202122232425262728293031323334353637root@ubuntu:~# lshw -C disk *-disk description: SCSI Disk product: My Passport 25E2 vendor: WD physical id: 0.0.0 bus info: scsi@7:0.0.0 logical name: /dev/sdb version: 4004 serial: WX888888HALK size: 3725GiB (4TB) capabilities: gpt-1.00 partitioned partitioned:gpt configuration: ansiversion=6 guid=88e88888-422d-49f0-9ba9-221db75fe4b4 logicalsectorsize=512 sectorsize=4096 *-disk description: ATA Disk product: WDC WD10EZEX-08W vendor: Western Digital physical id: 0.0.0 bus info: scsi@0:0.0.0 logical name: /dev/sda version: 1A01 serial: WD-WC888888888U size: 931GiB (1TB) capabilities: partitioned partitioned:dos configuration: ansiversion=5 logicalsectorsize=512 sectorsize=4096 signature=f1b42036 *-cdrom description: DVD reader product: DVDROM DH1XXX8SH vendor: PLDS physical id: 0.0.0 bus info: scsi@5:0.0.0 logical name: /dev/cdrom logical name: /dev/dvd logical name: /dev/sr0 version: ML31 capabilities: removable audio dvd configuration: ansiversion=5 status=nodisc 使用 fdisk 格式化硬盘，并且分区 1234567891011fdisk /dev/sdb#输入 n#输入 p#输入 1#输入 wsudo mkfs -t ext4 /dev/sdb1mkdir -p /media/mynewdrivevim /etc/fstab# /dev/sdb1 /media/mynewdrive ext4 defaults 0 2# 直接挂载所有，或者 rebootmount -a 至此为止，硬盘就格式化完成了。 关于安装硬盘，可以参考 https://help.ubuntu.com/community/InstallingANewHardDrive 配置 MySQL篇幅有限，只简介具体在 Ubuntu 16.04 上面 配置 MySQL 的 DataDIR ，省去安装和基本登录认证的配置。 mysql 在 ubuntu 下面默认的路径如下： 1/var/lib/mysql/ 我们开始配置 DataDIR 12345678910111213141516171819202122232425systemctl stop mysqlrsync -av /var/lib/mysql /mnt/volume-nyc1-01mv /var/lib/mysql /var/lib/mysql.bakvim /etc/mysql/mysql.conf.d/mysqld.cnf# 修改至 datadir=/mnt/volume-nyc1-01/mysqlvim /etc/apparmor.d/tunables/alias# alias /var/lib/mysql/ -&gt; /mnt/volume-nyc1-01/mysql/sudo systemctl restart apparmorvim /usr/share/mysql/mysql-systemd-start# 修改成if [ ! -d /var/lib/mysql ] &amp;&amp; [ ! -L /var/lib/mysql ]; then echo "MySQL data dir not found at /var/lib/mysql. Please create one." exit 1fiif [ ! -d /var/lib/mysql/mysql ] &amp;&amp; [ ! -L /var/lib/mysql/mysql ]; then echo "MySQL system database not found. Please run mysql_install_db tool." exit 1fi# 接下来sudo mkdir /var/lib/mysql/mysql -psudo systemctl restart mysql# 最后 my.conf 修改相关文件路径 详细请参考这篇文章 https://www.digitalocean.com/community/tutorials/how-to-move-a-mysql-data-directory-to-a-new-location-on-ubuntu-16-04 将 DataDIR 配置完成之后，就可以导入数据了。嗯，经过这么麻烦的事情之后，我决定下次遇到这种情况首选 Docker 而不是在 Ubuntu Server 上面搞这个。 站在现在看，如果重来的话，我肯定会用 Docker 然后把数据盘挂载到新硬盘到。 比如直接 Docker 命令执行 1docker run --name some-mysql -v /my/own/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 导入数据 之 MySQL + PV我们使用 mysql 导入脚本的时候，有几种导入方式 source 命令，然而这个命令容易在数据量很大的时候直接卡掉。（印象中是直接把 sql 文件加载到内存中，然后执行，然而，只要涉及到大量文本打印出来并且执行，速度一定会变慢很多） mysql 命令 12# mysql 命令的典型导入场景就是这样mysql -uadmin -p123456 some_db &lt; tb.sql 加上 PV 命令的话，比较神奇了。有进度条了！! 12# 附加进度条的导入场景pv -i 1 -p -t -e ./xxxx_probe.sql | mysql -uadmin -p123456 some_db 然后，可以查看一下磁盘 CPU 内存的占用情况。如果负载（着重注意 IO，内存）还不够满，使用 tmux 多开几个进程导入数据。 因为每个 SQL 文件对应的表不一样，所以多开几个进程批量 insert 的话并不会锁表，这样可以显著提升导入速度。 1.2 导出数据既然已经导入了数据，为什么需要导出数据呢？ 因为数据量比较大，需要进行初步清洗。而我们最后肯定使用 Pandas 进行分析，从局域网数据库中读取大量的数据的时候，pandas 速度会非常的慢（具体是因为网络传输速度？)。所以，为了后面分析省事，我批量导出了数据，然后按照我的习惯进行了归类。 在这个过程中，我还进行了一小部分的数据过滤，比如： 只选取对自己有用的行与列。 化整为零，拆分数据为最小单元的 CSV 文件 只选取对自己有用的行与列1select col_a , col_b from some_table where Acondition and bcondition and col_c in ('xx','yy','zz'); 这里面有一些值得注意的地方 尽量把简单的判断写在左边。 如果不是反复查询，则没有必要建立索引。直接走全表，筛选出必要的数据存 CSV 即可。 尽量拆分数据为最小单元的 CSV 文件如果按照某类，某段时间进行拆分可以在分析的时候随时取随时分析那就进行拆分。 比如，某个大的 CSV 包含琼瑶里面各种人物情节地点的位置就可以拆分为： 123201712_大明湖畔_夏雨荷_还珠格格_你还记得吗.csv201711_老街_可云_情深深雨蒙蒙_谁来救我.csv201710_屋子里_云帆_又见一帘幽梦_你的腿不及紫菱的爱情.csv 当我们需要取这坨数据的时候，可以直接 glob 一下，然后 sort, 接着二分查找。就可以快速读取这块数据了。 1.3 校验数据完备性第三方给的数据多多少少会有这些或者那些的问题，一般情况下，可以通过检查数据完备性来尽可能的减少数据的不靠谱性。 我习惯性在这样的表里面详细记录数据完备性的各种参数与进度。 比如： 数据的提供情况和实际情况 阶段性的记录条数和点位的统计值 max，min，mean，median 用来避免异常值 如果是分年份，则必须要统计每一天的情况，否则也不知道数据的缺失程度。 0x02 分析阶段经过上一步处理，数据的文件总大小大约从 1000GB (uncompressed) -&gt; 30GB 左右 （拆分成若干个文件 compressed) 。每个文件大约是几百兆。 2.1 性能要点 1：文件系统如果统计逻辑很简单，但是数量多，首选使用读取文件。读取文件进行统计速度是非常快的。（人民币玩家走开） 像 linux 里面的 wc,grep,sort,uniq 在这种场景有时候也能用到。 注意，如果文件特别大，一定要迭代器一个一个读取。 对于超大文件，比如说，上百 G 文件，可以先分成小片的文件，然后多进程批量读取并且处理。 2.2 性能要点 2：化整为零，map reduce filter化整为零这个已经在上面的 1.2 节讲过了。 map/reduce/filter 可以极大的减少代码。 collection 中有个 Counter , 在进行简单代码统计的时候用起来可以极大的减少代码。 2.3 性能要点 3：进程池的两种作用我们都知道，当 用 Python 执行计算密集的任务时，可以考虑使用多进程来加速： 即为了加速计算，此为作用一。如下： 123456789def per_item_calc(item): df = pd.read..... # complex calc return resultwith ProcessPoolExecutor(3) as pool: result_items = pool.map(per_item_calc,all_tobe_calc_items)reduce_results = .... 其实进程的销毁本身就可以给我带来第二个作用管理内存。 具体会在 2.6 中的 DataFrame 里面解释。 2.4 性能要点 4：List 和 Set , itertools有 400 组 UUID 集合，每个列表数量在 1000000 左右，列表和列表之间重复部分并不是很大。我想拿到去重之后的所有 UUID，应该怎么处理 在去重的时候，自然而然想到了使用集合来处理。 最初的做法是 12list_of_uuid_set = [ set1 , set2 ... set400 ]all_uuid_set = reduce(lambda x: x | y, list_of_uuid_set) 1 小时过去了。 突然之间，四下里万籁无声。公司内外聚集数百之众，竟不约而同的谁都没有出声，便有人想说话的，也为这寂静的气氛所慑，话到嘴边都缩了回去。似乎硬盘的指示灯也熄灭了，发出轻柔异常的声音。我心中忽想： 小师妹这时候不知在干甚么？ 卧槽，程序是不是又卡死了？ SSH 上去 htop 一下机器。发现实存和内存都满了。直觉告诉我，CPython 的集合运算应该是挺耗内存的。 嗯，这怎么行，试试用列表吧。列表占用内存应该是比较小的。 123456def merge(list1,list2): list1.append(list2) return list1list_of_uuid_list = [ list1 , list2 ... list400 ]all_uuid_set = set(reduce(merge, list_of_uuid_list)) 1 小时过去了。 我一拍大腿，道： 小师妹这时候不知在干甚么？ 卧槽，程序是不是又卡死了？ 最后在 StackOverFlow 上找到了更好的解决方案。 12list_of_uuid_list = [ list1 , list2 ... list400 ]all_uuid_set = set(list(itertools.chain(*list_of_uuid_list))) 运行一下，5s 不到出了结果（注意，包含了 Set 去重）。 itertools 里还有很多有趣的函数可以使用。 https://docs.python.org/3/library/itertools.html 2.5 性能要点 5：IPython 给性能带来的影响当我们在分析数据的时候，往往使用的是 IPython, 或者 Jupyter Notebook 但是，方便的同时，如果不加以注意的话，就会带来一点点小问题。 比如下划线和双下划线分别存储上一个 CELL 的返回值，和上上个 CELL 的返回值。 2.6 性能要点 6：DataFrame 带来的 GC 问题DataFrame 是我用 Pandas 的原因，在这次使用 DataFrame 的过程中，还是出现一些头疼的问题的。比如莫名的内存泄露。 12345678910def per_item_calc(item): df = pd.read..... # complex calc return resultresult_items = []for item in all_tobe_calc_items: result_items.append(per_item_calc(item))reduce_results = .... 我在 For 循环中读取 DataFrame 赋值给 df, 然后统计出一个结果。按理来说，每次只要一个简单的 result, 每次读取的文件大小一致，同样的会占用接近 2G 内存，而，当我赋值 df 的时候，按理来说，应该是把原先 df 的引用数应该为 0, 会被 gc 掉，又释放了 2G 内存，所以，是不太可能出现内存不够用的。 运行程序，内存 biubiubiubiu 的增长，当进行到约第 1000 次的循坏的时候，直到 16G 内存占满。 那么显式的 del 一下会不会好一点呢？代码如下： 12345def per_item_calc(item): df = pd.read..... # complex calc del df return result 似乎好了一点点，但是其实并没有好到哪里去。 然而，和前一次一样，内存 biubiubiubiu 的增长，当进行到约第 1000 次的循坏的时候，直到 16G 内存占满。 只是在读取文件的时候，预先减少了上次循环没有 del 掉的 df. 和上一个想法没有太大区别。除了比上一个方法每次读取文件的提前减少了一个多 G 的内存。 查找相关资料，涉及到 Python 里面的 Pandas GC 的资料并不多，稍微整理一下，如下： Python 程序 在 Linux 或者 Mac 中，哪怕是 del 这个对象，Python 依旧 站着茅坑不拉屎 就是不把内存还给系统，自己先占着，有本事你打死我啊 直到进程销毁。 嗯？这个和我要的东西不一样嘛？具体怎么管理 pandas 里面的 object 的，到底是哪里 GC 不到位呢？还是没有说呀。 参考： https://stackoverflow.com/questions/23183958/python-memory-management-dictionary http://effbot.org/pyfaq/why-doesnt-python-release-the-memory-when-i-delete-a-large-object.htm 不过有一点启示了我。 直到进程销毁。 Python 里面不是有个 ProcessPoolExecutor 模块么。 那么问题来了，ProcessPoolExecutor 是动态创建进程并且分配任务的呢，为每一个 item 分配一个进程来运算？还是创建完三个进程之后把 item 分配给空闲进程的进行运算呢？ 如果是前者，则是正经的进程池。似乎 map 过去，除非任务执行完毕或者异常退出，否则进程不销毁。并不能给我们解决 内存泄露 的问题。 如果是后者，则是并不是线程池。 你说，进程池肯定是前者咯。可是你在验证之前，这是进程池只是你的从其他语言带来的想法，这是不是一个线程池，是一个什么样子的进程池，如果进程执行过程中挂掉了，这个时候就少了一个线程，会不会再补充一个进程呢？？ 怎么看验证呢？ 运行程序，进入 Htop 看进程 PID 看源码 123456789# https://github.com/python/cpython/blob/3.6/Lib/concurrent/futures/process.py#L440def _adjust_process_count(self): for _ in range(len(self._processes), self._max_workers): p = multiprocessing.Process( target=_process_worker, args=(self._call_queue, self._result_queue)) p.start() self._processes[p.pid] = p 从源码得出在主线程创建了管理进程的线程，管理进程的线程创建了 max_workers 个进程（在我的例子里面就只有 3 个 worker). 是个进程池。 好，如果是进程池，似乎 map 过去，除非任务执行完毕或者异常退出，否则进程不销毁。并不能给我们解决 内存泄露 的问题。 等等，如果用多进程池不就好咯？ 1234567891011121314def per_item_calc(item): df = pd.read..... # complex calc return resultresult_items = []step = 300for idx in range(0,len(all_tobe_calc_items),step): pieces_tobe_calc_items = all_tobe_calc_items[idx:idx+step] with ProcessPoolExecutor(3) as pool: pieces_result_items = pool.map(per_item_calc,pieces_tobe_calc_items) result_items.append(pieces_result_items)reduce_results = list(itertools.chain(*result_items)) 当然，这是一种让操作系统帮我 GC 的方法。即 Python 不能帮我 GC 的，操作系统帮我 GC PS: 其实用 multiprocessing 模块也行，只是线程池可以稍微控制一下进程创建的数量。 总结一下，对于大量的 DataFrame 处理： 多个进程池是一种处理的方式。 尽量减少 DataFrame 的数量 尽量减少赋值导致的 COPY, 修改时带上 inplace=True 读取 CSV 的时候指定相关列的类型 {‘col_a’: np.float64, ‘col_b’: np.int32}，否则 pandas 会产生大量的 object 0xDD 番外篇在分析这次的数据过程中，自己的 Mac 主板也坏掉了，幸好还在保修期，送到苹果店维修了一下。给苹果的售后点个赞。 0xEE 更新 2017-12-07 初始化本文 2017-12-16 增加分析阶段的文字 2017-12-26 去掉一些 TODO, 发布到我的小站 2017-12-31 正式发布]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>性能优化</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的作用域准则]]></title>
    <url>%2F2017%2F11%2F20%2FPythonClosureAndScopes%2F</url>
    <content type="text"><![CDATA[0x00 前言因为最早用的是 Java 和 C#，写 Python 的时候自然也把 Python 作用域的想的和原有的一致。 Python 的作用域变量遵循在大部分情况下是一致的，但也有例外的情况。 本文着通过遇到的一个作用域的小问题来说说 Python 的作用域 0x01 作用域的几个实例Python 的作用域变量遵循在大部分情况下与其他语言一致，但也有例外的情况。比如： 1.1 第一个例子作用域第一版代码如下 12345a = 1print(a, id(a)) # 打印 1 4465620064def func1(): print(a, id(a))func1() # 打印 1 4465620064 作用域第一版对应字节码如下 1234567894 0 LOAD_GLOBAL 0 (print) 3 LOAD_GLOBAL 1 (a) 6 LOAD_GLOBAL 2 (id) 9 LOAD_GLOBAL 1 (a) 12 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 15 CALL_FUNCTION 2 (2 positional, 0 keyword pair) 18 POP_TOP 19 LOAD_CONST 0 (None) 22 RETURN_VALUE PS: 行 4 表示 代码行数 0 / 3 / 9 … 不知道是啥，我就先管他叫做条吧 是 load globalPPS: 注意条 3/6 LOAD_GLOBAL 为从全局变量中加载 顺手附上本文需要着重理解的几个指令 LOAD_GLOBA : Loads the global named co_names[namei] onto the stack. LOAD_FAST(var_num) : Pushes a reference to the local co_varnames[var_num] onto the stack. STORE_FAST(var_num) : Stores TOS into the local co_varnames[var_num]. 这点似乎挺符合我们认知的，那么，再深一点呢？既然这个变量是可以 Load 进来的就可以修改咯？ 1.2 第二个例子然而并不是，我们看作用域第二版对应代码如下 123456a = 1print(a, id(a)) # 打印 1 4465620064def func2(): a = 2 print(a, id(a))func2() # 打印 2 4465620096 一看，WTF, 两个 a 内存值不一样。证明这两个变量是完全两个变量。 作用域第二版对应字节码如下 1234567891011124 0 LOAD_CONST 1 (2) 3 STORE_FAST 0 (a)5 6 LOAD_GLOBAL 0 (print) 9 LOAD_FAST 0 (a) 12 LOAD_GLOBAL 1 (id) 15 LOAD_FAST 0 (a) 18 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 21 CALL_FUNCTION 2 (2 positional, 0 keyword pair) 24 POP_TOP 25 LOAD_CONST 0 (None) 28 RETURN_VALUE 注意行 4 条 3 (STORE_FAST) 以及行 5 条 9/15 (LOAD_FAST) 这说明了这里的 a 并不是 LOAD_GLOBAL 而来，而是从该函数的作用域 LOAD_FAST 而来。 1.3 第三个例子那我们在函数体重修改一下 a 值看看。 1234567a = 1def func3(): print(a, id(a)) # 注释掉此行不影响结论 a += 1 print(a, id(a))func3() # 当调用到这里的时候 local variable 'a' referenced before assignment# 即 a += 1 =&gt; a = a + 1 这里的第二个 a 报错鸟 123456789101112131415163 0 LOAD_GLOBAL 0 (print) 3 LOAD_FAST 0 (a) 6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 POP_TOP4 10 LOAD_FAST 0 (a) 13 LOAD_CONST 1 (1) 16 BINARY_ADD 17 STORE_FAST 0 (a)5 20 LOAD_GLOBAL 0 (print) 23 LOAD_FAST 0 (a) 26 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 29 POP_TOP 30 LOAD_CONST 0 (None) 33 RETURN_VALUE 那么，func3 也就自然而言由于没有无法 LOAD_FAST 对应的 a 变量，则报了引用错误。 然后问题来了，a 为基本类型的时候是这样的。如果引用类型呢？我们直接仿照 func3 的实例把 a 改成 list 类型。如下 1.4 第四个例子12345678a = [1]def func4(): print(a, id(a)) # 这条注不注释掉都一样 a += 1 # 这里我故意写错 按理来说应该是 a.append(1) print(a, id(a))func4()# 当调用到这里的时候 local variable 'a' referenced before assignment ╮(╯▽╰)╭ 看来事情那么简单，结果变量 a 依旧是无法修改。 可按理来说跟应该报下面的错误呀 1&apos;int&apos; object is not iterable 1.5 第五个例子12345678a = [1]def func5(): print(a, id(a)) a.append(1) print(a, id(a))func5()# [1] 4500243208# [1, 1] 4500243208 这下可以修改了。看一下字节码。 12345678910111213141516171819202122233 0 LOAD_GLOBAL 0 (print) 3 LOAD_GLOBAL 1 (a) 6 LOAD_GLOBAL 2 (id) 9 LOAD_GLOBAL 1 (a) 12 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 15 CALL_FUNCTION 2 (2 positional, 0 keyword pair) 18 POP_TOP4 19 LOAD_GLOBAL 1 (a) 22 LOAD_ATTR 3 (append) 25 LOAD_CONST 1 (1) 28 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 31 POP_TOP5 32 LOAD_GLOBAL 0 (print) 35 LOAD_GLOBAL 1 (a) 38 LOAD_GLOBAL 2 (id) 41 LOAD_GLOBAL 1 (a) 44 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 47 CALL_FUNCTION 2 (2 positional, 0 keyword pair) 50 POP_TOP 51 LOAD_CONST 0 (None) 54 RETURN_VALUE 从全局拿来 a 变量，执行 append 方法。 0x02 作用域准则以及本地赋值准则2.1 作用域准则看来这是解释器遵循了某种变量查找的法则，似乎就只能从原理上而不是在 CPython 的实现上解释这个问题了。 查找了一些资料，发现 Python 解释器在依据 基于 LEGB 准则 （顺手吐槽一下不是 LGBT） LEGB 指的变量查找遵循 Local Enclosing-function locals Global Built-In StackOverFlow 上 martineau 提供了一个不错的例子用来说明 123456789101112131415161718192021222324252627x = 100print("1. Global x:", x)class Test(object): y = x print("2. Enclosed y:", y) x = x + 1 print("3. Enclosed x:", x) def method(self): print("4. Enclosed self.x", self.x) print("5. Global x", x) try: print(y) except NameError as e: print("6.", e) def method_local_ref(self): try: print(x) except UnboundLocalError as e: print("7.", e) x = 200 # causing 7 because has same name print("8. Local x", x)inst = Test()inst.method()inst.method_local_ref() 我们试着用变量查找准则去解释 第一个例子 的时候，是解释的通的。 第二个例子，发现函数体内的 a 变量已经不是那个 a 变量了。要是按照这个查找原则的话，似乎有点说不通了。 但当解释第三个例子的时候，就完全说不通了。 1234567a = 1def func3(): print(a, id(a)) # 注释掉此行不影响结论 a += 1 print(a, id(a))func3() # 当调用到这里的时候 local variable 'a' referenced before assignment# 即 a += 1 =&gt; a = a + 1 这里的第二个 a 报错鸟 按照我的猜想，这里的代码执行可能有两种情况： 当代码执行到第三行的时候可能是向从 local 找 a, 发现没有，再找 Enclosing-function 发现没有，最后应该在 Global 里面找到才是。注释掉第三行的时候也是同理。 当代码执行到第三行的时候可能是向下从 local 找 a, 发现有，然后代码执行，结束。 但如果真的和我的想法接近的话，这两种情况都可以执行，除了变量作用域之外还是有一些其他的考量。我把这个叫做本地赋值准则 （拍脑袋起的名称） 一般我们管这种考量叫做 Python 作者就是觉得这种编码方式好你爱写不写 Python 作者对于变量作用域的权衡。 事实上，当解释器编译函数体为字节码的时候，如果是一个赋值操作 (list.append 之流不是赋值操作），则会被限定这个变量认为是一个 local 变量。如果在 local 中找不到，并不向上查找，就报引用错误。 这不是 BUG 这不是 BUG 这不是 BUG 这是一种设计权衡 Python 认为 虽然不强求强制声明类型，但假定被赋值的变量是一个 Local 变量。这样减少避免动态语言比如 JavaScript 动不动就修改掉了全局变量的坑。 这也就解释了第四个例子中赋值操作报错，以及第五个例子 append 为什么可以正常执行。 如果我偏要勉强呢？ 可以通过 global 和 nonlocal 来 引入模块级变量 or 上一级变量。 PS: JS 也开始使用 let 进行声明，小箭头函数内部赋值查找变量也是向上查找。 0xEE 参考链接 Martineau 的例子 ChangeLog: 2017-11-20 从原有笔记中抽取本文整理而成]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>作用域</tag>
        <tag>语言细节</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 Cheatsheet]]></title>
    <url>%2F2017%2F10%2F20%2FUbuntuCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Shell 单行命令。 不定期更新。 桌面版和 Server 版的操作系统版本均为 Ubuntu 16.04 , 数据库为 MySQL / PostgreSQL , Python 3.5.2 开发和运行环境。 由于部分 Mac 上面的配置与 Ubuntu 上配置几乎相同，特别是一些桌面端，跨平台，强烈建议使用。 每次来一个新同事就需要给他们的环境进行配置，配置其实挺麻烦的，虽然可以花一天的时间配置一遍，但总觉得如果多来几个同事的话我基本上就废掉了。于是抛弃 bash 脚本，修改为 Ansible 脚本，将当前的配置任务彻底脚本化。 0x01 Ubuntu 桌面版开发基本配置语言级别配置，请参考我的其他文章，如何优雅的使用 MAC 0x02 Ubuntu 服务器版本基本配置第一步，更新源： 123456789101112131415161718# deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricteddeb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 123456789101112# 更换源sudo apt-get updatesudo apt-get install git-core curl zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev python-software-properties libffi-devsudo apt-get install zsh tree htopsudo apt-get install build-essential acl ntp htop git libpq-dev libmysqlclient-dev libffi-dev libfreetype6-dev libjpeg8-dev liblcms2-dev libtiff5-dev libwebp-dev libxml2-dev libxslt1-dev tcl8.6-dev tk8.6-dev zlib1g-dev python-dev python-pip python-pycurl python-tk ipython supervisor python3.5 python3.5-dev python3-pip python3-lxml python3-tk ipython3sudo apt-get install mysql-server mysql-client libmysqlclient-dev slurm# GIT 配置git config --global color.ui truegit config --global user.name "twocucao"git config --global user.email "twocucao@gmail.com"ssh-keygen -t rsa -b 4096 -C "twocucao@gmail.com" 2.1 设置无登录密钥123456# 刚开始用了一个很蠢的方法scp ~/.ssh/id_rsa.pub twocucao@192.168.2.156:.ssh/id_rsa.pubssh twocucao@192.168.2.156 "mkdir .ssh;chmod 0700 .ssh"# 现在想想，可以直接 ssh-copy-idssh-copy-id twocucao@192.168.2.156 http://askubuntu.com/questions/46930/how-can-i-set-up-password-less-ssh-login12345678910111213141516171819202122232425# 服务器sudo apt-get install openssh-serversudo vi /etc/ssh/sshd_config # 找到 PermitRootLogin no 一行，改为 PermitRootLogin yessudo service ssh restartsudo apt-get install git-core curl zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev python-software-properties libffi-devsudo adduser deploysudo adduser deploy sudosu deploy# 开发机复制 ssh 公钥。# 可以用下面的命令，汗，之前都是在服务器上面创建.ssh 文件夹，然后在本地 scp 拷贝过去，现在想想这个方法还是挺笨的。# 就像这样scp ~/.ssh/id_rsa.pub deploy@192.168.1.143:/webapps/xxxapp/.ssh/authorized_keys# 其实这个命令就 OK 了。ssh-copy-id deploy@IPADDRESS# 服务器sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 561F9B9CAC40B2F7sudo apt-get install -y apt-transport-https ca-certificatessudo apt-get install -y nginx-extrassudo service nginx start 0x02 Ubuntu 服务器版本基本配置0x03 了解 Linux 服务器运行情况1234567891011121314151617181920212223242526272829# 运行时间uptime# 内存情况free -h# 网络类## 实时流量监控iftop## 进程占用带宽nethogs## sudo nethogs eth0iptraf# 磁盘类iotop## 当 dstat 的 wai 字段值比较大时，可以使用 iotop 找出哪些进程出了问题# 综合类 之 监控进程，进程管理tophtopglances # PS , 这个监控粒度更细# 综合类 可以取代 vmstat , iostat , netstat , ifstatdstat# 综合类# 约等于 strace + tcpdump + htop + iftop + lsofsysdig 0x04 踩坑集合前段时间公司新买了一台 Thinkpad Server 作为内网服务器。 于是在安装 Ubuntu16.04 的时候就遇到了一个令人哭笑不得的问题。 无法正常安装 报 ubuntu 的 initramfs 错误。 于是，我下意识的去 Google 问题，在 Ubuntu 的一个论坛上面找到了对应的答案： 是 Superblock 的问题。 对应措施如下： 123456# 找到分区号sudo fdisk -l|grep Linux|grep -Ev 'swap'# 找到超级块sudo dumpe2fs /dev/sda2 | grep superblock# 修复超级块sudo fsck -b 32768 /dev/sda2 -y 然后重启即可。 当然，问题并没有结束，还是在老地方发现 initramfs 错误。 就在我哭笑不得的准备最后一搏，实在不行就安装 CentOS 作为系统的时候，由于安装时候选择 language 的时候选择英文，结果居然安装成功了。 所以，解决问题的方式就是不要使用简体中文进行安装. 虽然这是一个很奇怪的问题，至今我也没有探索出来具体的原因。想到问题居然是因为安装的时候因为选择了中文安装。 这个问题还真的是….. 最后知道真相的我眼泪掉下来 3.1 磁盘问题12345678df -h 查看磁盘块占用的文件（block）df -i 查看索引节点的占用（Inodes）find / -size +100M |xargs ls -lh# 删除 5 天前的文件find /path/to/files* -mtime +5 -exec rm &#123;&#125; \;du -hrm xxx.logecho &quot;&quot; &gt; xxx.log ChangeLog: 2017-03-19 重修文字，准备整理安装配置将结果转化为 Ansible PlayBook 2017-10-20 重修文字，准备整理安装配置将结果转化为 Ansible PlayBook]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅地使用 macOS]]></title>
    <url>%2F2017%2F10%2F05%2FElegantMac%2F</url>
    <content type="text"><![CDATA[当时写这篇文章的时候才接触 mac 没多久，使用快两年之后，再次修订了本文。 0x00 前言谈及 macOS , 很多人喜欢和 Win 比个高下。在我看来， Win 虽在非编程类生态和易用性比 Mac 要好很多，可专业人士之所以专业是因为他能挑选适合的武器发挥最大的效用，不是吗？ 适合自己的，能让自己用最大效率生产或者是娱乐的，才是更好的工具。 Win 的优点如下： 优良的兼容性。 由于出自于什么都爱做的微软公司，从整体来说，VS，.NET, 游戏性，兼容性，性能，新手上手速度来说，都是遥遥领先 Mac 的。 Win 的缺点如下： 微软的战线实在是拉的太长，什么都想做，什么都想垄断。于是，与之服务密切相关的公司也就受到了 MS 的牵制。这对大公司来说，几乎是不能够忍受的行为。硅谷的公司使用微软服务的也就接近 5%（可能有误差）。 糟糕的终端环境（DOS）和无法与、*nux 世界的脚本友好相处使得系统的可定制性和进阶操作性大大降低。 虽然有 Everything，TotalCMD，AHK 这种神级辅助工具可以满足定制要求。但由于过高的学习成本（哈哈哈，混乱也是学习成本之一，AHK 语言真的很混乱啊，TC 实在是太不人性化了）。 Python 的环境配置实在是太头疼了 Win 的缺点就是我切到 Mac 上面的原因。 macOS 的优点如下： Mac 的好在于终端和美观的图形的结合。适合不是微软技术栈和重度 Office 的用户。 *nux 应用的方便以及非常容易与脚本文件配合出强大的组合技能。 反观 Win 上，则这种组合技能则在环境配置上和操作流畅度上差了很多。 macOS 的缺点如下： 娱乐项目实在是少的要死。Metal 和 DirectX 相差不是一点点。 软件和有些少的不只一点点。 本文从下面几处入手，分别从下面几个角度介绍了 macOS ▼ 如何优雅地使用 macOS 0x00 前言 ▼ 0x01 系统内置 1.1 系统设置 1.2 自带软件 1.3 快捷键与触摸板 ▼ 0x02 必备软件 2.1 必备软件 之 日常必备 ▼ 2.2 必备软件 之 开发必备 2.2.1 GUI 应用 2.2.2 CMD 命令 ▼ 2.3 必备软件 之 编程语言 2.3.1 Shell 2.3.2 Python ▼ 0x03 踩坑史 ▼ 3.1 日常类 01. 时间机器无法完成备份 02. 下载站的软件包显示损坏 ▼ 3.2 编程类 01. homebrew 的与 Python 的问题 0xEE 参考链接 0x01 系统内置1.1 系统设置General 默认浏览器 : Google Chrome Decktop &amp; Screen Saver 桌面 / 屏保 Language &amp; Region 语言 地区设置 Security &amp; Privacy 防火墙 Sharing Remote Control - SSH Trackpad 设置手势 滚轮 Scrool Direction : Natural 1.2 自带软件 iTunes iPhoto iMessage SpotLight -&gt; Alfred 3 1.3 快捷键与触摸板 cmd 为 command 按键，通常情况下为所有桌面程序通用性的快捷键。 ctrl ，通常情况下是针对程序的功能进行加强，并且此功能往往是非 cmd 类（窗口操作，选择，复制粘贴等等）操作。 shift 按键通常用于加强操作。一般会让操作更进一步 or 相反操作。 cmd+tab =~ alt+tab 程序之间的切换 cmd+` 应用内窗口切换 cmd+h 窗口 hide cmd+m 窗口 minimize cmd+n 新建窗口 cmd+o 打开 cmd+s 保存 cmd+shift+s 另存为 cmd+p 打印 print cmd+w 关闭 cmd+q quit cmd+a select all cmd+i show info cmd+n create a new folder cmd+f search cmd+c copy cmd+v paste cmd+delete 删除选中文件 cmd+shift+delete 清空回收站 cmd+= 放大 cmd+- 缩小 cmd+t 新建选项卡 cmd+r 刷新 cmd+shift+3 截取整个屏幕 cmd+shift+4 截取选择区域 cmd+shift+4+SPACE 截取选择窗口 cmd+ 鼠标点击 -&gt; 选中不连续文件 control+ 鼠标点击 -&gt; 相当于 win 中右键点击 fn+left home fn+right end fn+up pageup fn+down pagedown 触摸板手势： 点击 单指点击 - 单击 单指滑动 - 滑动鼠标光标 双指点击 - 相当于 Windows 的鼠标右键 三指点击 - 划词查找 滑动与缩放 双指上下滑动 - 滚动 双指缩放 - 与 Android 上图片缩放一致 双指双击 - 只能缩放 双指旋转 - 旋转 双指左右滑动 - 应用内切换网页 双指头从右往左 三指头左右滑动 - 全屏幕 App 切换 大拇指和食中无名缩放 - launchpad 0x02 必备软件2.1 必备软件 之 日常必备 启动器 Alfred 3 SpotLight 网络工具 Chrome 社交通讯 QQ WeXin 图形图像 Adobe PhotoShop CC Adobe PhotoShop LightRoom Sketch Annotate Camtasia 2 Snagit ScreenFlow Final Cut Pro MPlayerX QuickTime iQiyi NeteaseMusic IINA 办公软件 欧陆词典 Calibre Wiznote PDF Reader iBook Microsoft Office Work 套件：包括 pages, numbers, keynote XMind Airmail TeamViewer OmniFocus OmniGraffle OmniOutline OmniPlan 系统软件 搜狗输入法 AppCleaner CleanMyMac VMWare BetterZip Caffeine / Amphetamine PopClip HandShaker AirDroid 2.2 必备软件 之 开发必备2.2.1 GUI 应用 终端用户 iTerm2 IDE PyCharm IntellijIDEA WebStorm 编辑器 MacVim 配合 C-VIM Sublime Text 3 后台组件 MySQL PostgreSQL Redis MongoDB 数据库管理软件 Navicat Datagrip RoboMongo RDM Dash 网络工具 SS QT Charles, Wireshark Chrome Exporter : 百度云，需要离线安装 AdBlock : 广告拦截 AutoPatchWork : 链接下一页 Axure RP Extension : Axure CSSViewer Dream Afar New Tab JSON Editor JSON View Octotree One-Click Extensions Manager Proxy SwitchyOmega React Developer Tools Redux DevTools Vue.js devtools Vimium 代码仓库 Github Desktop SourceTree GIS 相关 ArcGIS QGIS PostgreSQL + PostGIS 2.2.2 CMD 命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152if test ! $(which brew); then echo "Installing homebrew..." ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"fi# Make sure we’re using the latest Homebrew.brew update# Upgrade any already-installed formulae.brew upgrade --all# Install GNU core utilities (those that come with OS X are outdated).# Don’t forget to add `$(brew --prefix coreutils)/libexec/gnubin` to `$PATH`.brew install coreutilssudo ln -s /usr/local/bin/gsha256sum /usr/local/bin/sha256sum# Install some other useful utilities like `sponge`.brew install moreutils# Install GNU `find`, `locate`, `updatedb`, and `xargs`, `g`-prefixed.brew install findutils# Install GNU `sed`, overwriting the built-in `sed`.brew install gnu-sed --with-default-names# Install Bash 4.brew install bashbrew tap homebrew/versionsbrew install bash-completion2# We installed the new shell, now we have to activate itecho "Adding the newly installed shell to the list of allowed shells"# Prompts for passwordsudo bash -c 'echo /usr/local/bin/bash &gt;&gt; /etc/shells'# Change to the new shell, prompts for passwordchsh -s /usr/local/bin/bash# Install `wget` with IRI support.brew install wget --with-iri# Install RingoJS and Narwhal.# Note that the order in which these are installed is important;# see http://git.io/brew-narwhal-ringo.brew install ringojsbrew install narwhal# Install Pythonbrew install pythonbrew install python3# Install ruby-build and rbenvbrew install ruby-buildbrew install rbenvLINE='eval "$(rbenv init -)"'grep -q "$LINE" ~/.extra || echo "$LINE" &gt;&gt; ~/.extra# Install more recent versions of some OS X tools.brew install vim --override-system-vibrew install homebrew/dupes/grepbrew install homebrew/dupes/opensshbrew install homebrew/dupes/screenbrew install homebrew/php/php55 --with-gmp# Install font tools.brew tap bramstein/webfonttoolsbrew install sfnt2woffbrew install sfnt2woff-zopflibrew install woff2# Install some CTF tools; see https://github.com/ctfs/write-ups.brew install aircrack-ngbrew install bfgbrew install binutils --with-default-namesbrew install binwalkbrew install ciferbrew install dex2jarbrew install diffutilsbrew install dns2tcpbrew install ed --with-default-namesbrew install fcrackzipbrew install findutils --with-default-namesbrew install foremostbrew install gawkbrew install gnu-indent --with-default-namesbrew install gnu-sed --with-default-namesbrew install gnu-tar --with-default-namesbrew install gnu-which --with-default-namesbrew install gnutlsbrew install grep --with-default-namesbrew install gzipbrew install hashpumpbrew install homebrew/x11/xpdfbrew install hydrabrew install johnbrew install knockbrew install netpbmbrew install nmapbrew install pngcheckbrew install screenbrew install socatbrew install sqlmapbrew install tcpflowbrew install tcpreplaybrew install tcptracebrew install tmuxbrew install ucspi-tcp # `tcpserver` etc.brew install watchbrew install wdiff --with-gettextbrew install wgetbrew install xz# Install other useful binaries.brew install ackbrew install dark-mode#brew install exiv2brew install gitbrew install git-lfsbrew install git-flowbrew install git-extrasbrew install hubbrew install imagemagick --with-webpbrew install luabrew install lynxbrew install p7zipbrew install pigzbrew install pvbrew install renamebrew install rhinobrew install speedtest_clibrew install ssh-copy-idbrew install treebrew install webkit2pngbrew install zopflibrew install pkg-config libffibrew install pandoc# Lxml and Libxsltbrew install libxml2brew install libxsltbrew link libxml2 --forcebrew link libxslt --force# gitbook autocoverbrew install pkg-config cairo pango libpng jpeg giflib# Install Caskbrew install caskroom/cask/brew-caskbrew tap caskroom/versions# aerial 屏保# https://github.com/JohnCoates/Aerialbrew cask install aerial# https://github.com/sindresorhus/quick-look-pluginsbrew cask install qlcolorcode qlstephen qlmarkdown quicklook-json qlprettypatch quicklook-csv betterzipql qlimagesize webpquicklook suspicious-package quicklookase qlvideobrew update &amp;&amp; brew upgrade --all &amp;&amp; brew cleanup &amp;&amp; brew prune 2.3 必备软件 之 编程语言2.3.1 ShellMAC 使用的大多命令行工具来自于 FreeBSD , 并不是来自 GNU , 所以很多命令会与常规的 linux 命令大同小异。 而本人喜欢 GNU 系软件。 Shell 脚本可参考我的笔记。 第九节如何优雅的使用 Shell_ 说到 shell, 除了要使用 bash 的 shell 之外，zsh 的 shell 也值得一试。（不过大神 kennethreitz 最喜欢 fish shell ) 1sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 2.3.1.1 Oh My Zsh2.3.2 Python笔者虽然也接触过很多语言，都是粗浅一过，但无一精通，唯一可以稍微谈谈的就是 Python 语言。 当然，安装完毕自然是可以参考一下我的 第三节 Pythonista 的工具集_ 国内外网络环境不通畅，安装与配置环境这件小事也就成了一个大事情。 我对于 Python 版本的安装 和 Python 依赖包管理有三个阶段： 入门级 新手级 熟手级 2.3.2.1 入门级最初是入门级，我配置环境和大部分的 Pythonista 一样，最初版： 面对 Python 版本的管理，干脆就是不管理，brew 安装一个 Python2 用于开发 Python2 的代码，brew install 一个 Python3 用于 Python3 的代码开发。 面对 Python 依赖包管理，干脆就是直接使用 virualenv 或者他的 wrapper 直接 venv 一个环境，然后 active 一下，接着 PIP install -r req.txt 2.3.2.2 新手级 面对 Python 版本的管理，使用 pyenv 面对 Python 依赖包管理，使用 pyenv virtualenv 出多个环境，然后切换环境就好了。 12345678910111213141516171819202122232425262728293031323334353637383940414243brew install pipenvgit clone https://github.com/yyuu/pyenv.git ~/.pyenvgit clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenvecho 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.zshrcecho 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv init -)"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.zshrc# 接着另开终端# 不喜写兼容代码，所有代码均向 3.5+ 靠拢v=3.5.2|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=3.6.0|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=2.7.11|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v# 可以先用迅雷把 官网的 Anaconda3-4.4.0-MacOSX-x86_64.sh 下载下来，然后mv Anaconda3-4.4.0-MacOSX-x86_64.sh ~/.pyenv/cache/ &amp;&amp; pyenv install anaconda3-4.4.0# 设置 Global Python 为 2.7.11, 备注：尽量不要把 Py3 设置为全局，否则由于 Homebrew 本身有一些依赖是依赖于 Py2 的，这样容易出现一些奇怪的问题。pyenv global 2.7.11pip install -i https://pypi.doubanio.com/simple requests# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hy# 创建最常用 Py3 虚拟环境pyenv virtualenv 3.5.2 py3-dailypyenv activate py3-dailypip install -i https://pypi.doubanio.com/simple requestspip install -i https://pypi.doubanio.com/simple beatutifulsoup4pip install -i https://pypi.doubanio.com/simple ipython[notebook]pip install -i https://pypi.doubanio.com/simple jupyter# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hy# 创建 Anaconda 的数据科学 AI 环境pyenv virtualenv anaconda3-4.4.0 py3-aipyenv activate anaconda3-4.4.0/envs/py3-aipyenv deactivate# 进入一个项目之后pyenv activate py3-projpip install -r requirements/local.txtpip install -r requirements/prod.txt# requirements/local.txt 与 requirements/prod.txt 依赖于 requirements/base.txt 2.3.2.3 熟手级其实，第一种入门级管理方式弊病在于，python 版本太粗糙，之前遇到一个 python3.3 的问题，python3.4 就解决了。而为了避免这种奇葩的版本差异带来的潜在风险，开发与部署一般要锁死 Python 版本。 即便是解决了入门级管理方式带来的版本管理粗糙的问题，同样的，依赖也要锁死。一个项目对应一种环境该多好 通过 PIP 的确可以用 freeze 输出为 txt 达到锁死的目的。但个人认为，这个还不够，至少要知道依赖树之类的吧？还要知道哪些东西是可以更新的吧？ 而且，就应该像 node 项目里面的 package.json 一样，把依赖什么乱七八糟的东西都放进去才好。 面对 Python 版本和依赖包管理，使用 pipenv 这代表着，只要一个就行了。 2.3.3 JavaScript 与 Node 环境nvm &amp;&amp; npm &amp;&amp; yarnnvm 主要用户管理 node 的版本，linux / mac only ,windower 最好下载 node 版本安装，记得配置环境变量。 npm 主要用户管理包，国内人喜欢使用 cnpm, 但是 cnpm 包管理比较渣，所以一般情况下选择 Yarn 配合管理 12345npm install cnpmcnpm install yarn -g# 查看下载源# yarn config get registryyarn config set registry https://registry.npm.taobao.org yarn 在使用包管理的时候会分析依赖，这对总是 BUG 不断的 node_module 简直是福音。 2.3.4 JavaJava 环境安装稍微有一丢丢蛋疼。特别是多版本管理。 1TODO: 以后补充 JAVA 环境安装 2.3.5 Ruby两年前写过几个月的 Ruby, 现在安装 Ruby 环境更多是因为 Ruby 还有一些 Gem 质量挺高的。 123curl -sSL https://get.rvm.io | bash -s stablervm install 2.3.0gem install tmuxinator 2.4 必备配置 之 dotfiles详细内容请见 yadotfiles 依照我个人的习惯，在 OhMyZsh 基础上增加了个人习惯的环境变量的配置，一些函数的封装。 比如，当我在写本文的目录中输入 todos, 就可以查看该我在写文章的时候里面挖了多少个还没有填上去的 TODO（坑）。如下 12343e383c54 (Micheal Gardner 2017-11-18 12:40:38 +0800 422) ## 0xEE TODO TO LISTae86b7cb (Micheal Gardner 2017-11-19 21:39:49 +0800 245) ### 5. TODOc0d51990 (Micheal Gardner 2017-11-22 16:42:08 +0800 552) TODO: 以后补充 JAVA 环境安装c0d51990 (Micheal Gardner 2017-11-22 16:42:08 +0800 561) 比如，当我在写本文的目录中输入 todos, 就可以查看该我在写文章的时候里面挖了多少个还没有填上去的 TODO（坑）。 详细请参考 yadotfiles 0x03 踩坑史3.1 日常类01. 时间机器无法完成备份我有定期备份的习惯，在一次备份中，意外的发现怎么备份都无法备份完毕，经过几次测试： 我首先猜测是硬盘问题，换了一块硬盘，问题依旧。 复制了几个大文件，感觉也不太像是接口接触不良的问题。 我认为可能是文件数量过多导致的问题。于是删除掉 node_module 后再次备份，备份成功。当然，这也有一定概率是误打误撞。毕竟从概率学上讲，坏掉的钟还能一天有两次时间是对的呢。 外接硬盘的时候，将网络关闭即可。 02. 下载站的软件包显示损坏有的时候并不是软件损坏，而是 macOS 的安全配置中配置关掉了未识别出的 App 在终端中开启这个选项，并在安全与隐私处点上 anywhere 即可。 1sudo spctl --master-disable 3.2 编程类01. homebrew 的与 Python 的问题在 Python 中执行下面的代码的时候总是报错： 123456789ip = socket.gethostbyname(socket.gethostname())# socket.gaierror: [Errno 8] nodename nor servname provided, or not known# 最后发现是因为设置主机名没有设置好sudo scutil --set ComputerName "newname"sudo scutil --set LocalHostName "newname"sudo scutil --set HostName "newname"dscacheutil -flushcache# 然后重启电脑即可 如果本机安装了 Homebrew 如果后面使用 PyEnv 或者 Anaconda 并且设置当前环境为默认 Python 为 Python3（不建议这么搞）, 但是如果偏偏要把默认的 Python 版本换成 Python3, 会弹出一些 pythonpath的问题，执行下面命令即可暂时屏蔽这个问题，但是没有隐患则不清楚。 1mv /usr/local/lib/python2.7/site-packages/sitecustomize.py /usr/local/lib/python2.7/site-packages/sitecustomize.py.back 02. Homebrew 安装过去的文件0xEE 参考链接 本文部分命令行安装借鉴了 dev-setup ChangeLog: 2016-02 确定大致内容 2017-06-28 重修文字，调整文章结构，Python 环境 和 Homebrew 安装环境 2017-10-05 再次重修文字，不定期更新]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>Ubuntu</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue 项目漫谈]]></title>
    <url>%2F2017%2F09%2F25%2FVueProjectTalking%2F</url>
    <content type="text"><![CDATA[0x00 前言最近升级 Vue 项目的脚手架，踩了一些关于 Webpack2 升级为 Webpack3 的版本的坑，解决了之后，顺手分享一下，我接近一年来对 Vue 项目的开发理解。 欢迎切磋。 项目使用的脚手架为 VueCli 提供的 webpack 脚手架： VueJS 2.5.2 0x01 项目结构1234567891011121314# 根文件├── Makefile 恩，其实 package.json 也能代替这个功能。├── README.md├── build #├── config # 环境变量配置├── dist # 最后输出├── extra # 个人偏好，存放最终用于打包成 IconFont 的 svg├── index.html # 可以在这里加首屏 loading, 以及其他预先准备好的样式。├── node_modules├── package.json # 依赖，开发时├── src├── static # 存放静态资源├── test└── yarn.lock 12345678910111213# 在 SRC 下面├── App.vue # CORE 组件├── api # 相关的 Web API 定义├── assets # 静态资源，对于已经压缩的，还是直接放在 Static 下面├── components├── config # 定义常量名称├── filters # 定义过滤器├── directives # 定义指令，比如 v-loading├── main.js # 用于初始化项目，注册组件等等├── mixins # 混合├── routes.js # 路由├── store # vuex 状态└── utils # 工具方法 值得一提的就是 main.js 应该要做的事情 注册全局组件和过滤器 给 Vue 实例加戏，哦，说错了，给实例加一些全局性的方法，比如 $comfirm 等对话框 $verbose $warning 等日志 完成刷新界面之后的从 localStorage 的重新赋值 注册路由切换的时候的调用的各类方法 1234567891011121314151617181920212223# components├── fed-commons 定义通用型组件，比如手风琴，tab 卡，全局的卡片，一般为了开发效率，如果是 PC 端的话，建议使用 ElementUI,ElementUI 不满足要求的时候，再考虑自己封装组件。└── views ├── auth ├── Login.vue ├── Register.vue ├── commons ├── 404.vue ├── 401.vue ├── core ├── Dashboard.vue ├── Content.vue ├── pages ├── AModule ├── AModulePart1Componennt ├── Charts01.vue ├── Map02.vue ├── Editor03.vue ├── AModulePart1.vue ├── AModulePart2.vue ├── BModule ├── BModulePart1.vue ├── BModulePart2.vue 值得一提的是，AModulePart1.vue 页面的同级 AModulePart1Componennt 下面如果有多个 ECharts 图表，实际上可以通过 mixin 来达到减少代码量的目的。 0x02 开发技巧8. 日志管理我觉得日志管理也应该是比较重要的部分，不管是调试程序，还是用于检查用户浏览器这块的错误日志，甚至是埋点。 依据具体技术栈可以考虑上个 sentry 或者 ELK 6. 登录，登录校验以及权限登录可以使用 Mixin 来混入每一个需要校验登录权限的 7. 首屏 Loading这个可以放在 index.html 里面 4. 路由管理与嵌套路由路由管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344const routes = [ &#123; path: '/login', component: Login // 似乎路由中的 component 至少要有一个不是懒加载的，否则会出奇怪的 BUG &#125;, &#123; path: '/', redirect: 'AModule/APage' &#125;, &#123; path: '/', meta: &#123; requiresAuth: true // 通过这个用来区分网页是否需要注册用户登录 &#125;, component: Dashboard, children: [ &#123; path: 'AModule', component: AModule.vue, name: 'AModule', meta: &#123; requiresAuth: true &#125;, children: [ &#123; path: 'AModulePart1', name: 'AModulePart1', component: () =&gt; import('./components/views/pages/AModule') &#125;, &#123; path: 'AModulePart2', name: 'AModulePart2', component: () =&gt; import('./components/views/pages/AModule') &#125;, ] &#125;, ] &#125;, &#123; // not found handler path: '*', component: NotFoundView &#125;] 嵌套路由有什么优点？ 使得子路由里的页面可以复用父级路由的页面的组件 减少手动硬编码 meta 和 props 的代码量 便于定制面包屑组件 其他 0x03 构建技巧3.1 离线 IconFont经常需要离线调试网页，顺手写了这个脚本。 之前在研究某个网站的反爬机制的时候发现时动态生成 iconfont, 然后通过 unicode 码来实现数字的显示，从而让爬虫小白无法爬取。研究了一下他们的 iconfont, 知道了 font-carrier, 然后调用 node 脚本打包字体文件，并在这个过程中自动生成对应的 iconfont.css 最后的结果就是，当我放一个文件到 svg 文件夹下面的时候，比如 bank.svg , 我执行一下脚本，生成对应的字体文件，在 html 里面编写脚本 1&lt;span class=&quot;iconfont iconfont-bank&quot; &gt;&lt;/span&gt; 然后对应图标就呈现出来了。 3.2 Webpack 构建工具日常开发用的是 VueCli, 配置还是非常人性化的。开箱即用。 开发环境与部署环境VueCLI 内置了变量的管理，你可以定义 config/dev.js 1234module.exports = merge(prodEnv, &#123; NODE_ENV: '"development"', API_ROOT: '"http://dev-data.twocucao.xyz"'&#125;); 其实，开发的环境用一组变量是不行的。比如，开发的人分为纯前端，纯后端，我这样的前后都会一些的人，每个对于环境的配置都是不太一样的。 对于前端 Windowser 直接执行 npm run dev 对接到局域网服务器 对于单个人同时调试后端和前端的时候，一般要把 Web API 对应到本地的机器上。可是使用环境便来配置不同的 DEBUG_MODE=True npm run dev 123456789101112131415// dev.js 应该如下var merge = require('webpack-merge');var prodEnv = require('./prod.env');if (process.env.DEBUG_MODE === 'True')&#123; module.exports = merge(prodEnv, &#123; NODE_ENV: '"development"', API_ROOT: '"http://local-dev-data.twocucao.xyz"' &#125;);&#125;else&#123; module.exports = merge(prodEnv, &#123; NODE_ENV: '"development"', API_ROOT: '"http://dev-data.twocucao.xyz"' &#125;);&#125; DLL 打包大约在半年前，开发过程中突然在使用 ECharts 后，仅仅不到 10M 大小的项目居然开发 build 的时间需要 5MIN, 打包出来的文件超级大。居然接近了 100 多 M 震惊之余，差点准备写一篇骗点击量的文章：看完震惊了！！前端和后端男程序员都无法忍受的大小！, 然后文章内就介绍 Webpack 打包文件居然没有避免重复引入依赖库导致打包文件太大提出抗议。 回到主题，使用 npm run analyze 发现问题出现在 ECharts 上， 每一个图表组件都是依赖于 ECharts, 而每一个组件都包含了一个完整的 ECharts 库的大小。 于是，我一边吐槽 webpack 考虑不周，另一方面寻找解决方案。最后找到了 DLL 方案 这个方案的原理大致是： 编写独立的脚本，把几个需要复用的库一个配置文件 (manifest.json), 以及打包库到一个 JS 文件中。 然后从 index.html 引入这个 JS 文件。 接着在 webpack 配置中使之每次引入一个库的时候，避免重复引入。 但这不应该是 Webpack 本身就应该做的吗？为嘛还要配置，还要不伦不类的生成一个配置文件和一个 JS 文件，再从 index.html 里面导入？ 当然，Webpack 生态还是很丰富的，后来出来了一个 https://github.com/asfktz/autodll-webpack-plugin 尝试了之后。感觉很赞。 123456789101112131415161718192021222324252627// windows 系统不兼容，暂时去掉new AutoDllPlugin(&#123; inject: true, // will inject the DLL bundles to index.html filename: '[name]_[hash].js', path: './static/js/', entry: &#123; vendor: [ 'mapbox-gl', 'd3', 'echarts', 'echarts-gl', 'leaflet', 'axios', 'vue', 'vue-router', 'vuex' ] &#125;, plugins: [ new webpack.optimize.UglifyJsPlugin(&#123; compress: &#123; comparisons: false // don't optimize comparisons &#125;, sourceMap: true &#125;), ]&#125;) 可惜在 mac 上一切安好，Windows 上晴天霹雳，debug 了一下，发现是这个库的一个依赖库对 windows 的路径处理好像还有点小问题。而公司的前端小伙伴是 Windowser, 只好作罢。 Macer 可以先用试试，至于 Windowser, 那就去这个 ISSUE 下面催催作者吧… 哈哈哈 update: 现在 windows 已经可以用了。 0x03 代码质量工程管理1. 语义化与可读性2. 提取公共逻辑（通过 Service, Mixin 来）3. CSS 管理在项目中，我采用 SCSS 来管理 CSS 代码， 过去的时候有两种 css 的代码命名方法 第一种，我管他叫做配置式写法，通过将 CSS 语法的几个片段转化成名称，从而实现快速配置出效果的的 CSS 123456789101112131415.fl &#123; float: left&#125;.fr &#123; float: right&#125;.mr10 &#123; margin-right: 10px&#125;.pb10 &#123; padding-bottom: 10px&#125;.... 这种写法对于简单页面来说确实也是可以使用的。缺点就是当页面变得复杂一些的时候，则比较难控制这种短小精捍（不直观）的变量。比如 12345678.tmd01&#123; padding-bottom: 10px font-size: 16px; position: relative; top: 0; color: #2d3c48; line-height: 1.6;&#125; 请脑补一下我的黄人问号脸 当然，如果用得好的话，自然是 OK, 如果用不好的话， 后来进入了嵌套写法时代（感谢伟大的 Rails 社区出的 SASS）, 下面的语法都是 SCSS. 第二种写法就变成了这样 1234567891011121314.actions &#123; .card_wrapper &#123; .card &#123; .title &#123; &#125; .content &#123; .list &#123; .fa &#123; &#125; &#125; &#125; &#125; &#125;&#125; 外加变量和 mixin 以及函数的话，基本上就可以完成代码的组织了。 这种写法倒是比原来不知道高到哪里去了，但问题依旧存在，比如 title,content 这些玩意太多，完完全全的看不懂。更加糟糕的事情是，有的小伙伴直接是乱用嵌套，也不用伪类和伪选择器，从而达到单页面调出来小伙比较快，但因为代码不能重用，调多个页面的时候速度巨慢无比。 123456789101112131415161718.apage &#123; bbizlogic &#123; .actions &#123; .card_wrapper &#123; .card &#123; .title &#123; &#125; .content &#123; .list &#123; .fa &#123; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 我本人推荐（其实我是写 Python Web 后端的，逃… ) 代码风格比较倾向于 BEM 命名，关于 BEM 的介绍，请参考简单心理团队的教程。 https://jiandanxinli.github.io/2016-08-11.html https://juejin.im/post/58d0e5caa22b9d00643e8b51 然而，最好的方式，就是读一个非常使用 SCSS 来组织项目的 CSS 代码的成熟项目。 我推荐两个： BOOTSTRAP V4: Bootstrap V4 使用 SCSS 来写 ELEMENT UI: 饿了么的团队出的，前段时间从 v1 版本升级到 v2 版本，发现网站大部分样式都没有出现大变动，在这里给个赞。 0. 先从整体上设计好骨架接着才是 HTML, 然后才是 CSS 现在前端入行的人越来越多，很多的新手前端 er 会用比较快的思维来编写，这就导致代码质量奇差无比。 哎，我看看，面粉加多了，我加点水，水加多了，我再加点面粉。 哎，我看看，面粉又加多了，我加点水，水加多了，我再加点面粉。 哎，我看看，面粉又加多了，我加点水，水加多了，我再加点面粉。 哎，我看看，面粉又加多了，我加点水，水加多了，我再加点面粉。 哎，我看看，面粉又加多了，我加点水，水加多了，我再加点面粉。 当设计出来的网页本身的 HTML 写的就很混乱，CSS 能写的好在哪里呢？ 命名都很混乱，遑论代码可维护性？ 可以多去参考一些成熟的项目的 CSS 是怎么命名的呀，HTML 是怎么设计的呀 1. Scoped 的滥用我印象中，有个小伙伴把一个比较大的 CSS 库多次 import 到被 Scoped 的组件中，于是开发时猛然发现 head 处多了大量的 style 标签，除了 css 选择器后面随机的属性 hash, 文件内容都一样。 公共组件往往可以通过嵌套和加前缀的方式来防止污染。如果 scoped 的属性里面有成吨的 style, 慎用 import. 还有小伙伴喜欢在很多七七八八的组件各种 import scss. 其实对于中小型项目，完全可以直接全局一个文件 style 即可。 我现在的做法，是直接在 src 的上方直接用 gulp 搭建一个只用来编译 SCSS 到 CSS 的项目，每次编译后输出到页面里面。 如果项目是小项目，建议直接在 app.vue 里面 import pages 1234567├── common├── fonts├── global.scss├── index.scss├── mixins├── pages.scss└── reset.scss 2. 保持代码的通用性一般，当同一段逻辑出现三次的时候，是要停下来重构一下的，这样的话，就可以节省很多时间。 套用在 CSS 的样式上也是如此。 0x04 Tmux 和 Tmuxnator 打造工作流具体参考我的文章 用 Tmux 和 Tmuxnator 打造工作流 ChangeLog: 2017-09-25 初始化本文]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>VueJS</tag>
        <tag>全栈开发</tag>
        <tag>项目经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VueJS 文档阅读笔记]]></title>
    <url>%2F2017%2F09%2F15%2FReadingVueDocuments%2F</url>
    <content type="text"><![CDATA[0x01 Essential1.1 The Vue Instance当 Vue 实例被创建时，添加所有在 Data 对象中的属性到 Reactivity System 中。 而创建之后添加赋值新属性，则不 Reactive 而实例被创建之时，会自带前缀为 $ 的一系列属性和方法 1.1.1 内置方法和属性Instance Propertiesvm.$datavm.$propsvm.$elvm.$optionsvm.$parentvm.$rootvm.$childrenvm.$slotsvm.$scopedSlotsvm.$refsvm.$isServervm.$attrsvm.$listeners Instance Methods / Datavm.$watchvm.$setvm.$delete Instance Methods / Eventsvm.$onvm.$oncevm.$offvm.$emit Instance Methods / Lifecyclevm.$mountvm.$forceUpdatevm.$nextTickvm.$destroy 1.1.2 生命周期 1.2 Template SyntaxVueJS 编译 模板为 VirtualDOM render 函数，如果对 VirtualDom 非常熟悉的话，则可以使用 1.2.1 插值123456789101112# text&#123;&#123; msg &#125;&#125;&lt;span v-once&gt; &#123;&#123; msg &#125;&#125; &lt;span&gt;# raw html&lt;div v-html=&quot;rawHTML&quot;&gt;&lt;/div&gt;# attributes&lt;div v-bind:id=&quot;dynamicID&quot;&gt;&lt;/div&gt;# JS Expressions&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &apos;YES&apos; : &apos;NO&apos; &#125;&#125;&#123;&#123; message.split(&apos;&apos;).reverse().join(&apos;&apos;) &#125;&#125;&lt;div v-bind:id=&quot;&apos;list-&apos; + id&quot;&gt;&lt;/div&gt; 1.2.2 指令 v-bind -&gt; : v-on -&gt; @ v-on:submit.prevent=”onSubmit” 1.3 Computed Properties and Watchers 当使用 Computed 的时候，一旦其依赖的 reactive 的 data 发生变化之后，则其值发生变化。 其实，可以在模板中调用方法，但只能在项目中。 1.4 Class and Style Bindings1.4.1 Object 语法123&lt;div class=&quot;static&quot; :class=&quot;&#123; active: isActive, &apos;text-danger&apos;: hasError &#125;&quot;&gt;&lt;/div&gt; 1.4.2 Array 语法1&lt;div v-bind:class=&quot;[isActive ? activeClass : &apos;&apos;, errorClass]&quot;&gt;&lt;/div&gt; 1.4.3 组件123&lt;my-component class=&quot;baz boo&quot;&gt;&lt;/my-component&gt;&lt;p class=&quot;origin baz boo&quot;&gt; 1.5 Conditional Rendering1234567891011121314151617&lt;h1 v-if=&quot;ok&quot;&gt;Yes&lt;/h1&gt;&lt;h1 v-if=&quot;ok&quot;&gt;Yes&lt;/h1&gt;&lt;h1 v-else&gt;No&lt;/h1&gt;&lt;div v-if=&quot;type === &apos;A&apos;&quot;&gt; A&lt;/div&gt;&lt;div v-else-if=&quot;type === &apos;B&apos;&quot;&gt; B&lt;/div&gt;&lt;div v-else-if=&quot;type === &apos;C&apos;&quot;&gt; C&lt;/div&gt;&lt;div v-else&gt; Not A/B/C&lt;/div&gt; v-if 是否 v-for 优先级高于 v-if 1.6 List Rendering对于数组 12345&lt;ul id=&quot;example-2&quot;&gt; &lt;li v-for=&quot;(item, index) in items&quot;&gt; &#123;&#123; parentMessage &#125;&#125; - &#123;&#123; index &#125;&#125; - &#123;&#123; item.message &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 对于对象 12345&lt;ul id=&quot;example-2&quot;&gt; &lt;li v-for=&quot;(item, index) in items&quot;&gt; &#123;&#123; parentMessage &#125;&#125; - &#123;&#123; index &#125;&#125; - &#123;&#123; item.message &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 1.6.1 ARRAY 修改检测方法 push() pop() shift() unshift() splice() sort() reverse() 取代数组filter 警告12345678910111213141516171819直接通过 index 对数组进行修改不应该vm.items[indexOfItem] = newValue应该// Vue.setVue.set(example1.items, indexOfItem, newValue)// Array.prototype.spliceexample1.items.splice(indexOfItem, 1, newValue)修改 length不该 vm.items.length = newLength应该 example1.items.splice(newLength) 猜测背后可能是因为这种方式是无法监测设置 1.6.2 Object 修改检测警告123js 无法直接提供对this.$set(this.userProfile, 'age', 27) 1.7 Event Handling1.7.1 Listening to Events1234&lt;div id="example-1"&gt; &lt;button v-on:click="counter += 1"&gt;Add 1&lt;/button&gt; &lt;p&gt;The button above has been clicked &#123;&#123; counter &#125;&#125; times.&lt;/p&gt;&lt;/div&gt; PS: 注意，前面 v-on v-bind 所有的绑定可以绑在方法上，也可以直接填单行表达式。可以提高可阅读性 1.7.2 Method Event Handlers可以绑定方法 1.7.3 Methods in Inline Handlers可以绑定方法加参数，配合 for / if 1.7.4 Event Modifiers事件修饰符 12345.stop.prevent.capture.self.once 1234567891011121314&lt;!-- the click event's propagation will be stopped --&gt;&lt;a v-on:click.stop="doThis"&gt;&lt;/a&gt;&lt;!-- the submit event will no longer reload the page --&gt;&lt;form v-on:submit.prevent="onSubmit"&gt;&lt;/form&gt;&lt;!-- modifiers can be chained --&gt;&lt;a v-on:click.stop.prevent="doThat"&gt;&lt;/a&gt;&lt;!-- just the modifier --&gt;&lt;form v-on:submit.prevent&gt;&lt;/form&gt;&lt;!-- use capture mode when adding the event listener --&gt;&lt;!-- i.e. an event targeting an inner element is handled here before being handled by that element --&gt;&lt;div v-on:click.capture="doThis"&gt;...&lt;/div&gt;&lt;!-- only trigger handler if event.target is the element itself --&gt;&lt;!-- i.e. not from a child element --&gt;&lt;div v-on:click.self="doThat"&gt;...&lt;/div&gt; 1.7.5 Key Modifiers123456789.enter.tab.delete (captures both “Delete” and “Backspace” keys).esc.space.up.down.left.right 1234&lt;!-- same as above --&gt;&lt;input v-on:keyup.enter="submit"&gt;&lt;!-- also works for shorthand --&gt;&lt;input @keyup.enter="submit"&gt; 1.7.6 System Modifier Keys键盘 1234.ctrl.alt.shift.meta 1234&lt;!-- Alt + C --&gt;&lt;input @keyup.alt.67=&quot;clear&quot;&gt;&lt;!-- Ctrl + Click --&gt;&lt;div @click.ctrl=&quot;doSomething&quot;&gt;Do something&lt;/div&gt; 鼠标 123.left.right.middle 1.7.7 Why Listeners in HTML?在以往的开发中，直接写在 html 的 onclick 是很糟糕的方式，因为这违反了局部变量准则。将 onclick 变量提升为整个页面很容易导致，页面内部组织混乱。 而 v-on 则仅执行 viewmodel 的方法，不会绑定到其他方法里。 1.8 Form Input Bindingshttps://vuejs.org/v2/guide/forms.html 对于每个 Form 空间，可以进行一定的封装。 比如拖拽上传啦，比如 RadioGroup 啦等等。通过封装，可以进行相关的分析。 1.9 ComponentsUsing ComponentsGlobal RegistrationLocal RegistrationDOM Template Parsing Caveatsdata Must Be a FunctionComposing ComponentsPropsPassing Data with PropscamelCase vs. kebab-caseDynamic PropsLiteral vs. DynamicOne-Way Data FlowProp ValidationNon-Prop AttributesReplacing/Merging with Existing AttributesCustom EventsUsing v-on with Custom EventsBinding Native Events to Components.sync ModifierForm Input Components using Custom EventsCustomizing Component v-modelNon Parent-Child CommunicationContent Distribution with SlotsCompilation ScopeSingle SlotNamed SlotsScoped SlotsDynamic Componentskeep-aliveMiscAuthoring Reusable ComponentsChild Component RefsAsync ComponentsAdvanced Async ComponentsComponent Naming ConventionsRecursive ComponentsCircular References Between ComponentsInline TemplatesX-TemplatesCheap Static Components with v-once 总结组件化是 Vue 模块化组织前端网页的方式。 Vue 的组件化，将模板，JavaScript 与样式放在一起。出于代码的复用性： 组件化可以给组件子组件们组织起来，起一个阅读性更好的名称，从而使得编写 Vue 组件更加语义化。 如果模板是常用的组件，比如手风琴控件，Menu 控件，sidebar 控件 Vue 通过组件来组织代码，但糟糕的是并不是一切都可以被组件化 0x02 Transitions &amp; Animation2.1 Event Handling2.2 Event Handling0x03 Reusability &amp; Composition0x04 Tooling0x05 Scaling Up0x06 Internals0x07 Vue 番外篇下面的内容从 Vue 作者的知乎 Live 上取来。 阅读源码的建议http://hcysun.me/2017/03/03/Vue 源码学习 / 框架背后的要解决的原理组件为基本单元 页面 -&gt;应用（模块，组件树（偏展示）） 接入型 container 展示型 交互型 比如各类加强版的表单组件，通常强调复用 功能型 比如 &lt;router-view&gt;，&lt;transition&gt;，作为一种扩展、抽象机制存在。 view = render(state) 命令式 (jquery) 声明式 Virtual Dom变化侦测和渲染机制push pull vue 混合式 状态管理0xEE TODO TO LIST ChangeLog: 2017-09-15 初始化本文]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>VueJS</tag>
        <tag>文档阅读</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React CheatSheet]]></title>
    <url>%2F2017%2F07%2F26%2FReactCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00. 前言 备注：由于目前没有上 React 的打算，本文暂时太监 之前一直使用 VueJS 进行开发，心血来潮想换换口味，于是就借着自己的一个开源的项目尝试一下 ReactJS , 代码分为两部分，如下： 前台系统（支持 SSR) YaReactBlog 后台系统 YaReactAdmin 12TODO: 本文目录 前端、单页与 React 开发 官网的 Tutorial / Guide 要点 Dva 下使用 React JS 的要点 0x00. 前端、单页与 React 开发0.1. 前端前端开发，是最近几年才出现的独立工种。 在我的印象中，以前的人很少会区分前端和后端，现在的前端的职责往往是由后端的人顺手做掉的。当然，这种界面一般情况下都比较丑。 后来，随着浏览器的功能越来越强大，性能越来越好，用户对于界面要求也就越来越高。甚至到后来，对于用户界面的操作的复杂程度要求也越来越高。 传统的后端渲染 Template + 简单的 Ajax 不能满足要求了。 要界面，要交互，要复杂 于是便出现了单页应用。 0.2. 单页单页完全可以当做一个性能不是很强的，运行在浏览器中的，使用 HTML CSS JS 来编写的小型客户端。 写单页和写客户端基本一致的情况下，于是在这种情况下，前端开发在使用单页后，直接可以 Mock 数据，接着编写界面，接着调通页面的状态和操作，最后发布。 0.3. ReactJS为什么选用 ReactJS 呢？ 个人认为，框架是用于改善代码组织的一种约束。 不管是 Web 应用开发的早期的 HTML in PHP OR PHP in HTML, 还是中期的 MVC MTV, 还是后来的 富 AJAX 操作，还是现在的 SPA, 出现的各种框架无非就是为了解决代码组织的问题。 对后端而言，后端 WEB 框架的设计，都是为了单个模块职责过重而出现的一种解决方案： HTML IN PHP 拼接代码简单暴力，可是如果拼接太多，每个文件就很职责重，代码阅读性差，不方便调试，就显得很杂乱。 PHP in HTML 相比上一个解决方案好很多。可是，嵌入过多 PHP 代码，代码阅读性差，不方便调试，则会显得比较混乱。 MVC 与 MTV 把渲染的变量独立出来放到 Controller 中，然后把需要渲染的 HTML 模板放到 Template 中，并且在 Template 中来完成模板的拼接。最后调用 Render 进行渲染。是不是这样问题就解决了呢？不是，如果把业务逻辑放在 Model 层，则 Model 职责过重。那就必须要添加一个 Serivce 层来封装业务逻辑。是不是封装了一个 如果业务逻辑简单到令人发指，HTML IN PHP 可以给人最大的灵活性。 尝试一下新技术。保持对技术的敏感性。 React 是 FB 出的一套前端框架。大厂支持，不会轻易太监掉。 写了一段时间 VueJS 换换口味。 当我们讨论一个框架的时候，除了基本的框架之外还必须要有大量的社区资源，那么对 React 而言，除了 ReactJS 之外，还有什么？ 123456789101112131415161718192021222324后台系统 - ant.design打包构建 - webpack路由和状态管理 - react-router - react-router-redux - redux - redux-saga为了更好的管理路由和状态，还是使用 dva 来管理比较好。 - [dva](https://github.com/dvajs/dva) - [dva-cli](https://github.com/dvajs/dva-cli)开发构建工具 - [roadhog](https://github.com/sorrycc/roadhog) 0x01. 官网的 Tutorial / Guide官网的要点 0x02. 在 dva 下，编写 React 组件的正确姿势编写 React 的时候，我选用了 dva 框架配合 ReactJS 来编写单页。 参考 FB 的这篇教程后，梳理了我编写组件的步骤 https://facebook.github.io/react/docs/thinking-in-react.html : 先构思出原型 （或者拿到 UI 图） Mock 出假数据 分解页面 OR 组件为 组件树 编写静态组件树 确定最小表达 UI （加上满足要求的样式） 确定什么时候需要什么状态（网络请求，键盘输入，位置变化等等） 收尾美化 在发现问题的时候进行优化 0x03. 在 dva 下，编写 React 组件的正确姿势 ChangeLog: 2017-07-17 重修文字]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>React</tag>
        <tag>Ant Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据科学的常识笔记]]></title>
    <url>%2F2017%2F07%2F17%2F%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%9A%84%E5%B8%B8%E8%AF%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[0x00 前言2017 年 07 月，为了解统计学和机器学习的基本常识，开了这篇文章。 当然，仅仅是为了了解，所以也就写的随性（不严谨）一些，排版什么的也都详细推敲。想到哪里就记录到哪里。 0x01 数据科学的含义与内容0.1 WHAT? To gain insights into data through computation, statistics , and visualization. Josh Blumenstock 认为 数据科学家就是比计算机科学家多点统计技术，比统计学家多点计算机技术。 Shlomo Aragmon 认为 数据科学家 = 统计学家 + 程序员 + 教练 + 讲故事者 + 艺术家 一些准则 多数据源 懂得数据如何被采集 对数据进行权重 使用统计模型 理解相关性 像 Bayesian 一样思考，像 frequentist 一样检验 良好的沟通能力（代表什么，如何可视化，检验，理解结论） 一些挑战 数据量大 高维诅咒 数据缺失 需要避免过度拟合 (test data vs. training data) Data Science 涉及到哪些领域呢？ Data Management Data Mining Machine Learning Business Intelligence Statistics Decision Making Theory Story Telling Perception Human Cognition 0.2 WHY?海量数据的时代 0.3 HOW? ASK an interesting question. 目标是什么？如果拿到数据可以预测或者估计什么？ GET the data. 数据如何抽样？那些数据是相关的？ EXPLORE the data. 可视化数据，有异常吗？有模式吗？ MODEL the data. 构建模型，拟合模型，检验模型。 COMMUNICATE and VISUALIZE the results 我们学到了什么？结果有意义吗？ 0.4 本文目录 统计学与数据分析 信息可视化 集中趋势的量度 分散性与变异的量度 概率计算 离散概率分布 排列与组合 几何分布、二项分布、泊松分布 正态分布 统计抽样 总体和样本的估计 置信区间 假设检验的运用 x2 分布 相关与回归 数据挖掘基本扫盲 推荐系统入门 隐式评价和基于物品的过滤算法 分类与分类进阶 朴素贝叶斯 朴素贝叶斯算法和非结构化文本 聚类 机器学习 分类与回归 交差校验 降维 支持向量机 决策树 &amp; 随机森林 Bagging &amp; Boosting 聚类与文本 贝叶斯思维 &amp; Naive Bayes 文本分析：LDA&amp;Topic Modeling 聚类 深度学习 自然语言 NLP 中文分词 新词发现 0x02 统计学与数据分析2.1 信息可视化建议直接阅读 AntV 的可视化基础 https://antv.alipay.com/vis/doc/chart/index.html 2.2 集中趋势的量度 目的：找出能够反映集中趋势的一个数值 PS: 可以用分布图看它的均值和平均数是否落在集中趋势，数据向右偏斜，均值位于中位数右侧 均值 （均值对于抽样数据更加稳定，但是如果村里一个杨千万九个穷光蛋，则个个都是杨百万） 中位数 众数 2.3 分散性与变异的量度 目的：仅有均值，中位数，众数是不够的，还需要距和差 全距：MAX（上界） - MIN（下界） 按照四分位书的切分方式： 下界 - 下四分位数目 (Q1) - 中位数 - 上四分位数 - 上界 四分位距：上四分位数 - 下四分位数 （当然，可以使用箱线图进行绘制，从而判断出数据集中的地方） 百分位距：在统计的时候，往往需要避免极值对数据的影响 方差：量度数据分散性 标准差：典型值与均值的距离，体现了数值的变异程度。即加入有一批数据的标准差为 3cm, 代表着平均而言，这些数值与均值的距离为 3cm 0x03 数据挖掘本节是『面向程序员的挖掘指南』的笔记。 数据挖掘是深一步的分析统计。 本书所讲内容就是一个核心： 给用户推荐物品 内容就是： 第一章和第二章均为依据用户对物品的评价（显示评价以及隐式评价）来做出相关推荐。 第三章为物品本身的特点进行分类 第四章直到最后一章则是分类的详细讨论以及聚类分析。 基于用户的协同过滤算法用户与用户之间相似 基本的距离算法 擦擦擦，LaTeX 公式 居然不能用… 曼哈顿距离 如果在 n 维坐标上，即绝对值。 欧几里得距离 就是其实就是 n 维勾股定理。 曼哈顿距离和欧几里得距离在判断 同样是 n 维的数据是完全 OK 的。即总量为 m 部电影的情况下，k 个人同样评价了 n 部电影，比较容易算出距离。 但，n 纬和比他更小的纬度算出的距离，似乎并不应该相等。 如何处理这些缺失的数据呢？如果是我的话，会设定一个默认值吧。（半值，均值） 闵科夫斯基距离 1TODO: 以后补上公式 r 值越大，单个维度的差值大小会对整体距离有更大的影响。 皮尔森相关系数 用户也分为好几种，比如说： 用户 1: 好的打分 5, 差的打分 3用户 2: 好的打分 5, 差的打分 1用户 3: 要么 5, 要么 1 余弦相似度 如果数据存在“分数膨胀”问题，就使用皮尔逊相关系数。如果数据比较“密集”，变量之间基本都存在公有值，且这些距离数据是非常重要的，那就使用欧几里得或曼哈顿距离。如果数据是稀疏的，则使用余弦相似度。 K 最邻近算法 隐式评价和基于物品的过滤算法显式评价：豆瓣的五星，用户的评论 显式评价可能存在下面几个问题： 懒得评价 会出于面子，合群，偏见撒谎。 懒得追加评价一般数量少，假如买的东西一个月后坏掉了，则不用。 账号共享带来的问题。 买东西就是有问题才调出来判断，其他的情况下懒得评价。 隐式评价：通过观察可得。通常需要工程师针对客户端和浏览器端进行埋点。比如，买过，还买过，点击情趣用品多次。 网页方面：页面点击、停留时间、重复访问次数、引用率、观看视频的次数； 音乐播放器：播放的曲目、跳过的曲目、播放次数； 然而，越精准的判断越消耗性能。 扩展性：当用户数量大幅度上升的时候，计算量就上来了。千万用户其中一个用户和其他用户进行有一次运算的话，计算量就相当大了。 稀疏性：物品数量远大于用户数量，而千万级用户仅仅对百万本书中几十本评价， 书中说，可以考虑基于物品的协同过滤，其实可以考虑，先给用户和书划分类型，从而使得计算量下来。 计算标签和标签之间的相似度，这样可以使得成本大幅度下降。 基于物品的协同过滤算法 修正的余弦相似度 是一种基于模型的协同过滤算法。我们前面提过，这种算法的优势之一是扩展性好，对于大数据量而言，运算速度快、占用内存少。 用户的评价标准是不同的，比如喜欢一个歌手时有些人会打 4 分，有些打 5 分；不喜欢时有人会打 3 分，有些则会只给 1 分。修正的余弦相似度计算时会将用户对物品的评分减去用户所有评分的均值，从而解决这个问题。 Slope One 算法 训练集和测试集十折交叉验证 将数据集随机分割成十个等份，每次用 9 份数据做训练集，1 份数据做测试集，如此迭代 10 次。 n 折交叉验证 评估分类器 混淆矩阵 （其实就是交叉表的统计学说法） Kappa 指标 优化邻近算法 kNN 算法 分类方法0x03 机器学习0x04 深度学习0x05 自然语言 NLP0xEE 链接 面向程序员的数据挖掘指南 ChangeLog: 2017-07-17 重修文字 2017-10-12 增加数据挖掘模块]]></content>
      <categories>
        <category>数据科学</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数学概念</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>自然语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Geoprocessing With Python]]></title>
    <url>%2F2017%2F07%2F11%2FGeoProcessingWithPython%2F</url>
    <content type="text"><![CDATA[0x00. 前言16 年 12 月研究 GIS 相关资料用于处理 GIS 相关问题，完成基本 GIS 功能。最新需要进阶相关内容用于更好的处理相关数据。 书籍： Geoprocessing With Python PostGIS In Action 2rd 框架： 前端 Leaflets D3 后端 GeoDjango 其他零零碎碎的资料 特此记录。 本文目录 基本概念 Vertor VS Raster Vertor 相关类型与坐标系 Raster 相关类型 其他类型 GIS 开发的生态圈以及常用技术栈 Vertor 分析 Raster 分析 Vertor 与 Raster 0x01 基本概念1.1. Vertor VS Raster Vector : 基本单元为 Point : points, lines, and polygons 以及其组合，适用于矢量图，地形边界，路线等。 Raster : 基本单元为 Pixel : 2d/3d 包含数值的数组，适用于连续性数据，不仅仅适用于图片。 1.2. Vertor 相关类型与坐标系1.2.1. 国内常见的几种坐标系国内由于特殊的国情，国际标准也要向国家标准靠齐。比如各个不同的坐标系上坐标的换算。 我们都知道一个坐标 (x,y) 可以表示为经纬度，甚至放在坐标系上，我们可以这么运算两点 (x1,y1) , (x2,y2) 之间的距离 12# z 表示比例系数distance = math.sqrt((x1-x2) ** 2 + (y1-y2) ** 2) * z 在近距离的时候的确是可以这么做的比如计算村里小芳和隔壁老王家的距离。当距离过大的时候，比如计算上海 A 区和 B 区的两个写字楼的距离的时候，则有相当大的误差。 那么问题来了： 挖掘技术哪家强 啊不是，是国内有哪些常用坐标标准呢？又是如何计算的呢？ GPS WGS-84 国际标准（原始） GCJ-02 国内标准（原始数据混淆） 其他坐标比如 BD-09（原始数据混淆再混淆） 对于小公司而言，我们是没有任何方法来通过 BD-09 以及 GCJ-02 这种坐标系进行运算的： 因为坐标点非线性偏移核心计算方法掌握在 GCJ-02 / BD-09 的公司里面，比如 Google 中国，高德地图，百度地图，腾讯地图。所以，为了研究，则必须要有能够对坐标进行运算的算法, 那这个东西有没有呢？答案是肯定的，因为国外使用的 WGS-84 标准，并且，计算坐标的算法早就开源。 那么，我们的思路就确定下来了。 各种地图的经纬度坐标比如 BD-09 或 GCJ-02 标转换成 WGS-84 坐标。 使用开源 GIS 软件进行对 WGS-84 进行运算。 感谢诸多在 GIS 运算上开源的中国先辈，我们轻而易举的获取到了坐标之间相互转化的方法： https://github.com/wandergis/coordTransform_py 1.2.2. 形状坐标系，我们可以简单的理解为一个笛卡尔坐标系（虽然这么说很不准确，但已经足够形象了） 于是对于二维的数据，GIS 的分析就可以理解为对于点，线段，多边形自身以及他们之间的关系的分析。 1.3. Raster 相关类型raster 的 digital elevation model(DEM), 即每一个像素值包含一个 elevation value GDAL/OGR 0x02. Vertor 分析0x03. Raster 分析3.1. 教程3.2. 教程3.3. 教程笔记0x04. Vertor 与 Raster基础版本 Point LineString Polygon MultiPoint MultiLineString MultiPolygon 中级概念 Raster / Tile (Bands 是什么鬼） PostGIS MetaTable spatial_ref_sys geography_columns geometry_columns raster_columns raster_overviews PostGIS 常用函数12345678910111213141516171819202122ST_AsText(geom) 用于查看 WKTST_GeometryType(geometry) returns the type of the geometryST_NDims(geometry) returns the number of dimensions of the geometryST_SRID(geometry) returns the spatial reference identifier number of the geometryST_X(geometry) returns the X ordinate , 如果作用在 Point 上，则返回经度ST_Y(geometry) returns the Y ordinate , 如果作用在 Point 上，则返回纬度ST_Length(geometry) returns the length of the linestringST_StartPoint(geometry) returns the first coordinate as a pointST_EndPoint(geometry) returns the last coordinate as a pointST_NPoints(geometry) returns the number of coordinates in the linestringST_Area(geometry) returns the area of the polygonsST_NRings(geometry) returns the number of rings (usually 1, more of there are holes)ST_ExteriorRing(geometry) returns the outer ring as a linestringST_InteriorRingN(geometry,n) returns a specified interior ring as a linestringST_Perimeter(geometry) returns the length of all the ringsST_NumGeometries(geometry) returns the number of parts in the collectionST_GeometryN(geometry,n) returns the specified partST_Area(geometry) returns the total area of all polygonal partsST_Length(geometry) returns the total length of all linear parts Snippets12345-- 合并多个区域并返回 multipolyUPDATE areas as ASET &quot;Boundary&quot; = ST_Multi(st_union(ARRAY(SELECT geom FROM county_boundary_region WHERE gid in ( &apos;foo_id&apos;,&apos;bar_id)&apos;))))WHERE A.&quot;ID&quot; = &apos;xxxxxx&apos; 0xEE 参考链接 http://gis.stackexchange.com/questions/6681/what-are-the-pros-and-cons-of-postgis-geography-and-geometry-types Geo Processing with Python ChangeLog: 2017-07-11 重修文字]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据可视化</tag>
        <tag>Django</tag>
        <tag>GIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReThinking In Python]]></title>
    <url>%2F2017%2F07%2F04%2FRethinkingInPython%2F</url>
    <content type="text"><![CDATA[0x00 前言本文诞生于利用 Topic Reading 方法读 Python 和 JavaScript 若干本技术书籍这个过程中结合自己的开发常见场景记录下来的一些笔记。 0x01 Python 胡论1.1 Python 的独一无二性是要用一门编程语言无非是两种原因： 这门技术很火，能挣钱 写起来很舒服，开发效率高 这也是我在涉猎了很多编程语言为什么选择了 Python 和 TypeScript 作为自己的主要技能树。 Python 具备这两点，TS （更加准确的说是 JavaScript）具备前一点。 Python 写起来真的特别舒服，语法简洁，第三方库丰富，而且也比较火。 有什么东西比，写代码效率高、生态圈好还重要了。 生态圈好，比如 Web 开发用 Django/Flask 数据抓取用 Requests 数据分析清洗用 Pandas 机器学习 Tensorflow SCIPY 1.2 工具链Pythonista 的工具集 1.3 文档1.4 社区1.5 书籍0x02 基础概念2.1 数据类型2.1.1 常量12345FalseTrueNoneNotImplementedElilipsis ... 布尔常量123456NoneFalse0 0.0 0j&apos;&apos; () []&#123;&#125;一个对象 __bool__() = False , 如果上一个为 True 则__len__() 布尔运算符123x or yx and ynot x 布尔比较值1234# 可以定制&lt; &lt;= &gt;= &gt; == !=# 无法定制is / is not 2.1.2 数字类型 int float complex 操作符12345678910+ - * / // % -n +n abs() int() float()complex(re,im)c.conjugate()divmod(x,y)pow(x,y) x ** ymath.trunc(x)math.round(x[,n])math.floor(x) &lt;=xmath.ceil(x) &gt;=x| ^ &amp; &lt;&lt; &gt;&gt; ~x 注意 12(-1) / 2 # -11 / (-2) # -1 数值类型的哈希// TODO : 麻蛋居然没看懂 4.4.4. Hashing of numeric types 2.1.3 迭代器类型生成器 2.1.4 序列类型C 实现的按照 item 是否为同一类型分为： Container sequences: list, tuple, and collections.deque can hold items of different types. Flat sequences: str, bytes, bytearray, memoryview, and array.array hold items of one type. C 实现按照 item 是否可修改分为： Mutable sequences: list, bytearray, array.array, collections.deque, and memoryview Immutable sequences: tuple, str, and bytes 通用序列操作12345678910111213x in sx not in ss + ts * n 或者 n * ss[i]s[i:j]s[i:j:s]len(s)min(s)max(s)s.index(x,i,j)s.count(x)// TODO 封装 deepEqual 切片 为何 Slice 和 Range 会排除 最后一个 Item? 书中讲的太复杂，其实这个和尺子是一个作用，尺子从 0 刻度开始，这样方便丈量。 比如说： items[0:10] 为 10 厘米 items[10] 为 10 刻度后一个单位，即 items[10:11] items[2:] 为 2 刻度后面若干个单位 items[::3] 以三为单位，从 0 刻度开始，最后为结尾，每三个 1a[i, j] # 调用 a.__getitem__((i, j)) 不可变序列类型 解包赋值 不要手贱加逗号 下划线可以用作临时变量 （但是 django 中下划线用于中英文） 123456a, b, *rest = range(5) # (0, 1, [2, 3, 4])a, b, *rest = range(3) # (0, 1, [2])a, b, *rest = range(2) # (0, 1, [])a, *body, c, d = range(5) # (0, [1, 2], 3, 4)*head, b, c, d = range(5) # ([0, 1], 2, 3, 4) namedtuple 123456City = namedtuple('City', 'name country population coordinates')tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))tokyo.populationtokyo.coordinatestokyo[1]City._fields # tuple 可变序列类型123456789s[i] = xs[i:j] = tdel s[i:j]s[i:j:k] = tdel s[i:j:k]s.append(x)s.clear()s.copy()s.extend(t) 或者 s += t List Comprehensions and Generator Expressions12345new_items = [func(a) for item in items]new_items = [ str(x) for x in range(100) if x % 2 == 0]new_items = list(map(str,list(filter(lambda x: x % 2 == 0 , list(range(100))))))# 可写成new_items = list(map(str,filter(lambda x: x % 2 == 0 , range(100)))) list 往往和 map filter 以及 listcomp 用于创建简单的序列 Augmented Assignment with Sequences123456789对于不可变类型 赋值 l *= 2 在内存中则是创建了新的两个长度的元祖，然后赋值而由于字符串则需要注意，str_a += "str b" , 虽然为不可变变量，但并不需要拷贝整个字符串（特殊情况）, 但字符串的拼接建议还是"".join()t = (1, 2, [30, 40])t[2] += [50, 60]# 结果为既赋值成功，又报错# 但 t[2].extend([50, 60]) 可以赋值成功import disdis.dis('s[a] += b') # 可以查看字节码 尽量不要在不可变变量内保存可变变量 t[2] += [50,60] 并不是原子操作，因为，当做了一半的时候，抛出的错误。 list.sort and the sorted Built-In Function对于 sort 和 sorted 来说，reverse 代表 desc,key 为单参数用于计算每一个值的结果的函数。list.sort 直接针对列表排序，并且返回 None（出于编程习惯的问题，直接返回 None 的函数大多是对程序有一定的修改） Managing Ordered Sequences with bisect1234567891011import bisectbisect -&gt; bisect_rightbisect_leftinsort -&gt; insort_leftinsort_right# 搜索可以用来划分档次def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): i = bisect.bisect(breakpoints, score) return grades[i][grade(score) for score in [33, 99, 77, 70, 89, 90, 100]] # ['F', 'A', 'C', 'C', 'B', 'A', 'A'] When a List Is Not the Answerlist 是一种 mix-typed 的数据结构，即可以存放不同种类型的数据结构，由此带来的问题自然是性能问题： list 第一是 mix-typed 的数据结构 动态数组，并非数组 当考虑性能的时候，则需要考虑是不是要换一个更好的数据结构： 适用于类型单一的 array 增删比较多，或者需要使用 FIFO,LIFO, 则使用 deque (double-ended queue) 12345# Arraysfloats = array('d', (random() for i in range(10**7)))# NumPy and SciPy# Deques and Other Queue Deques and Other Queue Deque queue 线程安全 Queue, LifoQueue, and PriorityQueue multiprocessing Queue 和 JoinableQueue asyncio Queue, LifoQueue, PriorityQueue, and JoinableQueue 2.2 语句语句 2.3 函数2.3.0 参数2.3.1 闭包与作用域本部分具备一定文字量，故单独抽取出来到文章，请参考 Python 中的闭包和作用域。 2.3.2 高阶函数 map reduce filter 2.3.3 特殊方法1234obj.__len__()len()obj.__ 对于内置类型 (list, str , bytearray) 解释器在调用特殊方法的时候调用 C 库，比如 CPython 实现的 len 方法一般直接会调用 PyVarObject C Struct ob_size 特殊方法往往并不是显示调用，而是被隐式调用。比如 init 在 new 中的作用，比如 for item in items 世界上会调用 iter(items), 这也会隐式调用 items.iter() . 一般当大量使用特殊方法的时候，都是在进行元编程。 12bool(x) 先调用 x.__bool__() , 如果 x.__bool__() 没有实现，则调用 x.__len__(), 如果为 0 则返回 Falsesorted(arr) 可以直接返回 arr，arr.sort() 是排序内部。 特殊方法名 （有操作符） 种类 方法名 String/Bytes repr , str , format , bytes Conversion to number abs , bool , complex , init , float , hash , index Emulating collections len , getitem , setitem , delitem , contains Iteration iter, reversed , next Emulating callables call Context management enter, exit Instance creation &amp; destruction new , init , del Attribute management getattr , getattribute , setattr , delattr, dir Attribute descriptors get , set ,delete Class service prepare , instancecheck , subclasscheck 特殊方法名 （无操作符） 种类 方法名 Unary numeric operators neg , pos , abs Rich comparison operators lt , le , eq , ne , gt , ge Arithmetic operators add ,sub , mul ,truediv ,floordiv ,mod , divmod , pow , round round Reversed arithmetic operators radd , rsub , rmul , rtruediv, rfloordiv , rmod , rdivmod, rpow Augmented assignment mathmatic iadd , isub , imul , itruediv, ifloordiv Bitwise operators invert , lshift , rshift , and , or Reversed bitwise operators rlshift , rrshift , rand , rxor , ror Augmented assignment bitwise ilshift , irshift , iand , ixor , ior Why len Is Not a Method 123456789101112131415161718192021因为对 不同类型并不是一定调用 __len__ , 对于基本类型查看 c struct 中长度，对于其他类型直接调用 __len__ , 这种区分对待### 2.4 生成器```pythondef gen(): yield 1 yield 2 yield 3 # 这里为了省事，标记 123, 但是一般会有个循环，或者多个循环gen # &lt;function __main__.gen&gt;# 显式调用，返回方法对象g = gen() # &lt;generator object gen at 0x10ec23dc0&gt;next(g)next(g)next(g)next(g) # 执行到结尾部分或者其他报错 StopIterationfor i in gen(): print(i) 生成器的作用就在于将遍历 lazy 化。嗯？其实编写代码的时候完全不中写生成器也可以 lazy 化很多操作。 需要注意的是，generator 后面支持了一个方法叫做 send(), 是 next() 的升级版本。将原来的数据的单向流通变成了双向流通。 见 协程 0x03 中级概念3.1 类和对象包含元编程 3.2 模块与包3.3 错误 / 调试测试3.4 IO 编程3.5 正则表达式12345678910111213. ^ $ * + ? &#123; &#125; [ ] \ | ( )Regular String"ab*""\\\\section""\\w+\\s+\\1"Raw stringr"ab*"r"\\section"r"\w+\s+\1" 0x04 高级概念4.1 元编程4.1.1 Dynamic Attributes and Properties123456789101112131415161718obj.attr重写__getattr__// TODO: 什么时候完成 python 的 DICT 以及 JSON 的相等？accessor?__new__ 是一个 class method, 但是并没有 xxxx = Foo('a')def object_maker(the_class, some_arg): new_object = the_class.__new__(some_arg) if isinstance(new_object, the_class): the_class.__init__(new_object, some_arg) return new_objectx = object_maker(Foo,'a') 4.1.2 Attributes Descriptors12345678910@property__class__ # 接近 type()__dict____slot__dir(obj) # 与__dict__接近getattrsetattrhasattr 4.1.3 Class MetaProgramming4.2 并发编程4.2.0 GIL - Global Interpreter Lock并不是所有的解释器语言都有 GIL （尽管 Python 和 Ruby 里面都有）, 也并不是没有尝试过去除 GIL, 但是每次去除都会导致单线程性能的下降。所以暂时保留。 GIL 对程序中的影响： 一个线程运行 Python , 而其他 N 个睡眠或者等待 I/O - 同一时刻只有一个线程对共享资源进行存取 , Python 线程也可以等待 threading.Lock 或者线程模块中的其他同步对象； 协同式多任务处理如果有两个线程，同时进行 IO 请求，当其中一个线程连接之后，立即会主动让出 GIL, 其他线程就可以运行。 当 N 个线程在网络 I/O 堵塞，或等待重新获取 GIL，而一个线程运行 Python。 让出之后还要执行代码呀，所以要有个收回 GIL 的动作。 抢占式多任务处理Python 2 GIL , 尝试收回 GIL 为 执行 1000 字节码。Python 3 GIL , 尝试收回 GIL 检测间隔为 15ms 线程安全原子操作：sort 之类不需要非原子操作：n=n+2 的字节码分为 加载 n , 加载 2 , 相加，存储 n, 四个步骤，由于不是原子性，很可能被由于 15 ms 而被打断。 当然，懒人一向是 : 优先级不决加括号，线程不决加 lock 对于 Java, 程序员努力在尽可能短的时间内加锁存取共享数据，减轻线程的争夺，实现最大并行。但 Python 中，线程无法并行运行，细粒度的锁就没有了优势。 4.2.1 多线程 Python 多线程约等于并发。 4.2.2 多进程4.2.3 协程Python 中，协程在语法上接近于生成器（函数内包含 yield 关键字）. 1234# 生成器def g(): yield a pass 12345# 协程def c(): # b = yield a b = yield pass 协程在 0x05 标准库与第三方库5.1 数据结构与算法5.2 字符串与文本5.3 数字日期与时间5.4 迭代器与生成器 Introduction Built-in Functions Built-in Constants Built-in Types Built-in Exceptions Text Processing Services Binary Data Services Data Types Numeric and Mathematical Modules Functional Programming Modules File and Directory Access Data Persistence Data Compression and Archiving File Formats Cryptographic Services Generic Operating System Services Concurrent Execution Interprocess Communication and Networking Internet Data Handling Structured Markup Processing Tools Internet Protocols and Support Multimedia Services Internationalization Program Frameworks Graphical User Interfaces with Tk Development Tools Debugging and Profiling Software Packaging and Distribution Python Runtime Services Custom Python Interpreters Importing Modules Python Language Services Miscellaneous Services MS Windows Specific Services Unix Specific Services Superseded Modules Undocumented Modules 0x06 可维护性代码社区推崇的代码风格 PythonicThe Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&apos;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you&apos;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it&apos;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let&apos;s do more of those! 正确性 外部不该引用 protected member （单下划线） lambda 为一次使用，最好不要赋值。 不要给 buildin 函数赋值 py3 直接 super() for in else 如果不内置 break 则出会在最后 for in 为 empty 的时候再执行 else 中的语句 context exit 如果不 catch 掉异常让其自然向上一级抛出错误的话，必须为 (self, exception_type, exception_value, traceback): 不要在 init 里面 return 数据 不要混用 tab 和 space 4 个 space 缩进 staticmethod 直接是 参数，classmethod 第一个参数为 cls 可变的 default value 是不能作为 参数的。（可能是解释器在确定函数的定义的时候完成赋值？) 遵循 exception hierachy https://docs.python.org/3/library/exceptions.html#exception-hierarchy defaultdict defaultdict(lambda : 6) , 必须 callable 尽量 unpack 赋值 字典用获取用 get(“myk”,None) , 赋值用 dictionary.setdefault(“list”, []).append(“list_item”) 可维护性 避免使用 import * , 我觉得这点值得商榷 , 如果是某个模块下，完全可以先把模块拆分成多个，最后 import 进来，接着使用 all. getxxx 获取实际值，如果不为实际值，返回 None 显然不如 try catch 来的实在。 避免使用 global 命名要注意 动态创建方法 , 我觉得这点值得商榷。 可读性 不要检查，如果可能有异常，尽量抛出异常来 trycatch 解决。 a is None , if flag isinstance , not type(r) is types.ListType “{name}{city}”.format(**info_dict) for k , v in infodict.items() 使用 poiinfo = namedtuple(“poiinfo”,[“name”,”lng”,”lat”]) 返回 poiinfo[‘上海’,121.00,23] 最后返回值打印 poi.name , poi.lng , poi lat for numbers_value, letters_value in zip(numbers, letters): enumerate 如果能用 listcomp 则不使用 map 和 filter 性能 用 set d.iteritems() 比 items() 省内存 0xEE 文章更新 2017-05-11 19:43:00 : 增加代码质量模块 2017-08-04 19:43:00 : 增加部分 Fluent Python 的笔记]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>重构技巧</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReThinking In JavaScript]]></title>
    <url>%2F2017%2F07%2F04%2FRethinkingInJavaScript%2F</url>
    <content type="text"><![CDATA[0x00. 前言JavaScript 这门语言已经不容小觑了，在项目中的前端部分基于 VueJS 和 ElementUI 之后，我也就顺应历史潮流深入了解了一下这门不容小觑的语言。 1. 为什么是 JavaScript为什么是 JavaScript 呢？ 因为太火，不得不认真学习一下。 我本人对 JavaScript 这种语言是有偏见的，这点我不会掩饰，我始终记得在正常的语言 Python / Java / C# 中实现一个休眠的简单功能和在 JS 中实现一个休眠功能的差别。 在 Python 中有很多语法糖，内置数据结构丰富，而 JS 则并不是如此，数据类型相对少，Bool 判断混乱，而今天，这门混乱的语言在流行程度上几乎接近于 Java 这门语言，即便是存在这样或者那样的问题，JavaScript 依然是一种奇葩的王者。 在服务端，有多少功能是 Python 完不成而 JavaScript（即 NodeJS) 可以胜任的呢？而且，NodeJS 写起来的感觉比起 Python 来说，还是差了很多，所以，我比较倾向于把计算类和 IO 类的操作用 Python 来写，至于浏览器端就交给 JavaScript 好了。 那么，对 JS 的这种定位，也使得我对 JS 生态圈的掌握程度不会超过 Vue/React 系。 2. 工具链2.1. 浏览器端2.2. 桌面端2.3. 客户端4. 文档5. 社区6. 书籍0x01 基本概念1. 数据类型 Number （没有 INT 值，只有 double-precision 64-bit format IEEE 754 ） String Boolean Symbol (new in ES2015) Object Function Array Date RegExp null undefined 2. 操作操作操作3. 语句0x02 中级概念函数作用域模块面向对象错误 / 调试测试IO 编程进程和线程多线程多进程GIL协同式多任务处理抢占式多任务处理线程安全正则表达式0x03 高级技巧0x04 标准库常用内建模块系统化模块安全性性能0xEE 文章更新 2017-07-05 19:43:00 : 初始化本文]]></content>
      <categories>
        <category>进击的 JavaScript</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>重构技巧</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim Cheatsheet]]></title>
    <url>%2F2017%2F06%2F23%2FVimCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中 Vim 使用场景。 不定期更新。 配置 基本使用技巧 原生 Tips &amp; Hacks Vim 必备插件 0x01 配置原先使用 k-vim 进行日常的编辑，然后依据自己的一些需求进行微调为 c-vim 。 https://github.com/twocucao/c-vim 0x02 基本使用技巧2.1 Insert Mode c-w 向后删除一个 word c-h 向后删除一个 char 2.2 Normal Mode gi 返回上次修改地点 d% 剪切包含括号的括号内部内容 U 恢复单个句子 在命令状态下按 c-d 可以查看所有命令，相当于 bash 下面的 tabtab hjkl 左下上右 EasyMotion 使用这个就可以代替乱七八糟的快速移动了。这是一个可以给当前的文字立即用打上 tag, 这样的话在 normal 情况下输入，,w 然后就可以看到很多 tag, 输入其中的 tag 就可以立即跳转到相应的 tag. insert 状态进行编辑 c-h c-w 删除一个字，删除一个词。 normal 状态下进行删除 x dd —— 删除一个字，剪切一行。 . .. —— 重复操作 &lt; —— 缩进 &gt;G]]></content>
      <categories>
        <category>编程利器</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>工作自动化</tag>
        <tag>Cheatsheet</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git CheatSheet]]></title>
    <url>%2F2017%2F06%2F15%2FGitCheatSheet%2F</url>
    <content type="text"><![CDATA[如何优雅地使用 Git0x00 前言Git 是一种分布式版本管理工具。 0x01 Git 命令范论 基础命令 （本地修改类） 合作命令 （本地与仓库类） 综合命令 管理命令 前两种命令是入门 Git 的程序员都必须要会的。 而队伍里的技术管理人员必须要会前三。 1.1 基础命令 git-init(1) to create a new repository. git-log(1) to see what happened. git-checkout(1) and git-branch(1) to switch branches. git-add(1) to manage the index file. git-diff(1) and git-status(1) to see what you are in the middle of doing. git-commit(1) to advance the current branch. git-reset(1) and git-checkout(1) (with pathname parameters) to undo changes. git-merge(1) to merge between local branches. git-rebase(1) to maintain topic branches. git-tag(1) to mark a known point. 123456789101112131415161718192021$ tar zxf frotz.tar.gz$ cd frotz$ git init$ git add . (1)$ git commit -m "import of frotz source tree."$ git tag v2.43 (2)$ git checkout -b alsa-audio (1)$ edit/compile/test$ git checkout -- curses/ux_audio_oss.c (2) # 恢复文件$ git add curses/ux_audio_alsa.c (3)$ edit/compile/test$ git diff HEAD (4) # 查看提交了哪些修改$ git commit -a -s (5) # 提交所有$ edit/compile/test$ git diff HEAD^ (6) # 查看所有变化，包含之前的 commit$ git commit -a --amend (7) # 修订前一个 commit, 把所有的新变化提交到$ git checkout master (8)$ git merge alsa-audio (9)$ git log --since='3 days ago' (10)$ git log v2.43.. curses/ (11) 1.2 合作命令 git-clone(1) from the upstream to prime your local repository. git-pull(1) and git-fetch(1) from “origin” to keep up-to-date with the upstream. git-push(1) to shared repository, if you adopt CVS style shared repository workflow. git-format-patch(1) to prepare e-mail submission, if you adopt Linux kernel-style public forum workflow. git-send-email(1) to send your e-mail submission without corruption by your MUA. git-request-pull(1) to create a summary of changes for your upstream to pull. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950## clone 修改 提交$ git clone git://git.kernel.org/pub/scm/.../torvalds/linux-2.6 my2.6$ cd my2.6$ git checkout -b mine master (1)$ edit/compile/test; git commit -a -s (2)$ git format-patch master (3)$ git send-email --to="person &lt;email@example.com&gt;" 00*.patch (4)$ git checkout master (5)$ git pull (6)$ git log -p ORIG_HEAD.. arch/i386 include/asm-i386 (7) # 查看感兴趣的部分$ git ls-remote --heads http://git.kernel.org/.../jgarzik/libata-dev.git (8) # 查看分支$ git pull git://git.kernel.org/pub/.../jgarzik/libata-dev.git ALL (9) # 从一个特地$ git reset --hard ORIG_HEAD (10) # 撤销 pull$ git gc (11) # garbage collect leftover objects from reverted pull# 推送到其他 reposatellite$ git clone mothership:frotz frotz (1)satellite$ cd frotzsatellite$ git config --get-regexp '^(remote|branch)\.' (2)remote.origin.url mothership:frotzremote.origin.fetch refs/heads/*:refs/remotes/origin/*branch.master.remote originbranch.master.merge refs/heads/mastersatellite$ git config remote.origin.push \ +refs/heads/*:refs/remotes/satellite/* (3)satellite$ edit/compile/test/commitsatellite$ git push origin (4)mothership$ cd frotzmothership$ git checkout mastermothership$ git merge satellite/master (5) 1. mothership machine has a frotz repository under your home directory; clone from it to start a repository on the satellite machine. 2. clone sets these configuration variables by default. It arranges git pull to fetch and store the branches of mothership machine to local remotes/origin/* remote-tracking branches. 3. arrange git push to push all local branches to their corresponding branch of the mothership machine. 4. push will stash all our work away on remotes/satellite/* remote-tracking branches on the mothership machine. You could use this as a back-up method. Likewise, you can pretend that mothership "fetched" from you (useful when access is one sided). 5. on mothership machine, merge the work done on the satellite machine into the master branch. Branch off of a specific tag. $ git checkout -b private2.6.14 v2.6.14 (1) $ edit/compile/test; git commit -a $ git checkout master $ git cherry-pick v2.6.14..private2.6.14 (2) 1. create a private branch based on a well known (but somewhat behind) tag. 2. forward port all changes in private2.6.14 branch to master branch without a formal "merging". Or longhand git format-patch -k -m --stdout v2.6.14..private2.6.14 | git am -3 -k 1.3 综合个体1.4 仓库管理安装完毕之后，cmd-s-p shell command install 0x02 Git Hacks123456789101112131415161718# 搜索代码的变化git log -S'&lt;a term in the source&gt;'# 放弃本地修改，与远程同步git fetch origin &amp;&amp; git reset --hard origin/master &amp;&amp; git clean -f -d# 列出所有冲突文件git diff --name-only --diff-filter=U# 手贱错误提交，但是没有 pushgit commit -m "Something terribly misguided" (1)git reset HEAD~ (2)# edit needing changed filesgit add needing changed files (4)git commit -c ORIG_HEAD (5)# Delete all changes in the Git repository, but leave unstaged thingsgit checkout .# Delete all changes in the Git repository, including untracked filesgit clean -f 0x03 Git 和 我的 Workflow一切工具都是为思路服务。 0xEE 扩展阅读]]></content>
      <categories>
        <category>编程利器</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas Cheatsheet]]></title>
    <url>%2F2017%2F06%2F03%2FPandasCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Pandas 相关语句。 主要包含： Pandas 中 Series 的一些常见操作和技巧 Pandas 中 Dateframe 的一些常见操作和技巧 Python 里的可视化技巧 Pandas 使用过程中的一些细节 不定期更新。 SQL 是一种面向集合的处理工具 / 语言Pandas 是一种面向数组的处理工具 而一般处理 pandas 的数据往往以二维表的形式存在。所以，可以类比为更加强大的 SQL 语言。 而依据 Pandas 的作者之言，牛逼的 Pandas 使用者必须要精通 numpy; 当然，关于 Numpy, 留待之后开一篇文章做笔记好了。 0x01 Series 相关Series 接近于 ndarray 的用法，区别仅仅在于会带上 label 而已 关于 ndarray, 请参考 我的另一篇文章 Numpy Cheatsheet 0x02 DataFrame 相关2.1 对象创建123456789101112131415161718192021222324# 1. 内存变量转 Dataframe## 1.1. 通过二位矩阵 , index , columnsdates = pd.date_range('20130101', periods=6)pd = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))## 1.2. 通过字典 Key 为 Column , Value 为 list,timestamp,np.array,valuedf2 = pd.DataFrame(&#123; 'A' : 1., 'B' : pd.Timestamp('20130102'), 'C' : pd.Series(1,index=list(range(4)),dtype='float32'), 'D' : np.array([3] * 4,dtype='int32'), 'E' : pd.Categorical(["test","train","test","train"]), 'F' : 'foo' &#125;)# 长度无需统一，会自动填充# 2. 从文件中读取pd.read_excel("./data_set.xlsx",index_col=False) # 关掉 Index# 3. 合并多个同样的 DataFramedf_items = [df_item1,df_item2,...]df = pd.concat(df_items).drop_duplicates()df.merge(data_set_df, left_on="lno", right_on="rno", how="outer")# 4.series to dataframedf = s.to_frame() 选择数据 Getting Selection by Label Selection by Position Boolean Indexing Setting缺失数据数据操作 Operations Stats Apply Histogramming String Methods数据合并 Concat Join AppendGroupingReshaping Stack Pivot TablesTime SeriesCategoricalsPlotting 2.2 浏览数据12345678910111213141516171819202122232425262728293031# 1. 查看表结构df.head()df.tail(3)df.index# df.index = ['日期','小时']df.columnsdf.columns = map(str.lower, df.columns)df.valuesdf['col'] = df['col'].astype(str).convert_objects(convert_numeric=True)# 2. 删除 col_namedf.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')del df['cola']# 3. 修改元数据df.rename(columns=lambda x: x.split('.')[-1], inplace=True)df.rename(columns=&#123;'oldName1': 'newName1', 'oldName2': 'newName2'&#125;, inplace=True)df.rename(columns = &#123;0: 'cola', 1: 'colb', 2: 'colc'&#125;, inplace=True)# 2.## 2. 遍历for index, row in df.iterrows(): print row["c1"], row["c2"]for row in df.itertuples(index=True, name='Pandas'): print getattr(row, "c1"), getattr(row, "c2")= IF([@price] &lt; 1, "未知",IF([@price] &lt; 30000, "三万以下", IF([@price] &lt;= 50000, "三万到五万", IF([@price] &lt;= 100000, "五万到十万", IF([@price] &lt;= 10000000, "十万以上", "其他"))))) 2.3 修改表内容1df.drop_duplicates(['col_a','col_b']) 2.4 查看表内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124# 选择df['A'] # 列选df[0:30] # 行选df['20130102':'20130104'] # 行选df.loc['20130102':'20130104',['A','B']] # by labeldf.loc[condition,['cola','colb']]df.loc[['ri01','ri02'] , ["cola","colb","colc"]]df.iloc[1:5, 2:4] # by positiondf.iloc[: , 0:7] # 全部列，0-7 索引df.ix[['ri02', 'ri09']] # 选取行total_rows=len(df.axes[0])total_cols=len(df.axes[1])df.sample(3000) # 随机抽取 3000 行，可以用于快速验证算法criterion = df2['a'].map(lambda x: x.startswith('t'))df2[criterion]df2[[x.startswith('t') for x in df2['a']]]# select * from df limit 5df.head()# select a,b,c from dfdf[['a','b','c']].head()# select a,b,c from df where a = 11 and b = 'xx'df[ ( df['a'] == 11) &amp; ( df['b'] == 'xx') ][['a','b','c']]df['a'].value_counts()# SELECT * FROM df ORDER BY a DESC LIMIT 10 OFFSET 5;df.nlargest(10+5, columns='a').tail(10)df.column.str[0:2]df.column_name.str.len()two_groups = '(?P&lt;letter&gt;[a-z])(?P&lt;digit&gt;[0-9])'s.str.extract(two_groups, expand=True)# 排序df.sort_index(axis=1, ascending=False)df.sort_values(by='B')df = df.sort(['col1','col2','col3'],ascending=[1,1,0])## window function# SELECT a, b, c, rank() OVER (PARTITION BY a ORDER BY b DESC) as rn FROM df;# 如果没有这个 window function 的话，可以 groupby 一下，然后生成表和原有表进行 JOINtips.assign(rn=tips.sort_values(['b'], ascending=False).groupby(['a']).cumcount() + 1)# Top N rows per group# rank 代表等级 如果两人并列第一名，则不存在第二名，直接是第三名 , row_number 代表排名，即即便两个人分数一样，也无法并列第一名# PostGRESQL's ROW_NUMBER() analytic functionSELECT * FROM ( SELECT t.*, ROW_NUMBER() OVER(PARTITION BY day ORDER BY total_bill DESC) AS rn FROM tips t) ttWHERE rn &lt; 3ORDER BY day, rn;(tips.assign(rn=tips.sort_values(['total_bill'], ascending=False) .groupby(['day']) .cumcount() + 1) .query('rn &lt; 3') .sort_values(['day','rn']))(tips.assign(rnk=tips.groupby(['day'])['total_bill'] .rank(method='first', ascending=False)) .query('rnk &lt; 3') .sort_values(['day','rnk']))# PostGRESQL's RANK() analytic functionSELECT * FROM ( SELECT t.*, RANK() OVER(PARTITION BY sex ORDER BY tip) AS rnk FROM tips t WHERE tip &lt; 2)WHERE rnk &lt; 3ORDER BY sex, rnk;(tips[tips['tip'] &lt; 2] .assign(rnk_min=tips.groupby(['sex'])['tip'] .rank(method='min')) .query('rnk_min &lt; 3') .sort_values(['sex','rnk_min']))# where 语句df['a'].isnull()df['a'].isin(arr)# groupbydf.groupby('a').size() # 计算 adf.groupby('a')['b'].count() # 同上计算 adf.groupby('a').count() # 计算所有 colsagg_fun_dict = &#123;'tip': np.mean, 'day': np.size&#125;agg_fun_dict_new = &#123;'tip': [np.mean, np.size]&#125;df.groupby('a')[['b','c']].agg(agg_fun_dict)df.groupby('a')['b'].describe()df.age.agg(['min', 'max'])df.applymap(multiply_10_for_every_int) #calc_groups = df.groupby([date])calc_groups['id_aa'].nunique().reset_index().to_excel("123.xlsx")# pivotpd.pivot_table(data=df,values='value_col', index='A_FROM', columns='B_TO', aggfunc=lambda x: len(x.unique()),margins=True)# CONCATappend# JOINpd.merge(df1, df2, on='key', how='outer')# UPDATE tips SET tip = tip*2 WHERE tip &lt; 2;tips.loc[tips['tip'] &lt; 2, 'tip'] *= 2# TODO: 2.5 表变换123# apply , apply mapDataFrame.apply operates on entire rows or columns at a time.DataFrame.applymap, Series.apply, and Series.map operate on one element at time. 2.6 表遍历12df.iterrows()df.itertuples() 数据导入导出SQL123456789101112131415161718192021222324from sqlalchemy import create_enginefrom sqlalchemy.engine.url import URLDATABASE = &#123; 'drivername': 'postgres', 'host': 'localhost', 'port': '5432', 'username': 'yourusername', 'password': 'yourpass', 'database': 'yourdb'&#125;# 这里并不建议直接写数据库连接字符串，而是使用 URL 函数，这样可以避免转义字符带来的坑，比如 @ 在数据库连接字符串是 %40engine = create_engine(URL(**DATABASE))# 读一整张表with engine.connect() as conn, conn.begin(): data = pd.read_sql_table('yourtablehere', conn) processyourdata(data)# 按照 SQL 语句来读with engine.connect() as conn, conn.begin(): data = pd.read_sql(""" yoursqlquery """, conn) processyourdata(data) CSV日常数据处理用 CSV 的比较多，因为这种格式语法简洁，类二维表，读写速度快，而且配合 gzip 压缩解压。 pandas 在 windows 上好像不能读取中文路径？ 而且，pandas 读取的时候要注意指定编码。因为在日常导出 CSV 的时往往使用的是 utf-8, 而 windows 默认打开文本文件时候使用的是 gbk read_csv 有几十个参数，挑几个说一下： sep 可以指定分隔符，默认为’,’, 但有的人导出的数据以 tab 为空格。 dtype 可以指定某些列的值类型为 int,float 的类型从而减少 object 的创建 , 但是对 str/object 没有什么暖用 parse_dates 可以指定 date 列 header 如果 CSV 没有 Header, 可以指定为 None usecols 可以指定几列，相当于数据库中的 SELECT a_col,b_col 其中还有一些比较有趣的东西，比如说，iterator=True值得注意的是，通过 ExcelGotchas 0x02 可视化技术123456789101112131415161718192021222324252627282930313233343536# 绘制df.plot(kind='bar')plt.xlabel('xlable')plt.ylabel('ylable')plt.title('title name')plt.show()df['数量'].plot(kind='bar')# 批量创建图g = sns.FacetGrid(customers, col="cola")g.map(plt.scatter, "数量", "单位", alpha=1)g.add_legend();ttbill = sns.distplot(tips["总价格"]);ttbill.set(xlabel = '价值', ylabel = '频率', title = "标题名")sns.despine()sns.jointplot(x ="total_bill", y ="tip", data = tips)# https://github.com/guipsamora/pandas_exercises/blob/master/07_Visualization/Tips/Exercises_with_code_and_solutions.ipynbplt.pie( [100,300], labels = ['男', '女'], shadow = False, colors = ['blue','red'], explode = (0.15 , 0), startangle = 90, autopct = '%1.1f%%' )plt.axis('equal')plt.title("男女比例")plt.tight_layout()plt.show() 0x03 asd10x07 Performance Tips最近遇到了数据量比较大的数据处理，数据条数差不多在 3 千万条。加载到内存中大约 1GB. 7.1 精简行列 读入 dataframe 的时候就排除多余的行列。 Merge 时候需要精简行列。 12df1.merge(df2[list('xab')])pandas.merge(dataframe1, dataframe2.iloc[:, [0:5]], how='left', on='key') 7.2 大文件的处理 参考我的文章 记一次小机器的 Python 大数据分析 0x 踩坑集合0x08 踩坑集合8.1 IO 类#### 8.2 IO 类0xEE 参考链接 ChangeLog: 2017-06-03 初始化本文 2018-02-03 重修文字]]></content>
      <categories>
        <category>数据科学</category>
      </categories>
      <tags>
        <tag>Pandas</tag>
        <tag>效率</tag>
        <tag>工作自动化</tag>
        <tag>Cheatsheet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个基于 TensorFlow 的图片分类器]]></title>
    <url>%2F2017%2F05%2F29%2F%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8ETensorFlow%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[0x00 前言 备注：本文训练效果太差，所以直接太监了。 这年头，不会写爬虫不会写网站，那基本上不能算是一个 Python 程序员，但是 2017 年的 Google IO 之后，作为一个 Pythonist 你不会点数据分析和机器学习，也不好见人了。所以，本文教你在什么机器学习概念都不懂的情况下，做出一个基于 TensorFlow 的图片分类功能，入个门。仅此而已。本文的代码和文章内容主要源于我在 Github 上无意间翻到的一个 Repo, 链接地址，我所做的功夫就是在这基础上将代码改为了 Python 3 / TensorFlow 1.1.0 的环境，将这个流程梳理一下，不算是代码的生产者最多搬运工，仅此而已。 本文的目的是： 通过 TensorFlow 训练一个小型的分类器，用这个分类器通过照片识别出明星的姓名。 即我们要训练一个小 AI, 这个小 AI 能分辨欢乐颂里面的五美： 乔欣 刘涛 王子文 杨紫 蒋欣 注意：本文主要在 MacOS 上进行测试。本文的目录结构如下： 准备训练数据和测试数据 TensorFlow 环境配置 开始训练图片 对图片进行分类 文章回顾 参考链接 首先克隆我的 Repo,（我的 Repo 在这里）[https://github.com/twocucao/the-machine] . 仓库结构大致如下1234567891011121314├── README.md├── compose│ └── tensorflow│ ├── Dockerfile│ └── Dockerfile-dev├── config├── doc├── image_classifier│ ├── __init__.py│ ├── label_dir.py│ ├── label_image.py│ ├── retrain.py│ └── train.sh└── bootstrap.sh 0x01 准备训练数据和测试数据准备训练数据，数据从哪里来呢？从百度来。我们从百度抓取大约 5 组图片，每组图片大约 1000 张图片，并且从每组里面留下 900 组作为训练数据，抽出 100 作为测试数据。 1.1 抓取图片抓取代码放在代码仓库中，比较简单，下载即可用。 在 crawl_baidu_images.py 中填入五美的姓名，运行脚本即可。脚本会请求百度图片的图片，然后下载下来，程序跑完会有如下的图片数据。好，抓取图片我们就完成了。 1.2 归类训练数据归类训练数据，其实就是把刚刚下载下来的图片，分类为五美，也就是把刘涛的照片放到刘涛文件夹中。看一下现在的文件夹，似乎已经分类完毕了，是不是这样呢？显然不是，因为： 下载下来的图片貌似 JPG 结尾的图片，但是文件内容是不是 JPEG 的格式就不好说了，也可 GIF 也可能是 PNG. 当你搜索刘涛的时候，百度图片给出的不仅仅是刘涛。也可能有胡歌《琅琊榜》, 也可能有胡军《天龙八部》 所以下面需要做的是： 移除非 JPG 的文件格式 人工确 (jian) 定 (huang) 文件夹中的图片。 在做上面这两步之前，我们先新建文件夹 image_classifier_train ( 笔者放在 /Users/twocucao/Codes/Repos/image_classifier_train ), 注意，这个文件夹不要放在代码下面，把五美的文件夹放到这个文件夹下面的 data 文件夹下。并且用拼音命名。 如下： 我们先移除非 JPEG 的图片。如果是 mac 系统需要先安装 jpeginfo , brew install jpeginfo 即可。进入 /Users/twocucao/Codes/Repos/image_classifier_train 执行下面脚本 去除非 JPG 的图片 123find . -iname &quot;*.jpg&quot; -exec jpeginfo -c &#123;&#125; \; | grep -E &quot;WARNING|ERROR&quot; &gt; need_delete.shcat need_delete.sh | awk &apos;&#123;print $1&#125;&apos; | xargs rmrm need_delete.sh 好了接下来，我们需要到每一个文件夹下进行人工鉴黄检验图片是不是五美，比如，到 liutao 文件夹下检查，删除图片基本上没有清晰面容的照片。为了速度，我们把图片转成缩略图大致看一下，去除明显不是五美的照片，我们进行下一步的筛选。 1.3 找出对应的头像我们需要从图片库中选出五美的头像来 1234pyenv global systembrew reinstall boost-python --with-python3 --without-pythonconda install -c menpo dlib=19.4 0x02 TensorFlow 环境配置2.1 Docker 的安装和镜像加速本文需要使用 Docker 作为环境配置，也正是因为如此，我们可以在很快的时间内搭建起来 tensorflow 的运行环境。目测，Docker 也是未来几年内搭建环境分发环境的首选。Docker 下载不必多说，需要补充一句的是，我们可以在阿里云账户上使用一个 registry 对 Docker 镜像进行加速。在阿里云的容器界面获取加速链接填到 docker 里面即可。如图。 2.2 构建镜像文件并且构建镜像建议在执行构建镜像之前，务必先完成本文的第二小节的图片准备。然后执行下面的命令，将镜像文件构建成镜像。12cd /Users/twocucao/Codes/Repos/the-machinedocker build -f compose/tensorflow/Dockerfile-dev -t twocucao/tensorflow . 该行命令使用 compose/tensorflow/Dockerfile-dev 作为 Dockerfile 文件，构建镜像名称为 twocucao/tensorflow , 传入的 context 为 当前路径。 2.3 测试 Tensorflow 容器12docker run -it twocucao/tensorflow /bin/bashecho 'hello tensorflow' 如果运行正常，则一切正常。可以进行下一步骤了。 0x03 开始训练执行命令开始训练。 1./train.sh /Users/twocucao/Codes/Repos/image_classifier_train 我设置的训练次数为 20000, 在我的本子上基本两个小时，可能时间有些长，没有耐心的童鞋可以吧训练次数调整低一些。然后重新构建镜像。 那么，当 TensorFlow 在训练的时候，我们要谈些什么？ Google 开源了 Inception 模型，这个模型从 ImageNet 的上千个分类的图片训练而来，而我们所做的工作，便是在此基础上做最后的增量训练。然而，我们只用来区分女明星，似乎这个 Inception 的模型有点大材小用？好，训练结束之后我们查看一下文件夹 /Users/twocucao/Codes/Repos/image_classifier_train 下， 123456789101112131415161718192021222324├── bottlenecks│ ├── jiangxin│ ├── liutao│ ├── qiaoxin│ ├── wangziwen│ └── yangzi├── data│ ├── jiangxin│ ├── liutao│ ├── qiaoxin│ ├── wangziwen│ └── yangzi├── inception│ ├── LICENSE│ ├── classify_image_graph_def.pb│ ├── cropped_panda.jpg│ ├── imagenet_2012_challenge_label_map_proto.pbtxt│ ├── imagenet_synset_to_human_label_map.txt│ └── inception-2015-12-05.tgz├── retrained_graph.pb├── retrained_labels.txt└── test_data ├── src └── target Bottlenecks 文件夹为我们将每一张 JPG 转成矩阵的文本Inception 为 Google 开源的模型文件。retrained_graph.pb 为训练出来的图的模型文件。retrained_labels.txt 为标签。 如下图不断刷出的一坨坨的文字是什么呢？ 时间 , 无需多说 当前训练次数 Train accuracy = 87.0% Cross entropy = 0.499145 Validation accuracy = 52.0% (N=100) 看到 Train accuracy &gt;&gt; Validation accuracy 估计是模型过度拟合了，嗯，看来这个模型还是有点问题的。 0x04 对图片进行分类4.1 开始分类4.2 对分类结果进行评估0x05 文章回顾0x06 参考链接 https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode CheatSheet]]></title>
    <url>%2F2017%2F05%2F27%2FVSCodeCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我使用 VSCode 的一些开发小技巧。 不定期更新。 VSCode 是一种编辑器，这显然是一句废话。 这个问题应该是，我为什么要使用 VSCode 作为主力编辑器。有人说：微软出品一定是精品。这个理由很软粉，但是不能打动我更换编辑器的欲望。 使用编辑器自然是求其轻量，高效的文字处理，以及编程的相关环境的支持，以及跨平台和可扩展性。 轻量是求其打开速度快，编辑不卡顿。这一点，用 Vim , Emacs , Sublime Text 完全都可以。 高效的文字处理是因为满足日常编写文字和代码的需求。 编程相关环境的支持是因为作为一个学习东西很杂乱的人来说，最痛苦的事情就在于 IDE 常常来不及给一些新技术予以足够的支持，比如说 Docker, 比如说 ansible。 跨平台和可扩展性 跨平台是必须的，可扩展性则是从插件资源和编写插件的难度考虑。 本文的目录结构如下： VSCode 常用命令 0x01 VSCode 相关配置安装完毕之后，cmd-s-p shell command install 0x02 VSCode 常用命令 Command Palette : cmd-s-p cmd-p : cmd-p 显示状态 : cmd-s-m 下一个错误 : F8 / shift-F8 ** : c-s-p ** : c-s-p ** : c-s-p ** : c-s-p ** : c-s-p ** : c-s-p ** : c-s-p0x03 VS 扩展相关 0x04]]></content>
      <categories>
        <category>编程利器</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacBook Pro 15.4 Multi-Touch Bar]]></title>
    <url>%2F2017%2F05%2F01%2FOhMyNewMac%2F</url>
    <content type="text"><![CDATA[前言一个月前换了这台新电脑 MacBook Pro 15.4 Multi-Touch Bar (Core i7/16GB/512GB)，感觉每天打字都很舒服，也算是实现了一个梦寐以求的小目标吧。 在此之前，用我的前任有下面几款： 大一时候从网吧买的 400 块钱的台式机 大一时候从淘宝买的 700 块钱的笔记本 大二上学期买的 1200 块钱的笔记本 大三上学期买的 3200 块钱的笔记本，后来花了 2000 块升级了一下下 大四上学期买的 5000 块的二手 MacBook Pro 后来手贱买了降噪耳机，机械键盘，手机，pad , 花的都是自己的钱。 能把一手烂牌打出不错的结果，这才是让人自豪的事情啊！ 晚安，以及劳动节快乐。 更新2017-05-01: 初始化本文]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『Fluent Python』读书笔记]]></title>
    <url>%2F2017%2F04%2F18%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0_FluentPython%2F</url>
    <content type="text"><![CDATA[前言Fluent Python 适用于中级 Pythoner。 以 Python 作为主力编程语言已经 1 年多了，读这本书，希望写的代码可以更加的 Pythonic。 本文目录本书结构 P1. Prologue C01. The Python Data Model P2. Data Structure C02. An Array of Sequences Overview of Built-in Sequences List Comprehensions and Generator Expressions Tuples Are Not Just Immutable Lists Slicing Using plus and star with Sequences Augmented Assignment with Sequences list.sort and the sorted Built-In Function Managing Ordered Sequences with bisect When a List Is Not the Answer Summary Further Reading C03. Dictionaries and Sets Generic Mapping Types Dict Comprehensions Common Mapping Methods Mappings with Flexiable Key Lookup Variations of Dict Subclassing UserDict Immutable Mappings Set Theory Dict and Set Under the Hood Summary Further Reading C04. Text VS Bytes Character Issues Byte Essentials Basic Encoders/Decoders Understanding Encode/Decode Problems Handling Text Files Normalizng Unicode for Saner Comparisons Sorting Unicode Text The Unicode Database Dual-Mode str and bytes APIs Summary Further Reading P3. Function as Objects C05. First-Class Function Treating a Function Like an Object Higher-Order Functions Anonymous Functions The Seven Flavors of Callable Objects User-Defined Callable Types Function Introspection From Positional to Keyword-Only Parameters Function Annotations Packages for Functional Programming Summary Further Reading C06. Design Patterns with First-Class Functions Refactoring Strategy Command Summary Further Reading C07. Function Decorators and Closures Decorators 101 When Python Executes Decorators Decorator-Enhanced Strategy Pattern Variable Scope Rules Closures The nonlocal Declaration Implementing a Simple Decorator Decorators In the Standard Library Stacked Decorators Parameterized Decorators Summary Further Reading P4. Object-Oriented Idioms C08. Object References, Mutability, and Recycling Variables Are Not Boxes Identity, Equality , and Aliases Copies Are Shallow by Default Function Parameters as References del and Garbage Collection Weak References Tricts Python Plays with Immutables Summary Further Reading C09. A Pythonic Object Object Representations Vector Class Redux An Alternative Constructor classmethod VS staticmethod Formatted Displays A Hashable Vector2d Private and “Protected” Attributes in Python Saving Space with the slots Class Attribute Overriding Class Attributes Summary Further Reading C10. Sequence Hacking , Hashing , and Slicing Vector: A User-Defined Sequence Type Vector Take #1: Vector2d Compatible Protocols and Duck Typing Vector Take #2: A Sliceable Sequence Vector Take #3: Dynamic Attribute Access Vector Take #4: Hashing and a Faster == Vector Take #5: Formatting Summary Further Reading C11. Interfaces: From Protocols to ABCs Interfaces and Protocols in Python Culture Python Digs Sequences Monkey-Patching to Implement a Protocol at Runtime Alex Martelli’s Waterfowl Subclassing an ABC ABCs in the Standard Library Defining and Using an ABC How the Tombola Subclasses Were Tested Usage of register in Practice Geese Can Behave as Ducks Chapter Summary Further Reading C12. Inheritance: For Good or For Worse Subclassing Built-In Types Is Tricty Multiple Inheritance and Method Resolution Order Multiple Inheritance in the Real World Coping with Multiple Inheritance A Modern Example: Mixins in Django Generic Views Chapter Summary Further Reading C13. Operator Overloading: Doing It Right Operator Overloading 101 Unary Operators Overloading plus for Verctor Addtion Overloading star for Scalar Multiplication Rich Comparison Operators Augmented Assignment Operator Chapter Summary Further Reading P5. Control Flow C14. Iterables, Iterators , and Generators Sentence Take #1 : A Sequence of Words Iterables VS Iterators Iterables Versus Itertors Sentence Take #2 : A Classic Iterator Sentence Take #3 : A Generator Function Sentence Take #4 : A Lazy Implementation Sentence Take #5 : A Generator Expression Generator Expressions : When to Use Them Another Example : Arithmetic Progression Generator Generator Functions in the Standard Library New Syntax In Python 3.3 : yield from Iterable Reducing Functions A Closer Look at the iter Function Case Study : Generators in a Databse Conversion Utility Generators as Coroutines Chapter Summary Further Reading C15. Context Managers and else Blocks Do This , Then That: else Blocks Beyond if Context Managers and with Blocks The contextlib Utilities Using @contextmanager Chapter Summary Further Reading C16. Coroutines How Coroutines Evolved from Generators Basic Behavior of a Generator Used as a Coroutine Example: Coroutine to Compute a Running Average Decorators for Conroutine Priming Coroutine Termination and Exception Handing Returning a Value from a Coroutine Using Yield from The Meaning of yield from Use Case: Coroutines for Discrete Event Simulation Chapter Summary Further Reading C17. Concurrency with Futures e.g. Web Downloads in Three Styles Blocking I/O and the GIL Launching Processes with concurrent.futures Experimenting with Executor.map Downloads with Progress Display and Error Handling Chapter Summary Further Reading C18. Concurrency with asyncio Thread VS Coroutine : A Comparison Downloading with asyncio and aiohttp Running Circling Around Blocking Calls Enhancing the asyncio downloader Script From Callbacks to Futures and Coroutines Writing asyncio Servers Chapter Summary Further Reading P6. Metaprogramming C19. Dynamic Attributes and Properties Data Wrangling with Dynamic Attributes Using a Property for Attribute Validation A Proper Look at Properties Coding a Property Factory Handling Attribute Deletion Essential Attributes and Functions For Attribute Handling Chapter Summary Further Reading C20. Attribute Descriptors Desciptor Example: Attribute Validation Overriding VS Nonoverriding Descriptors Methods Are Descriptors Descriptor Usage Tips Descriptor docstring and Overriding Deletion Chapter Summary Further Reading C21. Class Metaprogramming A Class Factory A Class Decorator for Customizing Descriptors What Happens When: Import Time VS Runtime Metaclasses 101 A Metaclass for Customizing Descriptors The Metaclass prepare Special Method Classes as Objects Chapter Summary Further Reading P1. Prologue序言部分讲了很重要的一点，Python 最优秀的地方就是其统一性。 Pythonic 体现在使用的 Python Data Model 来表述，其途径主要编写特殊方法 (Special/Magic Method) Iteration Collections Attribute access Operator overloading Function and method invocation Object creation and destruction String representation and formatting Managed contexts (i.e., with blocks) C01. The Python Data Model扩展阅读：http://zopeinterface.readthedocs.io/en/latest/ A Pythonic Card Deck1234567#### 1. 案例一：纸牌 nametupleCard = collections.namedtuple('Card', ['rank', 'suit'])# Card 是一个类# 重载到 Cards(object) 的 __init__ , __len__ , __getitem__# 重载可以之后可以使用 [] 语法 ( [0] [-1] random.choice(cards) [:3] [12::13] for in sorted reversed,sorted(cards, key=calc_score) card in cards ),# 还可以重载 __setitem__, 之后就可以 shuffle# 重载 __repr__ , __abs__ , __bool__ , __add__ , __mul__ 可以 repr() abs() bool() + * How Special Methods Are Used1234obj.__len__()len()obj.__ Overview of Special Methods对于内置类型 (list, str , bytearray) 解释器在调用特殊方法的时候调用 C 库，比如 CPython 实现的 len 方法一般直接会调用 PyVarObject C Struct ob_size 特殊方法往往并不是显示调用，而是被隐式调用。比如 init 在 new 中的作用，比如 for item in items 世界上会调用 iter(items), 这也会隐式调用 items.iter() . 一般当大量使用特殊方法的时候，都是在进行元编程。 12bool(x) 先调用 x.__bool__() , 如果 x.__bool__() 没有实现，则调用 x.__len__(), 如果为 0 则返回 Falsesorted(arr) 可以直接返回 arr，arr.sort() 是排序内部。 特殊方法名 （有操作符） 种类 方法名 String/Bytes repr , str , format , bytes Conversion to number abs , bool , complex , init , float , hash , index Emulating collections len , getitem , setitem , delitem , contains Iteration iter, reversed , next Emulating callables call Context management enter, exit Instance creation &amp; destruction new , init , del Attribute management getattr , getattribute , setattr , delattr, dir Attribute descriptors get , set ,delete Class service prepare , instancecheck , subclasscheck 特殊方法名 （无操作符） 种类 方法名 Unary numeric operators neg , pos , abs Rich comparison operators lt , le , eq , ne , gt , ge Arithmetic operators add ,sub , mul ,truediv ,floordiv ,mod , divmod , pow , round round Reversed arithmetic operators radd , rsub , rmul , rtruediv, rfloordiv , rmod , rdivmod, rpow Augmented assignment mathmatic iadd , isub , imul , itruediv, ifloordiv Bitwise operators invert , lshift , rshift , and , or Reversed bitwise operators rlshift , rrshift , rand , rxor , ror Augmented assignment bitwise ilshift , irshift , iand , ixor , ior Why len Is Not a Method1因为对 不同类型并不是一定调用 __len__ , 对于基本类型查看 c struct 中长度，对于其他类型直接调用 __len__ , 这种区分对待 P2. Data StructureC02. An Array of SequencesStrings, lists, byte sequences, arrays, XML elements, and database results share a rich set of common operations including iteration, slicing, sorting, and concatenation. Overview of Built-in SequencesC 实现的按照 item 是否为同一类型分为： Container sequences: list, tuple, and collections.deque can hold items of different types. Flat sequences: str, bytes, bytearray, memoryview, and array.array hold items of one type. C 实现按照 item 是否可修改分为： Mutable sequences: list, bytearray, array.array, collections.deque, and memoryview Immutable sequences: tuple, str, and bytes List Comprehensions and Generator Expressions12345new_items = [func(a) for item in items]new_items = [ str(x) for x in range(100) if x % 2 == 0]new_items = list(map(str,list(filter(lambda x: x % 2 == 0 , list(range(100))))))# 可写成new_items = list(map(str,filter(lambda x: x % 2 == 0 , range(100)))) list 往往和 map filter 以及 listcomp 用于创建简单的序列 Tuples Are Not Just Immutable Lists 解包赋值 不要手贱加逗号 下划线可以用作临时变量 （但是 django 中下划线用于中英文） 123456a, b, *rest = range(5) # (0, 1, [2, 3, 4])a, b, *rest = range(3) # (0, 1, [2])a, b, *rest = range(2) # (0, 1, [])a, *body, c, d = range(5) # (0, [1, 2], 3, 4)*head, b, c, d = range(5) # ([0, 1], 2, 3, 4) namedtuple 123456City = namedtuple('City', 'name country population coordinates')tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))tokyo.populationtokyo.coordinatestokyo[1]City._fields # tuple Slicing为何 Slice 和 Range 会排除 最后一个 Item? 书中讲的太复杂，其实这个和尺子是一个作用，尺子从 0 刻度开始，这样方便丈量。 比如说： items[0:10] 为 10 厘米 items[10] 为 10 刻度后一个单位，即 items[10:11] items[2:] 为 2 刻度后面若干个单位 items[::3] 以三为单位，从 0 刻度开始，最后为结尾，每三个 1a[i, j] # 调用 a.__getitem__((i, j)) Augmented Assignment with Sequences123456789对于不可变类型 赋值 l *= 2 在内存中则是创建了新的两个长度的元祖，然后赋值而由于字符串则需要注意，str_a += "str b" , 虽然为不可变变量，但并不需要拷贝整个字符串（特殊情况）, 但字符串的拼接建议还是"".join()t = (1, 2, [30, 40])t[2] += [50, 60]# 结果为既赋值成功，又报错# 但 t[2].extend([50, 60]) 可以赋值成功import disdis.dis('s[a] += b') # 可以查看字节码 尽量不要在不可变变量内保存可变变量 t[2] += [50,60] 并不是原子操作，因为，当做了一半的时候，抛出的错误。 list.sort and the sorted Built-In Function对于 sort 和 sorted 来说，reverse 代表 desc,key 为单参数用于计算每一个值的结果的函数。list.sort 直接针对列表排序，并且返回 None（出于编程习惯的问题，直接返回 None 的函数大多是对程序有一定的修改） Managing Ordered Sequences with bisect1234567891011import bisectbisect -&gt; bisect_rightbisect_leftinsort -&gt; insort_leftinsort_right# 搜索可以用来划分档次def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): i = bisect.bisect(breakpoints, score) return grades[i][grade(score) for score in [33, 99, 77, 70, 89, 90, 100]] # ['F', 'A', 'C', 'C', 'B', 'A', 'A'] When a List Is Not the Answerlist 是一种 mix-typed 的数据结构，即可以存放不同种类型的数据结构，由此带来的问题自然是性能问题： list 第一是 mix-typed 的数据结构 动态数组，并非数组 当考虑性能的时候，则需要考虑是不是要换一个更好的数据结构： 适用于类型单一的 array 增删比较多，或者需要使用 FIFO,LIFO, 则使用 deque (double-ended queue) 12345# Arraysfloats = array('d', (random() for i in range(10**7)))# NumPy and SciPy# Deques and Other Queue Deques and Other Queue Deque queue 线程安全 Queue, LifoQueue, and PriorityQueue multiprocessing Queue 和 JoinableQueue asyncio Queue, LifoQueue, PriorityQueue, and JoinableQueue C03. Dictionaries and Sets本章内容： Common dictionary methods Special handling for missing keys Variations of dict in the standard library The set and frozenset types How hash tables work Implications of hash tables (key type limitations, unpredictable ordering, etc.) Generic Mapping TypesHashable ? 一个 obj 的 hash value 在他生命周期内 hash value 是不变的。一个 frozen set 也是 hashable 的（包括每个子元素）. All of Python’s immutable built-in objects are hashable , except that tuple如果一个 tuple 是每个子元素都是 hashable 的话，则该 tuple 也是 hashable 的。 12# 直接在 dict 上面进行操作index.setdefault(word, []).append(location) missing 方法keyerror 会触发 missing 方法 Variations of DictOrderedDict - 有序字典ChainMap - 组装多个字典，按照次序搜索Counter - COUNTER Immutable MappingsSet Theory交差并补 1234567891011121314151617181920212223# 1. 交集s &amp; zz &amp; ss &amp;= z# 2. 差集s - zz - ss -= z# 3. 并集s | zz | ss |= z# 4. 补集s ^ zz ^ ss ^= z# 被包含e in z# 子集s &lt;= zs =&gt; z Dict and Set Under the HoodC04. Text VS Bytes- Character Issues - Byte Essentials - Basic Encoders/Decoders - Understanding Encode/Decode Problems - Handling Text Files - Normalizng Unicode for Saner Comparisons - Sorting Unicode Text - The Unicode Database - Dual-Mode str and bytes APIs - Summary - Further Reading P3. Function as Objectsfunction is the first-class object Higher-Order Functions 设计模式 装饰器 callables function attributes introspection parameter annotations nonlocal declaration references, mutability, 实例生命周期，定制自己集合类 collections and ABCs, 多继承，重载操作符。 生成器 上下文管理器 协程 （包括 Yield) concurrency event-oriented IO asyncio 动态创建类 descriptors class decorators metaclasses C05. First-Class Function- Treating a Function Like an Object - Higher-Order Functions - Anonymous Functions - The Seven Flavors of Callable Objects - User-Defined Callable Types - Function Introspection - From Positional to Keyword-Only Parameters - Function Annotations - Packages for Functional Programming - Summary - Further Reading C06. Design Patterns with First-Class Functions- Refactoring Strategy - Command - Summary - Further Reading C07. Function Decorators and Closures- Decorators 101 - When Python Executes Decorators - Decorator-Enhanced Strategy Pattern - Variable Scope Rules - Closures - The nonlocal Declaration - Implementing a Simple Decorator - Decorators In the Standard Library - Stacked Decorators - Parameterized Decorators - Summary - Further Reading P4. Object-Oriented IdiomsC08. Object References, Mutability, and Recyclingreference variable : variable 不是盒子，贴在盒子上的标签。 赋值并非创建 Copy赋值给一个值并非改变之前绑定的值，而仅仅是重新绑定 rebinding函数由于参数为 reference, 所以可以修改 mutable 的变量函数参数不应当初始化为可修改的值。 id 与 == : 内存值 和 值相等copy 默认是浅拷贝函数参数是引用GC 使用的引用计数，通过 weakref.finalize 可以增加 obj 被回收的回调函数强引用和弱引用，weakref 具体使用场景？ https://pymotw.com/3/weakref/One example is a class that wants to keep track of all its current instances. This can be done with weak references, a low-level mechanism underlying the more useful collections WeakValueDictionary, WeakKey Dictionary, WeakSet, and the finalize function from the weakref module.公用字符串字面量和小的数的技巧叫做 interning PS:1在 IPython 中 _ 为某个表达式返回的值 - Weak References - Tricts Python Plays with Immutables - Summary - Further Reading C09. A Pythonic Object- Object Representations - Vector Class Redux - An Alternative Constructor - classmethod VS staticmethod - Formatted Displays - A Hashable Vector2d - Private and &quot;Protected&quot; Attributes in Python - Saving Space with the slots Class Attribute - Overriding Class Attributes - Summary - Further Reading C10. Sequence Hacking , Hashing , and Slicing- Vector: A User-Defined Sequence Type - Vector Take #1: Vector2d Compatible - Protocols and Duck Typing - Vector Take #2: A Sliceable Sequence - Vector Take #3: Dynamic Attribute Access - Vector Take #4: Hashing and a Faster == - Vector Take #5: Formatting - Summary - Further Reading C11. Interfaces: From Protocols to ABCs- Interfaces and Protocols in Python Culture - Python Digs Sequences - Monkey-Patching to Implement a Protocol at Runtime - Alex Martelli&apos;s Waterfowl - Subclassing an ABC - ABCs in the Standard Library - Defining and Using an ABC - How the Tombola Subclasses Were Tested - Usage of register in Practice - Geese Can Behave as Ducks - Chapter Summary - Further Reading C12. Inheritance: For Good or For Worse- Subclassing Built-In Types Is Tricty - Multiple Inheritance and Method Resolution Order - Multiple Inheritance in the Real World - Coping with Multiple Inheritance - A Modern Example: Mixins in Django Generic Views - Chapter Summary - Further Reading C13. Operator Overloading: Doing It Right 依据我的经验。除非特别适合，比如说矩阵相加，否则不要进行操作符重载。 因为 加减乘除之类的操作符本身就容易有二义性。 P5. Control FlowC14. Iterables, Iterators , and Generators- Sentence Take #1 : A Sequence of Words Iterables VS Iterators - Iterables Versus Itertors - Sentence Take #2 : A Classic Iterator - Sentence Take #3 : A Generator Function - Sentence Take #4 : A Lazy Implementation - Sentence Take #5 : A Generator Expression - Generator Expressions : When to Use Them - Another Example : Arithmetic Progression Generator - Generator Functions in the Standard Library - New Syntax In Python 3.3 : yield from - Iterable Reducing Functions - A Closer Look at the iter Function - Case Study : Generators in a Databse Conversion Utility - Generators as Coroutines - Chapter Summary - Further Reading C15. Context Managers and else Blocks- Do This , Then That: else Blocks Beyond if - Context Managers and with Blocks - The contextlib Utilities - Using @contextmanager - Chapter Summary - Further Reading C16. Coroutines- How Coroutines Evolved from Generators - Basic Behavior of a Generator Used as a Coroutine - Example: Coroutine to Compute a Running Average - Decorators for Conroutine Priming - Coroutine Termination and Exception Handing - Returning a Value from a Coroutine - Using Yield from - The Meaning of yield from - Use Case: Coroutines for Discrete Event Simulation - Chapter Summary - Further Reading C17. Concurrency with Futures- e.g. Web Downloads in Three Styles - Blocking I/O and the GIL - Launching Processes with concurrent.futures - Experimenting with Executor.map - Downloads with Progress Display and Error Handling - Chapter Summary - Further Reading C18. Concurrency with asyncio- Thread VS Coroutine : A Comparison - Downloading with asyncio and aiohttp - Running Circling Around Blocking Calls - Enhancing the asyncio downloader Script - From Callbacks to Futures and Coroutines - Writing asyncio Servers - Chapter Summary - Further Reading P6. MetaprogrammingC19. Dynamic Attributes and Properties- Data Wrangling with Dynamic Attributes - Using a Property for Attribute Validation - A Proper Look at Properties - Coding a Property Factory - Handling Attribute Deletion - Essential Attributes and Functions For Attribute Handling - Chapter Summary - Further Reading C20. Attribute Descriptors- Desciptor Example: Attribute Validation - Overriding VS Nonoverriding Descriptors - Methods Are Descriptors - Descriptor Usage Tips - Descriptor docstring and Overriding Deletion - Chapter Summary - Further Reading C21. Class Metaprogramming- A Class Factory - A Class Decorator for Customizing Descriptors - What Happens When: Import Time VS Runtime - Metaclasses 101 - A Metaclass for Customizing Descriptors - The Metaclass prepare Special Method - Classes as Objects - Chapter Summary - Further Reading 相关链接 https://docs.python.org/3/reference/datamodel.html Python Cookbook Python Essential Reference, 4th Edition The Art of the Metaobject Protocol UPDATE: 日期 类型 详细操作 2017-04-18 动笔 初始化本文结构 2017-04-26 重构 添加目录和阅读笔记]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>碎碎念</tag>
        <tag>书单与简评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Full Stack Django DevOps Cheatsheet]]></title>
    <url>%2F2017%2F04%2F06%2FFullStackDjangoDevOpsCheatsheet%2F</url>
    <content type="text"><![CDATA[前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Django 全栈开发 的一些小经验和踩坑记录。本文没有安装和常识性配置的介绍，仅仅是一笔带过项目中遇到的一些点点滴滴的小问题。算是踩坑和心得笔记吧。 不仅仅是 Django, 还有 Django 涉及到的： 组件：PostgreSQL,RabbitMQ,Redis,MongoDB,Ngnix 技术：爬虫技术，数据库设计，GIS 记录，单页 / 多页 (VueJS+Webpack+DjangoRestFramework), 自动化部署 轮子：Django 紧密关联的可以极大推进项目开发的轮子 于是，本文的内容就如下： 前后端分离 自动化部署 数据库相关 其他踩坑经历 0x01. 前后端分离前后端分离是提高团队开发的一个重要的开发策略，前后端分离之后，后端和前端交流好 JSON 格式，并行开发，局域网中放置一台服务器，后端写好一个功能，推送代码，由 gitlab 触发 Runner 自动交付到局域网的服务器上。这样的话，前后端可以并行开发，从而摆脱每一次开发过程不可避免，前端编写模板，然后由后端套用模板，出了问题，前端修改模板，后端接着修改模板… 循环往复，不曾更改的问题，在这种职责分明的情况下也不会出现背锅侠的问题。 在往常的开发过程中，而如果 Ajax 比较多或者前端写的代码质量稍微低一些，那么倒霉的事情就发生了，后端和前端的沟通成本那是相当的高。推锅的事情也会发生。 而新的开发过程中，如果上级有界面上的需求，基本上只需要前端更新一下代码，推送，就可以立即看到效果。同样的，后端也是如此。 这就是我选择前后端分离的初衷 – 将主要的精力放在开发上面。而不是套用模板和编辑 Ajax 过程中带来的沟通问题。 在前后端配合上： 后端选择 Django,Restful 框架选择了 DjangoRestFramework, DRF 的优点在于可以自动生成 API 界面，让前端对照着表单进行请求接口的测试。于是局域网的那一台可以配置为 Debug 模式，生产机器就可以关闭 DEBUG 模式。 前端选择 VueJS, 选择这个小而精美的框架一方面是基于团队的开发水平考虑，如果使用太激进的框架 React, 可能遇到问题无法在短时间内解决。由于选用了 VueJS, 也就选用了 Vue 全家桶，通过 Webpack2 进行配置完成基本的打包任务，通过 config 读取环境变量进行生产环境和发布环境的 apiurl 的分离 代码提交选择 Coding.NET 用于提交代码，在局域网中选择 Gitlab 用于提交代码，配上 Gitlab CI 进行持续集成，每次提交代码直接直接构建本地发布。前后端合作亲密无间。 前后端分离有什么缺点呢？ 必须强行升级 Https 开发时候需要关掉 Django 的同源策略 IE8– 不兼容 1.1. Django 和 他的小伙伴们Django 适用于快速开发，对于创业公司来说，是不错的快速开发语言。 不仅仅是因为 Python 表达力比较强，更重要的是 Django 有很多高质量的包可以使用。 Django Debug Toolbar DjangoRestFramework Django Extensions 1.4. Django 的奇技淫巧Django Model Save If Changed 0x02. 自动化部署写程序 一般就是开发测试部署。 话虽然这么时候，但是在具体的实践过程中，还是有很多很多坑需要注意的。 比如，仅仅就开发环节来说，团队协作怎么搞？你说可以用 GIT 作为版本管理工具，代码托管。那我问你，这个 Web 开发过程中前端开发模板，后端套用模板怎么搞？你说，前后端分离，那前后端分离后 Http 请求被劫持怎么办，跨站攻击怎么搞……甚至如果是一个人开发的话，直接拉一台服务器做做部署，定期更新到网站上就行了。但如果是团队协作呢？前端提交了代码，产品经理过来说，你更新一下服务器，后端提交了代码，前端过来说，你更新一下服务器，过程琐碎而耗时。大量的时间就浪费在了这种枯燥的事情上了。两个后端，一个前端的情况下，每天本地发布（交付）的次数就已经是相当惊人（大概是前后端每天提交 5 次左右），如果以后是 3 个后端，三个前端，那我作为主程，每天就写不了代码了，这种情况是断不能忍的。 这个时候，就需要想着把团队协作开发流程优化好： 在我刚开始进行开发的时候，使用 bash 配合 Ansible 在本地和上线的 Ubuntu 16.04 上面自动化能够自动化的大部分工作，程序员在本地开发的时候，只需要进行开发，然后推送代码到 repo, 剩下的诸如自动化测试集成到系统中，则全部自动化。 2.1. 使用场景经过研究，我确定了理想中的使用场景： 前端与后端提交代码到代码托管上面的时候，直接集成，构建，Stage 到服务器。 到上线的时候，由我执行 Ansible 进行上线。 2.2. 实施方案在这个流程中，我需要安装如下的软件： Gitlab Gitlab-CI-Runner : 用于解决代码托管，项目的基本成长，以及持续化集成 PostgreSQL MongoDB Redis RabbitMQ Nginx Python 以及 Python 扩展的依赖包 其他 配置文件为 3 类： test stage production 硬件设备 3 台： 第一台为 Gitlab 部署的软件 第二台为 Stage 环境 （本地局域网持续交付）的机器 第三台为 Server （阿里云） 机器 注：最初使用 Ubuntu 机器，最终确定使用 Docker 镜像进行构建 2.3. 持续交付当前端工程师 Push Master 分支到 Repo 上的时候，执行 Job 更新网站当后端工程师 Push Master 分支到 Repo 上的时候，执行 Job 更新网站 Push Master 分支，这个自然无需多说，问题是怎么执行 Job 呢？ Gitlab CI Multi Runner 在一台 stage 的机器上安装 gitlab ci multi runner , 并且在该机器上注册 runner 为 shell , 这意味着 runner 会以 gitlab-runner 用户的权限进行测试 , 你需要 uninstall然后 install –user=root 一下，然后重启，即可在 gitlab-ci.yml 上。 修改文件123gitlab-runner register # 然后填入相关信息vim /etc/gitlab-runner/config.toml # 接着进行修改 123456789concurrent = 1check_interval = 0[[runners]] name = "yadjangoweb" url = "http://192.168.1.139/ci" token = "325asd65f4e7xa9faasda8da" executor = "shell" [runners.cache] 2.4. Dockerize ApplicationDocker 以其轻量级和类似于版本管理的软件方式吸引了我。于是，准备将所有的 Service 都 Docker 化。 拿 Django 程序来说，首先 Django 程序依赖三个组件 redis / postgresql / rabbitmq , 完成这些组件的安装之后才能进行下一步的操作。 0x03 数据库相关1. 数据库设计PostgreSQL Array 在爬虫方面可以用来标记一个 Record 的处理状态PostgreSQL Range 用来判断范围也是一个比较高效的选择（用空间 gist 索引取代两个索引） GeoDjango 和 PostGIS 非常配 2. 数据迁移1.1. 第一次数据迁移之 MySQL 转 PostgreSQL第一次数据迁移的时候基于 PostgreSQL 社区里面有个大杀器，叫做 PostGIS, 通过 PostGIS, 可以很方便的拥有和国内一些地图公司匹敌的算法。抛开算法实现的效率问题，基本上可以满足日常的开发需求，当时数据量不算大，使用 mysqldump 下来也就 500M 左右，而且行数大约 700W 条，于是使用了一个很笨的方法，就是将数据库使用 Django 命令 dump 成 json, 接着修改配置重新导入新数据库。 这种方式的缺点就是效率低而且太吃内存了，当时 16G 的服务器满内存，满交换内存地搞了一个上午。 1.2. 第二次数据迁移之重新 makemigrations为什么要重新 makemigrations 呢，因为糟糕的事情发生了。 有个需求，需要重新定制用户登录认证系统。用户登录认证系统是最最应该在项目开始的时候编写的，这就是项目的基石，这个需求就恰似在房子盖到第三层的时候突然要把地基给加固。 Django 中如果使用了 auth 模块，则 auth.user 是最先被迁移到数据库中的，而如果你经过权衡继承 AbstractUser 并且 makemigrations 生成个迁移文件 0001_initial.py 后，在正常的情况下不容易将 migration 修改应用到数据库中。 如果我偏要勉强呢？ 当然是可以勉强的，删掉数据库中已经记录下来的 auth.user migration 的相关记录即可。 那我为什么还是需要重新编写 migration 呢？ 因为之前对数据库的结构调整比较频繁，多达 138 次，而在 138 次调整数据结构之后，再去撤销第一次数据表的迁移操作的时候，则无异于厨子做菜要把牛排做 8 分熟，但是厨子做到 7 分熟的时候，突然顾客说，我要 5 分熟的牛排。那只能重新来了。 顺手精简掉 138 个文件。 如何做呢？ 数据的迁移在没有表与表之间的关联的时候是很好办的，CSV, 标准 SQL 文件。 有表关联的情况下则需要权衡数据量来进行迁移，假如数据量在 10 来个 G 的时候，读到内存中，按照数据表的依赖关系，自下而上逐层迁移即可。 数据量大的时候，则需要去约束，去索引，然后转 CSV/SQL, 迁移到数据表中。如果表依赖不复杂的话，直接 psql 命令重定向数据也可以。 但是呢，由于使用了 Django, 在数据量不大的时候，完全可以使用 Django 的 ORM 来做迁移。 我在 Google 了一下，发现下面一个脚本，于是设置数据库为新数据库 default 和 depressed 1234567891011121314151617181920def batch_migrate(model): # remove data from destination db before copying # to avoid primary key conflicts or mismatches if model.objects.using('default').exists(): model.objects.using('default').all().delete() # get data form the source database items = model.objects.using('depressed').order_by("pk").all() count = len(items) # process in chunks, to handle models with lots of data for i in range(0, count, 10000): chunk_items = items[i:i + 10000] print("已经迁移数据", i) model.objects.using('default').bulk_create(chunk_items) # many-to-many fields are NOT handled by bulk create; check for # them and use the existing implicit through models to copy them for m2mfield in model._meta.many_to_many: m2m_model = getattr(model, m2mfield.name).through batch_migrate(m2m_model) 按照表与表之间的依赖关系，逐个迁移到数据库中搞定。 1.3 sequence 问题在写 Django 的时候发现的时候无论如何都无法保存新的 item. 原来的代码为： 123item = Item.objects.get_or_create()item.foo = 1item.save() 报错信息是 Integrety, 报 duplicated 错误（下面的代码当然是打了马赛克了） 12django.db.utils.IntegrityError: duplicate key value violates unique constraint "foo_item_pkey"DETAIL: Key (id)=(111111) already exists. 那么，问题来了： 挖掘技术哪家强？ 啊，不是 How To Solve This? 经过猜测，而 get 到已有的 item 设置并且保存的话，并不会出现这个问题。问题主要出在 create 上面。 于是编写代码验证一下是不是猜想正确 12345678try: item = Item.objects.get()except Exception: item = Item.objects.create()# do somethingitem.save() duplicate 的问题肯定是多次存同样的不能重复的字段。 但尼玛，我之前做测试的时候考虑过这个逻辑呀？换而言之，这种问题不应该出现，如果出现了问题，八成是 ORM 用的不对。 印象中这种问题 Google 一下 Integrety Duplicate Django PostgreSQL 一般就能出来了。 最后找到解决方案：http://centoshowtos.org/web-services/django-and-postgres-duplicate-key/ 在终端进入 psql 查询 sequence 最新值 12345select start_value, last_value, max_value from dt_crawler_item_item_id_seq; start_value | last_value | max_value-------------|------------|--------------------- 1 | 111110 | 9223372036854775807 而我们查看一下 item_id 的最大值 12345select max(item_id) from app_model_item; max--------- 111111 重置 sequence last_value 值到最新即可。 1alter sequence app_model_item_item_id_seq restart with 111111; 当数据库每次插入一条非指定主键的记录，则获取 last_value(111110), 加 1 得到当前的主键接着插入。但这个过程无异于数据库中已经有了一个 pk 为 111111 的记录，再插入一条。于是报错。 回顾这个问题，该问题是由于 PostGres 的 sequence 造成 pkey 相等，换而言之，postgres 应该在有一个 pk 值为 111111 的时候，插入一个无主键的记录，PostgreSQL 获取 sequence+1(111110 + 1) 得到它认为当前的主键值，接着再一次插入了主键为 111111 的这个值。 这个过程相当于依次插入两个条 ID 相同的记录。12INSERT INTO table(id, column2, …) VALUES (111111, value2, …);INSERT INTO table(id, column2, …) VALUES (111111, value2, …); sequence 避免了每一次 max 查找带来的性能损失，一方面带来了方便，也带来了隐藏的坑。 如果以后这个问题比较多的话，参考下面的源码对文本进行修改。 https://github.com/ASKBOT/django-postgresql-fix-sequences/blob/master/postgresql_sequence_utils/utils.py 0x04 WebServer目前使用的 WebServer 是用 Nginx 做反向代理，将请求通过 unix socket 转发到 gunicorn，gunicorn 作为 django 实际上的 webserver。 unix socket 和 gunicorn 的 REMOTE_ADDR 问题Django Admin 模块在访问 某个页面的时候特别特别慢，而在我的机器上一切正常，我怀疑的是数据库的问题，于是，那么首先要知道数据库的查询语句，于是想借用 django debug toolbar 来 profiling, 于是问题来了，我在局域网模拟真机环境，结果无论如何都无法呈现 Django Debug Toolbar, 问题八成出现在 Django 配置环境 或者 Nginx 上面（当然，最后发现是 Gunicorn 的锅）. 在 经过一段时间的排查，认为是 Nginx 的问题，在相关配置添加下面设置 Header, 1proxy_set_header X-Forwarded-For $remote_addr; 结果依旧无法获取 request.Meta[“REMOTE-ADDR”] 经过搜索发现不止我一个人的问题：https://github.com/benoitc/gunicorn/issues/797 最后发现是 Http 请求从 nginx 这儿经过 unix socket 转发到 gunicorn.sock 下默认是没有赋值 REMOTE-ADDR 的， 那么，这个在 HTTP Header 层次的东西，没有在 gunicorn 层次解决，那就只能在 django 层次解决。 给 Django 添加中间件如下，放在 djangodebugtools 的前面。123456class XForwardedForMiddleware(MiddlewareMixin): def process_request(self, request): if request.META.get("HTTP_X_FORWARDED_FOR", False): request.META["HTTP_X_PROXY_REMOTE_ADDR"] = request.META["REMOTE_ADDR"] parts = request.META["HTTP_X_FORWARDED_FOR"].split(",", 1) request.META["REMOTE_ADDR"] = parts[0] 解决。 Nginx Gzip 压缩当 json 数据量比较大的时候，则必须要考虑开启压缩。一般情况下，虽然这个可以在 Django 层次完成，但是这么做还不如在 nginx 层次完成。 12345678gzip on;gzip_disable "msie6";gzip_vary on;gzip_proxied any;gzip_comp_level 6;gzip_buffers 16 8k;gzip_http_version 1.1;gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; 开启之后，我这边的 一个 220k 的数据缩减到 54k 0x04. 其他踩坑相关4.1 奇怪的文件问题在某一天遇到了一个问题 往常的时候，当文件上传到 Django 中的时候，都可以正常的解析，但是这两天居然不能用了。 12345# 问题代码出现在df = pd.read_excel(file_obj)# 报这个问题 google 几乎没有什么解决方案Invalid file path or buffer object type&lt;class 'django.core.files.uploadedfile.InMemoryUploadedFile'&gt; 更加糟糕的问题出现了，我本人的开发环境和服务器的开发环境基本一致，但，但，但为什么不能用呢？ 分别回滚代码，Nginx 设置，在线上打 Log, 最终确定了是 Pandas 从 0.19 升级到了 0.20 之后出现的一个小问题。最终还原线上 python 安装环境，搞定。]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>VueJS</tag>
        <tag>RestAPI</tag>
        <tag>全栈开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thinking In Python Language]]></title>
    <url>%2F2017%2F03%2F21%2FThinkingInPython%2F</url>
    <content type="text"><![CDATA[本文的内容都是一些简略的笔记。 前言本文诞生于利用 Topic Reading 方法读 Python 和 JavaScript 若干本技术书籍这个过程中结合自己的开发常见场景记录下来的一些笔记。 0x00 简介1. 为什么是 Python选 Python, 很大程度上是因为 Python 的快速开发。 当然，快速开发（这里的开发包含部署）这个词也往往会被误解。什么叫做快速？我用一个 CMS 框架快速搭建出一个网站这是否叫做快速？ 每一次部署的时候，如果使用 Java 或者是 Go, 部署的时候直接 maven 编译打包，接着把 War 包直接上传到 Tomcat 就结束了。而用 Python 则需要各种虚拟环境，各种稀里哗啦的配置。这种情况下是哪一种快速呢？ Python 有什么好处呢？ 写代码效率高 生态圈好 写代码效率高，这指的是写 Python 代码，而不是运行时。 生态圈好，Web 开发用 Django/Flask , 数据抓取用 Requests , 数据分析清洗用 Pandas, 机器学习。 2. 工具链4. 文档5. 社区6. 书籍0x01 基本概念 程序 = 算法 + 数据结构 这句话当然是不全面的，但并不影响这句话在计算机世界里面的地位。 依我看来，对我的启发大致是： 我会把 API 的调用和数据结构以及算法想清楚，然后才动手把代码分解成伪代码。 1. 数据类型数据类型按照不同的划分标准可以进行不同的划分： 按照复杂性可以这么划分： 简单类型 复杂类型 按照复杂性可以这么划分： 基本类型 引用类型 按照数据结构可以这么划分： 集合结构 : 串 线性结构 : 线性表 （单链表，静态链表，循环链表，双向链表，栈，队列) 树形结构 : 树（二叉树，B+ 树，红黑树） 图形结构 : 图 2. 操作操作对于一些基本的数据类型，操作为 加减乘除取余数位运算等等 对于复杂的一些数据类型，则需要对数据结构多一些了解。 比如，对队列而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对 hash 而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字典而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字符串而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？ 那字符串来说，Java 推荐使用 StringBuilder 来合并多个字符串，Python 推荐 join 多个字符串等等。 操作3. 语句0x02 中级概念函数作用域模块模块，这个概念，可大可小，大的时候，把一个程序说成是模块，小的时候，可以把一个文件，甚至你说这一个函数是一个模块，也行。 这里的模块指的是一个包下的函数。 面向对象面向对象有三大概念： 封装 继承 多态 错误 / 调试测试异常处理实际上可以考验一个程序员编写代码的健壮性。 事实上来说，代码写的健壮是一个程序员必备的素养。但其实在开发过程中，出于对项目进行赶工上线，需要对程序的健壮性做出一定的取舍。并且，在编写客户端，服务端，网页前端的时候基本上都会遇到这个问题。什么时候选择健壮的程序，什么时候选择是还可以的程序。需要自己的经验。 IO 编程进程和线程多线程 Python 多线程约等于并发。 多进程GILGlobal Interpreter Lock 并不是所有的解释器语言都有 GIL （尽管 Python 和 Ruby 里面都有）, 也并不是没有尝试过去除 GIL, 但是每次去除都会导致单线程性能的下降。所以暂时保留。 GIL 对程序中的影响： 一个线程运行 Python , 而其他 N 个睡眠或者等待 I/O - 同一时刻只有一个线程对共享资源进行存取 , Python 线程也可以等待 threading.Lock 或者线程模块中的其他同步对象； 协同式多任务处理如果有两个线程，同时进行 IO 请求，当其中一个线程连接之后，立即会主动让出 GIL, 其他线程就可以运行。 当 N 个线程在网络 I/O 堵塞，或等待重新获取 GIL，而一个线程运行 Python。 让出之后还要执行代码呀，所以要有个收回 GIL 的动作。 抢占式多任务处理Python 2 GIL , 尝试收回 GIL 为 执行 1000 字节码。Python 3 GIL , 尝试收回 GIL 检测间隔为 15ms 线程安全原子操作：sort 之类不需要非原子操作：n=n+2 的字节码分为 加载 n , 加载 2 , 相加，存储 n, 四个步骤，由于不是原子性，很可能被由于 15 ms 而被打断。 当然，懒人一向是 : 优先级不决加括号，线程不决加 lock 对于 Java, 程序员努力在尽可能短的时间内加锁存取共享数据，减轻线程的争夺，实现最大并行。但 Python 中，线程无法并行运行，细粒度的锁就没有了优势。 正则表达式0x03 高级技巧0x04 标准库常用内建模块系统化模块 Introduction Built-in Functions Built-in Constants Built-in Types Built-in Exceptions Text Processing Services Binary Data Services Data Types Numeric and Mathematical Modules Functional Programming Modules File and Directory Access Data Persistence Data Compression and Archiving File Formats Cryptographic Services Generic Operating System Services Concurrent Execution Interprocess Communication and Networking Internet Data Handling Structured Markup Processing Tools Internet Protocols and Support Multimedia Services Internationalization Program Frameworks Graphical User Interfaces with Tk Development Tools Debugging and Profiling Software Packaging and Distribution Python Runtime Services Custom Python Interpreters Importing Modules Python Language Services Miscellaneous Services MS Windows Specific Services Unix Specific Services Superseded Modules Undocumented Modules 0x05 第三方库 Requests : API 人性化 0x06 代码质量正确性 外部不该引用 protected member （单下划线） lambda 为一次使用，最好不要赋值。 不要给 buildin 函数赋值 py3 直接 super() for in else 如果不内置 break 则出会在最后 for in 为 empty 的时候再执行 else 中的语句 context exit 如果不 catch 掉异常让其自然向上一级抛出错误的话，必须为 (self, exception_type, exception_value, traceback): 不要在 init 里面 return 数据 不要混用 tab 和 space 4 个 space 缩进 staticmethod 直接是 参数，classmethod 第一个参数为 cls 可变的 default value 是不能作为 参数的。（可能是解释器在确定函数的定义的时候完成赋值？) 遵循 exception hierachy https://docs.python.org/3/library/exceptions.html#exception-hierarchy defaultdict defaultdict(lambda : 6) , 必须 callable 尽量 unpack 赋值 字典用获取用 get(“myk”,None) , 赋值用 dictionary.setdefault(“list”, []).append(“list_item”) 可维护性 避免使用 import * , 我觉得这点值得商榷 , 如果是某个模块下，完全可以先把模块拆分成多个，最后 import 进来，接着使用 all. getxxx 获取实际值，如果不为实际值，返回 None 显然不如 try catch 来的实在。 避免使用 global 命名要注意 动态创建方法 , 我觉得这点值得商榷。 可读性 不要检查，如果可能有异常，尽量抛出异常来 trycatch 解决。 a is None , if flag isinstance , not type(r) is types.ListType “{name}{city}”.format(**info_dict) for k , v in infodict.items() 使用 poiinfo = namedtuple(“poiinfo”,[“name”,”lng”,”lat”]) 返回 poiinfo[‘上海’,121.00,23] 最后返回值打印 poi.name , poi.lng , poi lat for numbers_value, letters_value in zip(numbers, letters): enumerate 如果能用 listcomp 则不使用 map 和 filter 安全性性能 用 set d.iteritems() 比 items() 省内存 0xEE 文章更新 2017-05-11 19:43:00 : 增加代码质量模块]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>重构技巧</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thinking In Programming Language]]></title>
    <url>%2F2017%2F03%2F21%2FLearnProgrammingLanguage%2F</url>
    <content type="text"><![CDATA[如何学习一门编程语言0x00 前言本文的内容都是一些个人的比较虚的经验。泛泛而谈。 很多人得出一些结论，往往是样本就一个。比如说一个只用过 PHP 的人叫嚣 PHP 是最好的语言。 但即便是用过几种语言，得出的经验依然是片面的。 所以，我得出的结论，不完全是对的，至少是我个人的经验。 本文诞生于利用 Topic Reading 方法读 Python 和 JavaScript 若干本技术书籍之际。 0x01 编程语言胡论在我看来，一个人说他会且只精通一门编程语言是很让我不能理解的事情，在我看来，什么编程语言框架上手两三天就能去写，但是这严格意义上应该叫做能用，和精通相差甚远。那是不是说写的时间长的人经验就老道了呢？也不见得。下棋下了一辈子是烂棋篓子的人比比皆是。 那我认为什么样子的人才是懂写代码的人。 拥有良好的组织代码的能力的人。 恩，组织代码的能力，一个文件排布混乱的人，不太可能写出整齐严谨的代码，当然，人也可能是复杂的，比如，这个人写的代码挺好，但是生活住处一团糟。 当然这是题外话了，依个人经验而言，学习任何一个复杂的系统，也需要像组织一个东西一样，系统性的学习。 系统化的东西往往像《如何阅读一本书》里面描述一本书的复杂架构那样。 没有一种物质或产品是绝对简单的。所有的东西都是复杂的组合体。当你看一个整体组成复杂的东西的时候，如果只看它如何呈现一体的面貌，那是还没有掌握精髓，你还必须要明白它怎样呈现多个的面貌，但不是各自为政、互不相干的多个面貌，而是互相融合成有机体的多个面貌。如果组成的各个部分没有有机的关联，仅仅是一个集合体罢了。 这就像是一堆砖头跟一栋又砖头建造起来的房子是有区别的。而单一的房子与建造的房子也不相同。一本书就像是一栋单一的房子。一栋大厦，拥有许多房间，每层楼都有房间，有不同的尺寸和形状，不同的外观，不同的用途，这些房间是独立的，分离的，每个房间都有自己的架构和装潢设计，但却不是完全独立与分离的，这些房间使用普通门 / 拱门 / 走廊 / 楼梯串联起来的，即建筑师错位的动线架构，因为这些架构师彼此联结的，因此每一个部分在整体的使用功能上要贡献出自己的力量。否则这栋房子便是不适合居住的。 对于复杂的东西，系统内部的各个部分都是密切相关。 先模块化，用一个快速的方式获得每个模块的全貌，接着不断分解模块为知识单元，最后连接各个子模块和知识单元 下面的内容就是我组织入手学习编程语言的思路。 1.1 编程语言的独一无二性有的人认为所有的编程语言都是一样的，我不这么认为。 我觉得这种想法很初级，所有的编程语言都是有特点的，也是有优缺点的。 举一个我朋友的爱说的很粗俗的例子： 虽然说关了灯全都一个样，但是每一个女孩子都有是独一无二的存在。 这个例子即便是我这种 23 年丰富单身经验的人，依然可以在第一时间捕捉到我这个段子手朋友的意思。 有的偏向于运行效率，有的偏向于开发效率。 有的据说是让人编程时候感到快乐 (ruby)，有的说你生命苦短，为什么不用 Python。 有的偏向于 Web 开发 (PHP)，有的偏向于并发操作 有的是 Windows 上面自动化的小白工具 (Autohotkey) 有的是据说是一次编译，到处运行 (Java) 编程语言往往是上面这些因素的取舍。 你要运行效率，往往开发效率就会打折。 你要开发效率，往往就需要堆更多的机器来提升性能。 你要充分利用某个平台，往往就没有极高兼容性。 你要编程语言省心，往往编程语言就会自作聪明。 1.2 工具链工欲善其事必先利其器，而这个器就是工具链。工具链大致有如下： Mac Homebrew 集成开发环境 编辑器 开发环境里面的 shell cmake 1.3 文档官网的文档是最应该反复查看的东西，这是我现在依然喜欢强调的。 而官网的文档也分为四种 一种是 tutorial – 用于上手对应的软件 / 编程语言 一种是 guide – 用于 Topic Reading 一种是 api document – 用于查看细节 一种是 RTFSC ( Read The Fucking Source Code ) 阅读源码 注：把 StackOverFlow 中某个标签的 Most Votes 的答案，是除了大略看看 tutorial 之外的另一种快速熟悉入门时候的痛点的手段。 当然，其实代码写的足够好的话本身就是一种注释。 1.4 社区社区一般情况下都会有的，但有几个网站特别值得提出来 官网上一般都会放一些比较出色的社区 Github reddit 某个技术对应的 Weekly 订阅 1.5 书籍特别值得一提的是有一个持续不断阅读到有趣的文章的方法： Google 出对应的 书 / Weekly 周报 / 博客，比如 Python Weekly 然后订阅 接着不断的查看列入优质文章的作者的文章，Github 地址啦，他关注的 Repo 啦等等等等。 然后去阅读他的代码 / 博客。 0x02 基础概念 程序 = 算法 + 数据结构 这句话当然是不全面的，这句话经典就经典在高度概括了程序中算法和数据结构的重要性，但并不影响这句话在计算机世界里面的地位。 依我看来，对我的启发是： 我会把 API 的调用和数据结构以及算法想清楚，然后才动手把代码分解成伪代码。最后写成代码。 2.1 数据类型按照复杂性可划分为： 简单类型 复杂类型 按照复杂性可划分为： 基本类型 引用类型 按照数据结构可划分为： 集合结构 : 串 线性结构 : 线性表 （单链表，静态链表，循环链表，双向链表，栈，队列) 树形结构 : 树（二叉树，B+ 树，红黑树） 图形结构 : 图 对于一些基本的数据类型，操作为 加减乘除取余数位运算等等 对于复杂的一些数据类型，则需要对数据结构多一些了解。 比如，对队列而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对 hash 而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字典而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字符串而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？ 那字符串来说，Java 推荐使用 StringBuilder 来合并多个字符串，Python 推荐 join 多个字符串等等。 2.2 语句 声明语句 赋值语句 条件语句 判断的时候不确定操作符优先级的时候，加括号 尽量显式判断，不要用隐式判断。 循环语句 Break 和 Continue 2.3 函数 传值还是传引用 参数 函数或者叫做方法，叫法不同。 函数，我有个很私人的称呼，称它为最小操作模块。 实际上，在编程的过程中，程序员用面向对象的思想进行编码的人可能真的不是很多。把一段长程序按照自己的需求进行切分成若干个函数的倒是比比皆是。 不过按照什么样子的标准来切分一段程序为多个函数，仁者见仁智者见智。 这里面需要注意的事情是： 注意传值（基本类型）和传引用（引用类型） 函数重载 对于不同的编程语言，传值（基本类型）和传引用（引用类型）基本上达成了共识。但在实现函数重载的时候则是有所不同， 比如，Java 里面选择了多写几个函数，Python 则没有这个机制，不过，通过默认参数却可以曲线救国，实现这个机制。 递归函数式编程高阶函数 mapreduce/ filter / sorted / 返回函数 / 匿名函数 / 装饰器 / 偏函数 2.3.1 作用域12345678910111213141516171819202122232425262728293031def outer(): a = 1 def inner(): a = 2 print(a)outer()# 1def outer(): a = 1 def inner(): a = 2 print(a) inner() print(a)outer()# 1# 1def outer(): a = [1] def inner(): a.append(2) print(a) inner() print(a)outer()# [1]# [1, 2] 12345678910111213141516171819202122232425var outer = function()&#123; var a = 1; var inner = function()&#123; a = 2 &#125;; console.log(a); inner(); console.log(a);&#125;outer()# 1# 2var outer = function()&#123; var a = 1; var inner = function()&#123; var a = 2 &#125;; console.log(a); inner(); console.log(a);&#125;outer()# 1# 1 2.3.2 高阶函数 map reduce filter 0x03 中级概念3.1 类和对象面向对象有三大概念： 封装 继承 多态 3.2 模块与包模块，这个概念，可大可小，大的时候，把一个程序说成是模块，小的时候，可以把一个文件，甚至你说这一个函数是一个模块，也行。 这里的模块指的是一个包下的函数。 3.3 错误 / 调试测试异常处理实际上可以考验一个程序员编写代码的健壮性。 事实上来说，代码写的健壮是一个程序员必备的素养。但其实在开发过程中，出于对项目进行赶工上线，需要对程序的健壮性做出一定的取舍。并且，在编写客户端，服务端，网页前端的时候基本上都会遇到这个问题。什么时候选择健壮的程序，什么时候选择是还可以的程序。需要自己的经验。 3.4 IO 编程3.5 正则表达式0x04 高级概念4.1 元编程4.2 并发编程4.2.1 多线程 Python 多线程约等于并发。 4.2.2 多进程4.2.3 协程0x05 标准库5.1 数据结构与算法5.2 字符串与文本5.3 数字日期与时间5.4 迭代器与生成器5.3 文本处理0x06 可维护性代码社区推崇的代码风格调试的若干种姿势0xEE 文章更新 2017-05-11 19:43:00 : 增加代码质量模块]]></content>
      <categories>
        <category>编程思索</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>重构技巧</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『如何阅读一本书』读书笔记]]></title>
    <url>%2F2017%2F02%2F10%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0_%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[前言选择了这本书进行精读是有原因的： 在一个需要大量阅读的时代里，读东西更加有策略。 记得大约是初三的考试比赛，监考老师发了卷子，我们这些人拿到卷子捋起袖子就是写，而监考老师说了一句话： 先看看卷子，然后再写，不要上来就做题。 虽然那次考试并不算理想，最大的收获应该就是这句话。 通过’先预估，然后再做’的意识，我应该是少走了一些弯路的。至少工作效率稍微提升了一些。 但，有了这个先预估一下，然后再做的意识可以减少很多问题，然而并不能更好解决的问题。因为意识这玩意，不是方法，不是策略。知道考虑火候，不懂得把握火候照样做不出好菜。 对应到我看这本书的目的，即是，当需要我能在捋起袖子干之前，找到一个更好的策略，对读书，有一个更好的方法。而不是仅仅是埋下头一通看。 也是为了给自己更好的啃源码，看文档激发一些更好的灵感。 这是从非专业领域里面找灵感的一种方式，即所谓：汝果欲学诗，工夫在诗外。 本文目录 Table of Contents - 本文目录 《如何阅读一本书》目录简评 问与答 CQ1: 本书整体讲了什么？ SQ1: 较好的阅读一本书的步骤 确定要补充那些知识 / 技能体系 筛选书籍阶段 : 过滤不适合的书 检视阅读阶段 : 判断一本书的质量 检视阅读阶段 STEP1 : 大体定位这本书。 检视阅读阶段 STEP2 : 检视阅读的一些误区： 分析阅读阶段 : 全方位吃透这本书 分析阅读第一阶段：找出一本书在谈写什么的规则 分析阅读第二阶段：诠释一本书的内容的规则。 分析阅读第三阶段：评论一本书的规则 主题阅读阶段 : 纳入自己的知识体系 SQ2: 上面关于阅读一本书的步骤是适用于所有书，即使通用的步骤吗？ 分析阅读之如何阅读实用型的书 分析阅读之如何阅读历史书 SQ3: 关于读书的有哪些误区 速读 随便翻翻 陷入细枝末节 EQ1: 为什么要重新学习如何阅读书籍的策略与方法 相关链接 《如何阅读一本书》目录简评本书的翻译版书籍的目录如下： 第一篇：阅读的层次 ch01: 阅读的活力与艺术 ch02: 阅读的层次 ch03: 阅读的第一个层次：基础阅读 ch04: 阅读的第二个层次：检视阅读 ch05: 如何做一个自我要求的读者 第二篇：阅读的第三个层次：分析阅读 ch06: 一本书的分类 ch07: 透视一本书 ch08: 与作者找出共通的词义 ch09: 判断作者的主旨 ch10: 公正的评断一本书 ch11: 赞同或反对作者 ch12: 辅助阅读 第三篇：阅读不同读物的方法 ch13: 如何阅读实用型的书 ch14: 如何阅读想象文学 ch15: 阅读故事，戏剧，诗的一些建议 ch16: 如何阅读历史书 ch17: 如何阅读科学和数学 ch18: 如何阅读哲学书 ch19: 如何阅读社会科学 第四篇：阅读的最终目标 ch20: 阅读的第四个层次：主题阅读 ch21: 阅读与心智的成长 这本书的目录看起来比较奇怪，分为四个部分，但是第一篇和第二篇分类比较混乱，ch03,ch04, 第二篇，ch20 不是应该是同一级嘛？ 以为找英文原版的目录拿来对照，译者还是严格的遵守了原文目录的排布。 译者把Part翻译为篇, 我觉得就直接翻译为部分比较好。整理目录，补充一部分 Part,Chapter,Section 的标题。 于是做了点体力活，把英文书籍的目录部分搬运过来。 第一篇：阅读的层次 ch01: 阅读的活力与艺术 Active Reading The Goals of Reading: Reading for Information and Reading for Understanding Reading as Learning: The Difference Betweenn Learning By Instruction and Learning by Instruction and Learning by Discovery Present and Absent Teachers ch02: 阅读的层次 ch03: 阅读的第一个层次：基础阅读 Stages Of Learning to Read Stages and Levels Higher Levels of Reading and Higher Education Reading and the Democratic Ideal of Education ch04: 阅读的第二个层次：检视阅读 Inspectional Reading I: Systemmatic Skimming or Pre-reading Inspectional Reading II: Superficial Reading On Reading Speeds Fixations and Regressions The Problem of Comprehension Summary of Inspectional Reading ch05: 如何做一个自我要求的读者 The Essence of Active Reading: The Four Basic Questions a Reader Asks How to Make a Book Your Own The Three Kinds of Note-making Forming the Habit of Reading From Many Rules to One Habit 第二篇：阅读的第三个层次：分析阅读 ch06: 分类一本书 The Importance of Classifying Books What You Can Learn from the Title of a Book Practical vs. Theoretical Books Kinds of Theoretical Books ch07: 透视一本书 Of Plots and Plans: Stating the Unity of a Book Mastering the Multiplicity: The Art of Outlining a Book The Reciprocal Arts of Reading and Writing Discovering the Author’s Intentions The First Stage of Analytical Reading ch08: 与作者找出共通的词义 Words vs. Terms Finding the Key Words Technical Words and Special Vocabularies Finding the Meanings ch09: 判断作者的主旨 &lt;Determing an Author’s Message&gt; Sentences vs. Propositions Finding the Key Sentences Finding the Arguments Finding the Solutions The Second Stage of Analytical Reading ch10: 公正的评断一本书 Teachability as a Virtue The Role of Rhetoric The importance of Suspending Judgement The Importance of Avoiding Contentiousness On the Resolution of Disagreements ch11: 赞同或反对作者 Prejudice and Judgment Judging the Author’s Soundness Judging the Author’s Completeness The Third Stage of Analytical Reading ch12: 辅助阅读 The Role Of Relevant Experience Other Books as Extrinsic Aids to Reading How to Use Commentaries and Abstracts How to Reference Books How to Use a Dictionary How to Use an Encyclopedia 第三篇：阅读不同读物的方法 ch13: 如何阅读实用型的书 The Two Kinds of Practical Books The Role of Persuation What Does Agreement Entail in the Case of a Practical Book? ch14: 如何阅读想象文学 How Not to Read Imageinative Literature Genaral Rules for Reading Imaginative Literature ch15: 阅读故事，戏剧，诗的一些建议 How to Read Stories A Note About Epics How to Read Plays A Note About Tragedy How to Read Lyric Poetry ch16: 如何阅读历史书 The Elusiveness of Historial Facts Theories of History Questions to Ask of Historical Book How to Reading Biography and Autobiography How to Read About Current Events A Note on Digests ch17: 如何阅读科学和数学 Understanding the Scientific Enterprise Suggestions for Reading Classical Scientific Books Facing the Problem of Mathematics Handlding the Mathematics in Scientific Books A Note on Popular Science ch18: 如何阅读哲学书 The Questions Philosophers Ask Modern Philosophy and the Great Tradition On Philosophical Method On Philosophical Styles Hints for Reading Philosophy On Making Up Your Own Mind A Note on Theology How to Read “Canoncial” ch19: 如何阅读社会科学 What Is Social Science? The Apparent Ease of Reading Social Science Didfficulties of Reading Social Science Reading Social Science Literature 第四篇：阅读的最终目标 ch20: 阅读的第四个层次：主题阅读 The Role of Inspection in Syntopical Reading The Five Steps in Syntopical Reading The Need for Objectivity An Example of an Exercise in Syntopical Reading: The Idea of Progress The Syntopicon and How to Use It On the Principles That Underlie Syntopical Reading Summary of Syntopical Reading ch21: 阅读与心智的成长 What Good Books Can Do For Us The Pyramid of Books The Life and Growth of the Mind 问与答如何阅读一本书里面有很多技巧，其中有个就是通过提问的方式来使得读书效率更高。 下文是我在读这本书之前和读这本书之后提出的部分问题，挑选一部分写出来作为自己的读书笔记。 我把提问类型标记为如下： CQ Common Question : 所有书提问。 SQ Specific Question : 本类书提问。 EQ Extended Question : 脑洞类提问。 CQ1: 本书整体讲了什么？ You see, but you do not observe. The distinction is clear. Sherlock Holmes/Arthur Conan Doyle, A Scandal in Bohemia (1891) 一句话概括： 本书讲的是读书的策略与技巧 (HOW). 再详细一些： 本书讲的是，当面对不同层次的书，不同种类的书，同一本书的不同部分，挑书，看书，读书，吃透书的策略与技巧。 作者从阅读的活力与艺术入手，介绍了阅读的必要性，然后介绍了阅读的四种层次，接着点出了阅读层次的进入一些阅读层次的要求，方法，技巧。着重介绍了分析阅读，以及面对各种各样的读物的阅读技巧。 第一部分 花了一章简单的介绍了基础阅读。花了一章介绍了检视阅读，附加另一章介绍做一个自我要求的读者。 接着是第二部分重点介绍阅读的第三个层次，分析阅读： 这个层次需要 『分类这本书』 『透视这本书』 『判断作者主旨』 『评断一本书』 『赞同或者反对』 PS: 译者把 Pigeonholing a Book 翻译为一本书的分类，这个放在标题上和分类一本书意思相差大了。 也介绍了辅助阅读的通用的一些方法和手段。 接着进入第三部分，作者用自己的经验来分享对于每一种不同类型（阅读使用类书籍，想象文学，故事 / 戏剧 / 诗篇，历史，科学与数学，哲学，社科）的书籍，有哪些注意点（抓重点）, 有哪些技巧。 第四个部分则是介绍了阅读的终极目的： 其实每一个人的读书都是主题阅读 挑选《沟通的艺术》基本上都是为了提升沟通上的技巧。换而言之，其实我们都是为了丰富自己在沟通上面的知识体系从而选择了看这本书。 当然，作者并不是新造一个概念，然后一本正经的说没有干货的道理，作者还举了一个例子用于如何在主题之间作取舍，更加有条理的去看某些类别的书。 SQ1: 较好的阅读一本书的步骤确定要补充那些知识 / 技能体系 “Some books are to be tasted, others to be swallowed, and some few to be chewed and digested” - Francis Bacon 有的书适合浅尝，有的书适合吞咽，只有少部分适合咀嚼和消化到变为身体的一部分。 培根对书归类的这句话相当形象。 看书除非是热爱读书，否则随便拿起一本书，实在是难以激发自己探索这本书的冲动。 而，这里面有一个隐藏的问题，就是要补充哪些知识 / 技能体系, 首先是要知道有哪些知识体系。 维护健康 高效自学 逻辑思考 规划管理 沟通表达 团队协作 …… 筛选书籍阶段 : 过滤不适合的书 目的：用一些比较通用的技巧筛选出书籍。然后进入下一阶段 技巧： 泛读书衣：书衣和封面是重要的宣传点，书衣没有亮点。基本上这本书也不会有太大亮点。 泛读封面： 出版社不行，基本上这本书也不行，出版社的可能在某个领域特别牛，比如图灵 / 机械在计算机方面特别牛，我就特别青睐于选这两家的新出来的技术书籍。但不管外面怎么说，反正我自从不考试了之后，我就拒绝看清华大学出版社的所有计算机相关的书籍。清华大学出版社的计算机类作者就几乎进入了我的计算机不读书籍作者的黑名单。 作者的其他书不行，新书八成也不怎么样。作者有一本书写的巨牛无比，他的其他书籍也不会差到哪里去。假如《母猪的产后护理》质量很高甚至连高科技养猪的网易老总都专门给这本书作序，那作者的《世界如此残酷，你一定要内心强大》一定是另一本仙风道骨的自传。 一本精心构造的书的内容，插画都是有一定的寓意的。很少有作家出一本书是忍心让自己的书封面长的巨丑。 这也需要注意的是：有的烂作品也会在封面下一番功夫，这就需要进入下一阶段的的探索了。 版次越高，则越好。 印次越高，则越好。 首印数量很少，则出版社对这本书没有多大信心。 编著，著是原创，编则是整合。 如果可以的话，优先阅读英文书。 豆瓣和亚马逊的书评。 泛读目录：好的书籍的目录一定是（注意是一定是）逻辑清晰，结构层次分明，足以概括该章节的，甚至对如果稍微懂一点点的人，仅仅凭着目录就可以脑补出整本书的结构。 其他技巧：比如，直接买某个社群推荐的书单。我在不懂编程的时候就是这么做的。当然，后来稍微入了编程的大门才发现当初买了很多烂书。当然，用别人的书单也会逐渐让自己挑选书的能力退化。 如果不适合口味，比如你想看《面向对象编程思想》过程中的翻到了一本《找对象，就这么做》的书，果断换一本；或者这书质量实在是太差，比如你翻到了《公猪在母猪的产后护理过程中不得不做的 138 件小事》, 书总共就 350 页，居然讲什么是母猪花了 147.6 页，果断换一本书。这样你就节约了看一本不合适的书的时间。 检视阅读阶段 : 判断一本书的质量 目的：判断一本书的质量，以及评估当前的书本是否值得进入下一阶段。然后进入下一阶段。 适用场景：不知道这本书适不适合进行更高质量的阅读。或者时间有限并且急于挖掘书中的知识。 经过上个阶段的过滤，不合适的书基本上也就差不了多少了，这时候就需要对这本书进行检视阅读了： 检视阅读阶段 STEP1 : 大体定位这本书。 看书名页 / 序 : 了解这本书的主题，归类这本书的类型。 研究目录页 : 对这本书的基本架构做概括性的理解。 查看索引 出版者的介绍 挑选几个和主题相关的篇章，着重看篇章的开头或结尾。 把书打开，随意翻，有时候连续看几页，但不要太多。 定位这本书的用途： 弃而不看。 放着做参考书。 进行检视阅读的第二阶段 检视阅读阶段 STEP2 :这篇作者 / 译者使用了一个很容易被误会词，粗读。 即： 头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或者思索。 那什么标准的读才叫粗读呢？ 把握主干，不拘泥于细枝末节，把握大原则，不拘泥于细微的重点，而不是那种随便翻翻的”粗读”. 检视阅读的一些误区： 速读也只能回答出”这是在说什么的”的问题。对深入理解，回答更深层次的问题没有大帮助。 分析阅读阶段 : 全方位吃透这本书经过筛选与检视，剩下的书则是很有价值的书。 而，读一本书的阅读技巧，明显是高于比书本长度少，比书本难度易的读物。即 这些阅读技巧也同样适用于非书籍的读物上 分析阅读第一阶段：找出一本书在谈写什么的规则步骤： 依照书的种类与主题来分类 使用最简短的文字说明整本书在谈些什么 将主要部分按顺序和关联性列举出来。将全书的大纲列举出来，并将各个部分的大纲也列出来。 确定作者想要解决的问题。 如果心中没有一个分类的标准，再清楚的书名也没有用。 每一本书都有一个骨架，作为一个合格的读者，目的就是找出这个骨架。 掌握一本书的架构 使用单一的句子，或者最多几句话来叙述整本书的内容。 将书中的重要篇章列举出来，说明他们如何按照顺序组成一个整体的架构。 PS: 建筑架构与书本架构的那个比方真的是精彩。 第三点可以用列提纲来解决： 作者将全数分为五个部分，第 1/2/3/4/5 部分讲的是什么 第一部分的第一节（注：Section, 译者翻译为段落）, 有 X/Y/Z 节 / X 节作者做出四个观点 (Point),I/II/III 由于纸笔速度跟不上大脑运转速度，对每一本书这样读并且列提纲的话相当耗费精力，但是具备这样的意识还是很重要的。 分析阅读第二阶段：诠释一本书的内容的规则。步骤： 诠释作者的关键字，与他达成共识。 由最重要的句子中，抓住作者的重要主旨。 知道作者的论述是什么，从内容中找出相关的句子，再重新架构出来。 确定作者已经解决了哪些问题，还有哪些问题是没有解决的，在判断那些是作者知道他没有解决的问题。 作者的主旨如果没有理论的支持，只是在书法个人想法罢了。2. 为什么他认为我们应该被说服，以接受这样的观点。 找出关键句 找出主旨 找出论述 找出解答 他沟通的主要核心是他所辖的肯定与否定的判断，以及他为什么会这么做的立构。 不能用他们自己的话，重述你的观点。则是代表不理解。 分析阅读第三阶段：评论一本书的规则规则： A. 智慧礼节的一般规则 除非你已经完成了大纲架构，也能诠释整本书了，否则不要轻易评断。 不要争强好胜，非辩到底不可。 在说出评论之前，你要能证明自己区别得出真正的知识与个人观点的不同。B. 批评观点的特别标准 证明作者的知识不足。 证明作者的知识错误。 证明作者不合逻辑。 证明作者的分析与理由是不完整的。 甚至，可以用于其他的类型的学习。 主题阅读阶段 : 纳入自己的知识体系主题阅读其实就是对同一个主题挑选几本书进行查看。 多问问自己：这本书谈的内容对我研究的主题内容道理有没有帮助？ 主题阅读 STEP1. 找到与主题相关的章节。只看与该章节相关的内容。主题阅读 STEP2. 带领作者与你达成共识。与检视阅读的第二步骤相反。主题阅读 STEP3. 理清问题。主题阅读 STEP4. 界定议题。主题阅读 STEP5. 分析讨论。 SQ2: 上面关于阅读一本书的步骤是适用于所有书，即是通用的步骤吗？ 不是 作者在书中介绍了四个问题，用来帮助读者进行更好的阅读，这些问题除了不适合小说类的书籍，基本上可以适用于绝大部分的书籍。 CQ1 : 本书整体讲了什么？ （主题，作者如何依次发展主题，如何逐步从核心主题分解出从属的关键议题来） CQ2 : 作者细说了什么？怎么说的？ （找出主要的 ideas,assertions,arguments, 汗，译者翻译为了 想法，声明，论点，实际上应该翻译为想法，主张，论据……) CQ3 : 这本书说的有道理吗？是全部有道理，还是部分有道理？ CQ4 : 这本书跟我有什么关系？ 如果是资讯，则询问是否有意义。是否值得有更深入的了解。这本书可以补充我哪些知识体系 作者在书中已经介绍完分析阅读，按理来说应该进入的是下一部分，即主题阅读。 但是第三部分莫名其妙硬塞了一部分内容叫做阅读不同读物的方法 内容是如何阅读下面的读物： 实用型的书 想象文学 故事，戏剧，诗 历史书 科学与数学 哲学书 社会科学 而这么做的答案在第十三章的开头（不是应该在第三部分的开头嘛？). 在任何艺术或实务领域，规则太通用是一件令人扫兴的事情。少量的通用性规则是优势。越通用的规则也就意味着越易懂，而与此同时当遇到真实案例的时候，往往通用规则太宽泛而难以应用。 即，尽管作者做了抽象的总结的经验，但还是要具体落实到具体的案例上。 分析阅读之如何阅读实用型的书 注：由于时间有限，仅仅对阅读实用类和历史书籍做了笔记，以后补上。 注意：任何一本实用性的书不能解决该书所关心的实际问题. 就像学会如何阅读一本书, 看完做好笔记并不意味着你不会阅读一本书这个问题消失了, 只有行动才能解决问题。 听过那么多道理，却不行动，不能过好这一生也没有那必要怪道理。 Just Do It 如果是阅读数学类的书，可能了解作者本人是没有任何必要的。 如果是阅读道德论述，经济论文和经济论著，则非常有必要了解作者的人格，生活所处的时代背景。 第一个问题：这本书是在谈些什么。第二个问题：这本书的意义或内容，共识，主旨，论述。第三个问题：内容真实吗？第四个问题：这本书与我何干？ 分析阅读之如何阅读历史书这部分刚开始就通过法庭陪审团的车祸事件来说明，在严格规范的证据之下，加上详细检验之后，身为陪审员都很难百分之百的确定一件事情的真相。 而，一个人连一件单纯的事都难以确知真相，遑论历史？ 由于历史的理论不同，历史学家对历史事件的描述则不同。 阅读历史的两个要点： 对你感兴趣的时间或者时期，尽量阅读一种以上的历史书 不要只关心在过去某个时间地点真正发生了什么事情，还要读懂在任何时空中，尤其是现在，人们为什么会有这般行动的原因。 SQ3: 关于读书的有哪些误区速读 许多书连略读都是不值得的，另外一些书只需要快速读过就行了。有少数的书需要用某种速度，通常是相当慢的速度，才能完全理解。 一本只需要快速阅读的书，却用很慢的速度来读，就是在浪费时间，这时速读的技巧就能帮你解决问题。 PS: 无论是多么难读的书，在无关精要的间隙部分都可以读快一些。而那些比较困难的部分，应该慢慢阅读。 核心的注意点应该放在：理解了多少。恰似沟通需要注意的：不是你说了多少，说的多快，而是对方理解了多少。 随便翻翻读书如果不是为了娱乐消遣，切忌进行在很松散的状态下随便拿一本书看看。 为了解决很随便的看一本书，我的技巧就是带着问题去看。 陷入细枝末节 头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或者思索。 不停的停下来查一些陌生的知识会不断的破坏兴趣。并且会忽略掉一些大的原则性的东西。比如：当你努力的去了解那些细微的重点时，就会错过大原则：关于成本中包含的薪水，租金，利润与利息种种因素，市场在定价中的角色，垄断专卖的害处，自由贸易的理由等等。 作者的意思其实就是从枝干再到树叶。不要上来就陷入一些细小的琐碎事物中。 EQ1: 为什么要重新学习如何阅读书籍的策略与方法 初学者的无知在于未学，而学者的无知在于学后 以上。 相关链接https://en.wikipedia.org/wiki/How_to_Read_A_Bookhttps://en.wikipedia.org/wiki/How_to_Read_Literature_Like_a_Professor亚马逊地址《如何阅读一本书》 UPDATE: 日期 类型 详细操作 2017-02-13 创建 初始化本文 2017-02-17 重构 删除零散笔记，重新组织本文结构 2017-02-26 重构 调整部分内容]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>书评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『好好说话』读书笔记]]></title>
    <url>%2F2017%2F01%2F27%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0_%E5%A5%BD%E5%A5%BD%E8%AF%B4%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[当时看到奇葩说这个节目就深深的喜欢上了这群打辩论的顶级高手们。 于是，当这些奇葩的辩论王者们出了『好好说话』的语音教程的时候，就非常开心的入手了。现在出了纸质书，像我这种不是特别聪明的人自然是要好好的拿来研究一番，于是诞生了本文。本文是我的公开的笔记，私人的笔记就不分享了。 好好说话有语音版和文字版。建议购买。很多技能都不重要，早一点学迟一点学基本上都没有问题，但是说话是为数不多的，不学就非常可惜的早学可以少走很多麻烦的。 真心建议买正版，为优秀的知识付费是追求上进的人的基本素质。 世界上需要交智商税的东西真的特别多，但是说话这种东西一般情况下交的智商税的特别的高： 就像在书籍第一章开头所说，说话之伤都是暗伤。 能意识到你问题所在的，通常都不会告诉你。心大点的，察人之过笑而不言，但是私下里知道你这个人不靠谱，以后有重要的事不能指望你，就会疏远你；心稍微小点的，不跟你计较，但是客客气气找个别的由头举了你；等而下之的人的，甚至会一边给你穿小鞋一边装大度，让你死都没有四个明白。 回想起我前 25 年的很多糟糕的言行，现在想想，当时总归是可以有更优解的。 但仔细一想，似乎寻常人总会去踩这些坑，吃过很多教训，才能明白。 说话是权利的游戏五维话术：演讲，沟通，说服，谈判，辩论。 演讲 A – 权力的形成（吸引，聚焦，引导） 沟通 B – 权力的流动（避免冲突与协调转向） 说服 C – 权力在对方（无权的一方要改变有权的一方） 谈判 D – 权力在双方（双方要合作，才能解决问题） 辩论 E – 权力在他方（双方无权决定胜负，通常由中立第三方裁决） 这里面的纬度，并不是每一个场景下就对应某一纬度的，比如说，当你在沟通的时候，有的时候就也需要说服，有的时候又需要辩论，甚至谈判。 所以，每一场复杂的说话场景实际上是在不断的变化当中，甚至可以用矢量 (A,B,C,D,E,T) 其中 T 表示的是 Times 次数。即以 A 为演讲值，MAX 为 10,MIN 为 0 的情况下，第 T 次演讲的说法应该为 (A,B,C,D,E), 比如 (2,3,4,9,0) 表示此次对话应该着重于谈判.P20 有一个非常有趣的说明叫做色有三原，光分七彩。 温和的的沟通，可能蕴含着辩论的机锋和谈判的策略；娓娓道来的说服可能需要演讲的华彩的沟通的诀窍。 而好好说话的工作流就是 S1. 倾听 For 收集信息S2. 判断 For 权力棍术S3. 思考 For 应对之策 说话策略需要依据权力（大小）, 态度（反对 / 赞同）, 成本（低 / 高）, 方向（单向 / 双向）, 受众（多 / 少）S4. 表达 For 语言输出，然后转 S1]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>书评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『把时间当做朋友』读书笔记]]></title>
    <url>%2F2017%2F01%2F27%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0_%E4%B8%8E%E6%97%B6%E9%97%B4%E5%81%9A%E6%9C%8B%E5%8F%8B%2F</url>
    <content type="text"><![CDATA[前言我大一的时候看到的这本书的第一版。转眼大四毕业半年了。 这本书对我有很大积极的作用，大一时候很庆幸读到这本书籍，当时一读这本书，就像一个溺水的人抓到了一个水面上的一根稻草，以为『明白一个道理，于是突然间就主角光环加深，从此走向人生巅峰』。当时可能是因为年轻气盛见识少，待我见识稍稍多了那么一点点之后，也就逐渐可以对成功学类的鸡汤脱敏。这里的脱敏指的是可以减少过度情绪化的理解，从句子中逐渐剥离感性的煽情的句子，慢慢的从稍稍理性的一些角度进行理解。 这本书放在公网上，并不需要购买即可免费查看，但，值得一提的是，第三版在排版上下足了功夫。阅读体验很好。推荐购买纸质书。 我是一个认为『术』重于『道』的人。『道』意味着对『术』进行抽象总结，并且艺术化的语言进行诠释，这个过程难保没有信息的损失。 这本书在四年后看的今天，依然读出了很多不一样的味道，这种惊喜恰如第一次读到这本书的时候那般惊奇。 四年前，我看了这本书，相信自己的积累终究会有一天有所回报。 现在想想，很多李老师说的道理也有道理本身的局限性，道理一旦脱离于扎根这些道理的土壤，就显得很没有道理，李笑来提到： 速成绝无可能 交换才是硬道理 完美永不存在 未知永远存在 现状永远无法摆脱 这些话的正确性在于如何定义速成，如何定义交换，如何定义完美，如何定义未知，如何定义摆脱现状。放在李老师列举的几个例子来说是成立的，但是放在其他的例子里面则是不成立的。 比如说，『速成绝无可能』： 拿我自己举例子，我本身已经学会了几门编程语言，再学另一门编程语言，那仅仅是多看几天编程手册的事情。几天学会一门编程语言这叫不叫速成呢？一两天学会另一个数据库这叫不叫速成呢？有的人可是要花好几周呢？你会说，这并不见得，你这是主场，你这是在同一个领域里面学习。这种情况不应该叫做速成。那，举个其他的例子，写代码这个过程涉及到大量的推导和不断的修正自己的方法，这让我学一门新的编程类技术或者非编程类技术的过程中有很强的 common sense, 这个过程也是事半功倍的，那这算不算速成呢？ 在本书中，对于『时间管理』, 这个词本来就不是管理时间的流动的，而是管理自己对于时间的开销。可，李老师反倒说：时间本来就不服从于每个人的管理，你只能选择和时间做朋友。 可，我只想对我的时间开销进行合理安排.我没有控制时间的想法呀! 当然，瑕不掩瑜，我认为这本书除了重要的内容是那些『术』而非那些『道』. 没有人不懂道，也没有人不懂道理，只是道理本身具备相当大的局限性罢了。 目录通常情况下，看一本『自我成长』类书籍，看他的目录就能了解这本书的讲解思路。 困境 - 醒悟 - 现实 - 管理 - 学习 - 思考 - 交流 - 应用 - 积累 几天读下来，私以为最有价值的部分为管理 - 学习 - 思考 - 交流这四个章节，这四个章节多看几遍，其他大略看看便好。 以下便是我的一些零散的笔记。 第 0 章：困境首先是发现时间不够用（问题）, 接着是尝试改变但却时间压力导致自己即勤奋又懒惰（慌乱）显得『用战术上的勤劳掩盖战略上的懒惰』, 我们尝试去管理时间，但是却无法管理好时间，于是李老师提出『我们无法管理时间，只能管理自己』，怎么管理自己？李老师给出的答案是『必须要看清楚、想明白『问题出在自己身上』, 而解决就只能靠积累』。 番外：为什么是第 0 章呢？因为程序员从零计数，而李笑来老师是一个 Geek 范十足的人。而且，概述放在第 0 章，我觉得也蛮有意义的。 从第 0 章可以看出这本书围绕着：运用心智获得解放 其实个人觉得这本书的这个副标题 – 运用心智获得解放倒是非常适合作为本书的标题，因为论概括性比把时间当做朋友显得更加的契合本书的内容。当然，做销售出身的李老师肯定也知道，这个副标题没有多大吸引力，至少没有把时间当做朋友那么有吸引力。 第 1 章：醒悟定义了孰主孰仆：不要跟着感觉走，翻身做大脑的主人 举了『一个锤子不能砸自身，钉子不能砸自身，但人脑可以修正自身的想法（元思考）来说明人脑的高级』的例子。放在一起总觉得怪怪的。举一个不恰当的例子：耳机可以通过不断的播放音乐来使得耳机音质得到大量的提升，这个过程叫做煲耳机，而超过一定使用期限之后，耳机的音质就会有所下降。我觉得耳机也是一个通过不同使用自身进行发声并且使得自己的发出的声音更加美妙的东西呢。 定义了何为心智：一个人心智就是其过往获得的一切的知识与经验的总和。 举了一个聪明人办傻事，还振振有词，义正辞严，双目炯炯的例子。我甚至会怀疑是否本来人家能接受意见，反而因为当众揭露出来，因而在内心里抵触别人意见。当然，缺乏具体的场景，我也无从判断。只能假设，这个倒霉的聪明蛋说的是那种很大的自以为振振有词的话了。 李老师举了自己学了计算机，盲打，统计，做销售，英语的例子来说明一些道理。PS: 不得不说，在 90 年代学到了这些先进的，time saving 的东西真的是让人非常的羡慕。 然后说了一个和乔布斯学习书法一样的道理，并且加以升华：『因为不知道那东西有什么用而决定去学』和『因为不知道那东西有什么用而决定不去学』, 前者在实践中越发相信技多不压身，后者只能感叹技到用时方恨少。（当然，与此同时，相信技多不压身的人往往也会陷入同时学习多个技能从而导致处处平庸的误区.) 第 2 章：现实 速成绝无可能 交换才是硬道理 完美永不存在 未知永远存在 现状无法马上摆脱 关于速成，李老师这么说：人本质上就容易对那些在短时间内能让自己满足的事物产生依赖，并且全然不顾事实上对自己的影响是好是坏，比如： 依赖打游戏来满足自己的成就感 『今天那么累了就大吃一顿吧』 然而，在很多领域，之所以相信有速成之法，多少因为之前的老师教的太烂。相信速成之法的聪明人，只是寻找一个更好的学习路径而已。相反，很多人看书不去看一下评论，不 Google 一下，不去征求一下该领域的牛人的意见，上来就一阵瞎折腾，这不也是一种『既勤劳又懒惰』的人么？ 第二章总结： 你得有耐心接受现状有耐心，接受自己的不完美，有耐心接受未知。 你得有所积累才能有资本。 相信我，你并不孤独。 其实整本书籍讲的都是不要急，慢慢来。 第 3 章：管理第三章叫做管理，一本书终于进入了干货期，特别是打电话这个流程总结的相当不错，不是很清楚打电话这个是不是商务人士的常识，但的的确确让我也注意到了一些细节其实可以处理的更加完美。 凭什么确定现在就可以接电话？发条短信问问对方是否方便 想清楚，对照着清单进行沟通。防止漏掉关键信息。 工作电话，对方未接，显示的是工作总机。应该发消息到对方手机。 交代自己是谁！ 对方没有纸和笔怎么办？善意提醒对方可以邮件发个备忘。 处处留心皆学问。 至于记录时间的方法，曾经尝试过一段时间，没有坚持下来，个人觉得并不适用于我。 至于制定计划的注意点，其实李老师说的其实就是 SMART 法则吧： 目标是具体的 (Specific) 可以衡量的 (Measurable) 可以达到的 (Attainable) 要与其他目标具有一定的相关性 (Relevant) 具有明确的截止期限 (Time-bound) 第 4 章：学习 效率本质 1.2. 学习有效率的东西才是王道 基本途径 2.1. 体验 / 试错 / 观察 / 阅读 主要手段 3.1. 科学方法 经验局限 4.1. 个体经验有限 4.2. 群体经验有限 4.3. 与现有知识相悖的知识 自学能力 5.1. 基础阅读能力 5.2. 检索能力（基于阅读能力） 5.3. 写作能力（写出简洁，有效，准确，朴素，具体的文字记录自己的只是和经验） 5.4. 实践能力是自学能力最终转化为真正价值的根本。 5.5. 保持开放的心态 记录下不能苟同的言论，定期想想原因 学习，就是为了提高效率。这与李老师主张的实用主义非常吻合。从四个基本途径（体验 / 试错 / 观察 / 阅读）入手，并介绍了主要手段即科学方法。接着介绍经验局限如何自学能力。 有趣的东西在于科学方法。 所谓科学方法，用于求索科学问题还是很有意义的，可是用于解决日常生活中的问题，多多少少显得过于书生气。 对于科学界已经确定的结论，经过严密的科学方法来验证，那些是值得相信的。比如进化论，现代医学，科学结论。 能不能说科学探索出来的就一定是正确的呢？不见得，但是经过严密推导后或者是严谨的双盲测试的结论则是非常值得去相信的，如果错了，那就只能认了。如果严谨的科学探究都能出错，那也属于”天亡我，我何辞为？”. 然而，遗憾的是，更多的问题则是没有足够的素材来验证这个道理是否属于真理，我们遵循科学方法估计得出的也就是假想。甚至来不及验证，机会就溜走了。 第 5 章：思考第五章是最有意义的一章，这是李老师特别擅长的思考，所以每次读都可以发现有趣的东西，比如，李老师定义的勤于思考 – 只不过是从别人那里知道一个结论的时候，自己动脑重新推演一遍，看看得出的结论的过程有没有漏洞和不合理的地方，衡量一下结论到底有没有道理的过程。 至于勤于思考的原因却是，我们也处于一个信任成本极高的社会。 接着李老师举出两个思维陷阱： 概念不清 拒绝接受不确定性 概念不清的人往往分不清目标与计划、 科学科普与科普作者 \ 历史与历史课 \ 上学与学习 拒绝接受不确定性的人就会往两个方向发展要么选择相信鬼神要么擅长使用二分法强行得出答案。 很多人也分不清相关性和因果性： 其实确立思考的方案也很简单，如果别人给了你一个因为 A, 所以 B： A 不一定是 B 的理由 A 不一定是 B 唯一的理由 A 不一定是 B 最重要的理由 A 可能是促进了 B ,B 也反过来促进了 A, 两者相互促进，互为因果。 举个例子： 有个人说：程序员只能去北京才能混得好。 想清楚这句话有没有道理很简单： STEP1. 确立他说的因果关系：因为程序员去北京混，所以混得好。STEP2. 想想混的好的原因真的是因为去北京混吗？去上海就一定不行咯？北京的程序员就一定混得好咯？STEP3. 想想混的好的原因的唯一理由是因为去北京混吗？不去北京就一定不行咯？STEP4. 想想混的好的原因的最重要的理由是因为去北京混吗？如果不去北京还想混得好，还有什么方法呢？ 命题的四种概念： 因为 A, 所以 B 因为~A, 所以~B 因为~B, 所以~A 因为 B, 所以 A 很早接触这个概念，虽然至今用的还是不熟，但这四个概念真的是写段子的强行混淆概念的好概念啊。 第 6 章 交流 学会倾听 说与不说 交流守则 正确复述 勤于反思 这一章也值得反复多看几遍，即便不能理解，一本正经的引用牛人的话也是提升谈资，满足自身小虚荣的重要手段。 有趣的是交流守则： 对话的目的是寻求真理，不是为了斗争。 不做人身攻击。 保持主题。 辩论时要用证据。 不要坚持错误不改。 要分清对话与只准自己讲话的区别。 对话要有记录。 尽量理解对方。 当然，有的时候别人会进行反驳，而注意双方的反驳层次也是很有用的（书中未提）: Paul Graham《How to Disagree》值得一看 http://www.zreading.cn/archives/4137.html 引用李老师的话： 如果我们作为讨论的一方，发现对方已经不再“遵守理性讨论基本原则”，那么就马上停止讨论吧，因为我们已经失去了讨论的对象。就算对方不依不饶，我们也应该回避回避再回避，因为任何接下去的过程都已经不再是“讨论”，而更可能是仅仅为争而争的“争论”了。这种争论的害处很多，比如浪费时间，比如影响情绪，比如把对方变成敌人，比如失去更多朋友…… 总结读到这本书之后，确实让我不安宁了好一阵子，因为这让我真真确确的感受到了自己对时间的浪费，对自己精力的浪费。这些东西原本可以使我变得更好。 四年后，重读这本书，依旧让我收获颇深，至于前面部分的挑刺，也仅仅是耍耍小聪明而已，挑刺很容易，建立体系并不那么简单。 遇见有趣的书，就如同遇见一个有趣的人一样。 所有的遇见，都是久别重逢，只叹相见恨晚。 感谢毕业后的第一个春节假期的都让我不断补充新知识不停止学习的步伐的公司，让我在大年初二完成这篇读书笔记。]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>书评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写给 Pythoner 的 Spacemacs 入门指北]]></title>
    <url>%2F2017%2F01%2F15%2FSpacemacs%2F</url>
    <content type="text"><![CDATA[前言最开始，使用 Sublime Text 编码，后来用 Vim 混合 PyCharm 写 Python。 前几天，Github 上的 Spacemacs 已经成功的突破一万 Star, 听说几个我非常佩服的 Pythoner（比如『Python Web 开发实战』的作者董伟明） 也是非常喜欢 Spacemacs, 我就萌生了从 Vim 切换到 Spacemacs 的想法，说做就做。 注：本文所有内容基于 macOS 10.11, 软件环境为 zsh , pyenv , python3.5.2 , node5.12.0. 其他类 Unix 平台略作修改即可使用。至于 Windows 平台，建议安装 Ubuntu 虚拟机。本文也需要读者具备基本的 VIM 基本常识和 Python 常识。 迁移到一个编辑器需要找到一些操作的 Emacs 替代操作。于是我安排文章结构如下： 0x00. 基本软件环境安装 0.1 zsh 与 ohmyzsh 0.2 pyenv 与 pyenv virtualenv 0.3 nvm 以及常用 npm 包 0.4 Spacemacs 安装以及基本配置 0x01. 日常的编辑 1.1 文件导航 1.2 文件编辑 1.3 Markdown Writing 0x02. Python 编程 2.1 代码补全 2.2 代码跳转 2.3 pytest 测试 0x03. IPython Notebook 3.1 IPython Notebook 基本配置 3.2 Emacs IPython Notebook 0x04. 扩展 本文只负责把读者带入 Spacemacs 的世界中，而不是涉及到 Spacemacs 的方方面面，所以此文为指北。而非详细的指南 (Guide). 0x00. 基本软件环境安装0.1 zsh 与 ohmyzsh123brew install zshchsh -s /bin/zshsh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 0.2 pyenv 与 pyenv virtualenv12345678910111213141516171819202122232425262728git clone https://github.com/yyuu/pyenv.git ~/.pyenvgit clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenvecho 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.zshrcecho 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv init -)"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.zshrc# 不喜写兼容代码，所有代码均向 3.5+ 靠拢v=3.5.2|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=3.6.0|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=2.7.11|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v# 设置 Global Python 为 2.7.11, 备注：尽量不要把 Py3 设置为全局，否则由于 Homebrew 本身有一些依赖是依赖于 Py2 的，这样容易出现一些奇怪的问题。pyenv global 2.7.11pip install -i https://pypi.doubanio.com/simple requests# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hypyenv virtualenv 3.5.2 py3-dailypyenv activate py3-dailypip install -i https://pypi.doubanio.com/simple requestspip install -i https://pypi.doubanio.com/simple beatutifulsoup4pip install -i https://pypi.doubanio.com/simple ipython[notebook]pip install -i https://pypi.doubanio.com/simple jupyter# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hypyenv deactivate# pyenv uninstall py3-daily 0.3 nvm 以及常用 npm 包12345678910111213# 安装 nvmcurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bashnvm install 5.12.0echo '\n#alias for cnpm\nalias cnpm="npm --registry=https://registry.npm.taobao.org \ --cache=$HOME/.npm/.cache/cnpm \ --disturl=https://npm.taobao.org/dist \ --userconfig=$HOME/.cnpmrc"' &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrcnpm install -g vmdnpm install -g gitbook-clinpm install -g hexo-clinpm install -g ternnpm install -g js-beautifynpm install -g js-hint 0.4 Spacemacs 安装以及基本配置12345678910brew install agbrew install grepbrew tap d12frosted/emacs-plusbrew install emacs-plus# 安装完毕之后，克隆我的配置 repo, 有一些基本的配置用于解决墙的问题。解决方案来自于子龙山人git clone https://github.com/syl20bnr/spacemacs ~/.emacs.dmv ~/.spacemacs .spacemacs.bakgit clone https://github.com/twocucao/spacemacs.d.git ~/.spacemacs.d# 输入 emacs 进行初始化，如果你可以正常访问 Github 的话时间在半小时之内。emacs 安装 Spacemacs 过程中画面如下： 安装前，Emacs 长这个样子： 安装后，Emacs 长这个样子： 在正式进入，请牢牢记住下面几个按键已经功能，以备不时之需 spc : 跳出命令面板 spc-spc : 跳出命令列表，可运行命令，也可以查找快捷键 spc-h-spc : 查找包的用途与定义 嗯，可以谈下一话题了！ 0x01. 日常的编辑1.1 文件导航 (VIM 流）hjkloOaA zz (VIM 流）查找 * /words spc-f-j 开发 neotree spc-tab 切换到上一个 buffer spc-f-f 打开文件 spc-p-f fuzzfind 类似于 ctrlp spc-s-g-p grep 搜索项目 spc-s-a-p ag 搜索项目 搜索项目如图 (spc-s-a-p ag 搜索项目）: 实在是方便至极 1.2 文件编辑文件内容编辑 (VIM 流）u 与 c-r d c 等 有趣的是查找替换功能也是自带预览的。比如 :%s/foo/bar/g 文件本身编辑 在 dired mode 下：copy - C , delete - D, new folder - + 也可以 spc-f-t 在 neotree 下进行编辑 除去这些和 Vim 相似的文件编辑功能之外，甚至窗口管理都和 Vim 一致了，使用 c-w+hjkl 直接跳转。强烈建议在读者抽空过一遍基本的 Vimtutor 1.3 Markdown Writing spc-spc-markdown-generate-to 回车即可生成本文的 Toc(Table Of Content) spc-b-i 打开 buffer 的 imenu（类似于 Vim 的 Tagbar 插件），enter 跳转 搜索项目如图 (spc-b-i 开启 buffer imenu ，enter 跳转）: 0x02. Python 编程2.1 代码补全当你按照前面的所有配置走一圈下来，基本上就已经可以完美的进行补全了。比如，当我编辑一个 py 文件的时候，123# 先激活虚拟环境pyenv activate 3.5.2/envs/py3-dailyemacs py.py 如图所示，因为 requests,numpy 这种第三方库都可以完美补全，其他自然不在话下。 代码补全还有另一个神器，就是可以内嵌 lisp 的 Snippet 模板 – yasnippet, 由于模板功能基本上和其他编辑器相同，而使用 elisp 语言进行编写动态 Snippet 模板则需要会 elisp, 这以后有机会再学学。 2.2 代码跳转 文件代码跳转 spc-spc-helm-imenu 查看文件结构 文件跳转 在 normal-mode 下，gd 即可跳转到函数定义上，但是不能跨文件跳转。 2.3 pytest 测试 spc-m-s-py3-daily enter 选择 py3-daily 虚拟环境 spc-spc-pytest-all enter 即可运行所有 pytest 测试。 测试过程： 运行测试失败，运行测试失败，使用 c-w-j 跳转到下面窗口，对红色标记处 enter, 即可跳转到出错文件行。 修正运行测试成功，如图： 0x03. IPython Notebook通常情况下我使用 IPython Notebook 都是在 Web 端，因为是 Web 端，实际上大量的 Dom 渲染对浏览器的渲染速度还是有一定的影响的，我还是比较喜欢客户端，因为客户端的快捷键可以定制，而 Web 端的快捷键实在是相当的不方便。 是不是 IPython Notebook 的 web 端没有好处呢？有的，比如我可以借用外部的 JS 可视化图表对 js 进行可视化呀。 比如我发在简书上的这篇技术文 IPython Notebook 引入 ECharts 做可视化 但，如果不需要 js 功能的话，还是用客户端舒服一些。 3.1 IPython Notebook 基本配置spacemacs 貌似只支持密码访问 IPython Notebook, 那么我们就生成密码。 1234567# 首先激活 py3-daily 环境python -c "from notebook.auth import passwd;print(passwd())" | pbcopy# 恩，于是剪切板上就有如下的字符串sha1:9bf4c48a6b83:26bc24a78a1e4aea7baa36874f5e86bafac0dbb9# 打开 config 文件取消注释并修改 c.NotebookApp.passwordvim ~/.jupyter/jupyter_notebook_config.pyc.NotebookApp.password = 'sha1:35543659622f:f9a78f0b20132f3e04aa1d4ed4060f9fd9eb7663' 3.2 Emacs IPython Notebook12# 首先在终端打开 IPython Notebookipython notebook 接着打开 emacs, 输入 spc-a-i-n, 默认端口，然后输入密码即可。首次登陆后还需要在输入一次 spc-a-i-n 即可看到 IPython Notebook 的主界面。 光标移到 [New Notebook] 键击 enter 新建 IPython Notebook. 输入如下代码： 123456789101112131415161718192021222324252627# The %... is an iPython thing, and is not part of the Python language.# In this case we're just telling the plotting library to draw things on# the notebook, instead of on a separate window.%matplotlib inline# See all the "as ..." contructs? They're just aliasing the package names.# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().import numpy as npimport scipy as spimport matplotlib as mplimport matplotlib.cm as cmimport matplotlib.pyplot as pltimport pandas as pdimport timepd.set_option('display.width', 1000)pd.set_option('display.max_columns', 100)pd.set_option('display.notebook_repr_html', True)import seaborn as snssns.set_style("darkgrid")sns.set_context("poster")sns.set()# Load the example flights dataset and conver to long-formflights_long = sns.load_dataset("flights")flights = flights_long.pivot("month", "year", "passengers")# Draw a heatmap with the numeric values in each cellsns.heatmap(flights, annot=True, fmt="d", linewidths=.5) shift+enter , 咣 热力图就出来了 0x04. 扩展看完上文，就可以深入文档进行探索了。 打开 Vim, 输入：help vimtutor 熟悉基本的 Vim 操作。 Spacemacs Layer 文档 Spacemacs 文档 我的 Spacemacs 配置页面 Spacemacs 达人子龙山人的教程 ChangeLog: 2017-01-15 18:53:45 重修文字 2017-01-16 12:49:19 润饰文字，增加可读性，首发简书。 2018-01-01 12:49:19 最后弃坑并回归 Vim 与 IDE]]></content>
      <categories>
        <category>编程利器</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>IPynb</tag>
        <tag>Linux Shell</tag>
        <tag>沟通交流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从一个小问题来说 Python 的作用域]]></title>
    <url>%2F2017%2F01%2F14%2FOneQuestionToSeePythonScope%2F</url>
    <content type="text"><![CDATA[备注，这种动态设置 module 里的方法不推荐 前言整理工具字符类的时候，想借助正则表达式来实现一部分的文字判断抽取等操作。 比如实现： 判断文字是否为 UUID 判断文字是否包含 UUID 抽取文字是中第一个 UUID 抽取文字是中所有 UUID 一个暴力的实现方法如果正则表达式比较少，就只一个 UUID，我们就不需要思考什么，我们分别编写四个函数： is_uuid(_str) has_uuid(_str) extract_first_uuid(_str) extract_all_uuid(_str) 没错，过早优化是万恶之源 但很显然，手动方法显得很弱智，当我需要编写判断 QQ 号的时候，我又必须编写四个函数： is_qq_num(_str) has_qq_num(_str) extract_first_qq_num(_str) extract_all_qq_num(_str) 然而： 如果，我还需要判断手机号、日期、时间等等，这手动复制粘贴的过程就比较痛苦了。 如果，我去要添加一个方法，给 QQ 号码，uuid 等打码 那就必须要给所有的 uuid, 手机，邮箱都添加一个 dama_xxx(_str) 方法 有没有好一点的解决方法呢？ 两个方法第一种，比如把函数修改为： is(_str,QQ_NUM_PATTEN) has(_str,QQ_NUM_PATTEN) extract_first(_str,QQ_NUM_PATTEN) extract_all(_str,QQ_NUM_PATTEN) 第二种，Python 中动态添加工具方法，我个人比较喜欢这种： 123456789101112131415161718# 一个优雅的错误实现方式for regex, regex_pattern in REGEXES.items(): def has_regex_func(_str): return has_pattern(_str, regex_pattern) def is_regex_func(_str): return match_pattern(_str, regex_pattern) def extract_first_regex_func(_str): return find_first_matched_pattern(_str, regex_pattern) def extract_all_regex_func(_str): return find_all_matched_pattern(_str, regex_pattern) setattr(sys.modules[__name__], 'has_&#123;regex_suffix&#125;'.format(regex_suffix=regex), has_regex_func) setattr(sys.modules[__name__], 'is_&#123;regex_suffix&#125;'.format(regex_suffix=regex), is_regex_func) setattr(sys.modules[__name__], 'extract_first_&#123;regex_suffix&#125;'.format(regex_suffix=regex), extract_first_regex_func) setattr(sys.modules[__name__], 'extract_all_&#123;regex_suffix&#125;'.format(regex_suffix=regex), extract_all_regex_func) 于是我添加了测试方法： 一个不对稍微有些复杂的逻辑的程序进行测试的程序员不是一个称职的老司机。 1234567891011121314151617181920212223242526272829303132333435363738@pytest.mark.parametrize(&apos;test_input,expected&apos;, [ (&quot;321323199509234453&quot;, False), (&quot;000528-332222&quot;, False), (&quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;, True),])def test_is_uuid(test_input, expected): assert is_uuid(test_input) == expected@pytest.mark.parametrize(&apos;test_input,expected&apos;, [ (&quot;321323199509234453&quot;, False), (&quot;000528-332222&quot;, False), (&quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;, True),])def test_has_uuid(test_input, expected): assert has_uuid(test_input) == expected@pytest.mark.parametrize(&apos;test_input,expected&apos;, [ (&quot;321323199509234453&quot;, None), (&quot;000528-332222&quot;, None), (&quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;, &quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;),])def test_extract_first_uuid(test_input, expected): assert extract_first_uuid(test_input) == expected@pytest.mark.parametrize(&apos;test_input,expected&apos;, [ (&quot;321323199509234453&quot;, None), (&quot;000528-332222&quot;, None), ( &quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;, [&apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;]), ( &quot;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4 aslakdj 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&quot;, [&apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;, &apos;521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4&apos;]),])def test_extract_all_uuid(test_input, expected): assert extract_all_uuid(test_input) == expected 测试未通过： 怎么查看代码本身都没有什么逻辑问题，那么问题出在哪里？ 对程序植入一些 print 代码来 Debug 一下： 12345678910111213141516171819202122for regex, regex_pattern in REGEXES.items(): def has_regex_func(_str, regex_pattern=regex_pattern): # 当函数被调用之后，打印 regex_pattern 查看对应的字符串 print(regex_pattern) return has_pattern(_str, regex_pattern) def is_regex_func(_str, regex_pattern=regex_pattern): return match_pattern(_str, regex_pattern) def extract_first_regex_func(_str, regex_pattern=regex_pattern): return find_first_matched_pattern(_str, regex_pattern) def extract_all_regex_func(_str, regex_pattern=regex_pattern): return find_all_matched_pattern(_str, regex_pattern) # 查看是否为同一个函数 print(id(has_regex_func)) setattr(sys.modules[__name__], &apos;has_&#123;regex_suffix&#125;&apos;.format(regex_suffix=regex), has_regex_func) setattr(sys.modules[__name__], &apos;is_&#123;regex_suffix&#125;&apos;.format(regex_suffix=regex), is_regex_func) setattr(sys.modules[__name__], &apos;extract_first_&#123;regex_suffix&#125;&apos;.format(regex_suffix=regex), extract_first_regex_func) setattr(sys.modules[__name__], &apos;extract_all_&#123;regex_suffix&#125;&apos;.format(regex_suffix=regex), extract_all_regex_func) 于是发现问题，所有打印出来的 regex_pattern 都是一致的。也就是，不管是 has_uuid 还是 has_qq_num 还是其他，最后 regex_pattern 都是我在字典中实现的]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>Metaprogramming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL CheatSheet]]></title>
    <url>%2F2017%2F01%2F05%2FPostgreSQLCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 PostgreSQL 相关和命令。 PostGIS 相关的资料参考文章 Geo Processing With Python 安装与基本配置 PostgreSQL 配套工具 PostgreSQL SQL 常用代码片段 Python Driver : psycopg2 , 与两个 ORM ( Django ORM / SQLAlchemy ) 不定期更新。 0x01 安装，配置，基本 shell 命令安装配置基本 Shell 命令12345# 开启关闭pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log startpg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log stoppg_ctl -D /usr/local/var/postgres startpg_ctl -D /usr/local/var/postgres stop -s -m fast 数据的导入导出12345pg_dump -C -Fp -f dump.sql -U twocucao QCS -h 192.168.2.175pg_dump -C -Fp -f 20160602-150144-dump.sql -U twocucao QCS --column-inserts --data-only --table=users_table -h 192.168.2.175# 插入数据psql -U twocucao -d QCS -a -f insert_doc_ids.sql -h 192.168.2.175pg_restore --verbose --clean --no-acl --no-owner -h localhost example.dump 0x02 PostgreSQL 配套工具 JetBrain 的 Datagrip 作为 编写大段 SQL 语句的 IDE 通过网络或者 Dash 查看文档 PostgreSQL 官方自带工具 0x03 PostgreSQL SQL 常用代码3.1 PostgreSQL 相关12345678910-- 强行中断连接到此数据库的 sessionSELECT pg_terminate_backend(pid)FROM pg_stat_activityWHERE -- don't kill my own connection! pid &lt;&gt; pg_backend_pid() -- don't kill the connections to other databases AND datname = 'demoweb' ; 3.2 DCL ( Data Control Languge )1234567891011-- 创建只读用户\c demowebCREATE ROLE ro_user WITH LOGIN ENCRYPTED PASSWORD &apos;xxx123456&apos;;GRANT CONNECT ON DATABASE demoweb TO ro_user;-- This assumes you&apos;re actually connected to mydb..GRANT USAGE ON SCHEMA public TO ro_user;GRANT SELECT ON ALL TABLES IN SCHEMA public TO ro_user;GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO ro_user;-- 撤销数据库连接 ()REVOKE CONNECT ON DATABASE demoweb FROM PUBLIC, demoweb; 3.3 DDL ( Data Definition Language )CREATEALTERDROPTRUNCATECOMMENTRENAME 3.4 DML ( Data Manipulation Languge )SELECTINSERTUPDATEDELETEMERGECALLEXPLAIN PLANLOCK TABLE 3.5 TCL ( Transaction Control Languge )0x04. 常用代码片段4.1. Tips And HacksRecursive Query12345WITH cte_name( CTE_query_definition -- non-recursive term UNION [ALL] CTE_query_definition -- recursive term) SELECT * FROM cte_name; 4.2. 大数据量运算技巧4.3 备份还原技巧1234567891011121314# 需要备份的机器DB_NAME=&apos;xxxdb&apos;DUMP_DB_FILE=&apos;latest_dump.sql.gz&apos;sudo -u postgres pg_dump $DB_NAME | gzip -9 &gt; $DUMP_DB_FILETARGET_HOSTNAME=&apos;xxx.org&apos;TARGET_PATH=&apos;/webapps/&apos;scp $DUMP_DB_FILE root@$TARGET_HOSTNAME:/webapps/# 需要还原的机器DB_NAME=&apos;xxxdb&apos;DUMP_DB_FILE=&apos;latest_dump.sql.gz&apos;sudo -u postgres dropdb $DB_NAMEsudo -u postgres createdb $DB_NAMEgunzip &lt; $DUMP_DB_FILE | sudo -u postgres psql $DB_NAME 0x05. 并发优化技巧 优化技巧请参考我关于 MySQL 的一片文章。 5.1 ACID Atomicity : 行不行，给个准话 Consistency : 完成时候，数据保持一致（多版本并发控制） Isolation : 事务与事务之间是隔离的。即一事务无法查看另一个事务正在修改的数据（默认，如果不默认这玩意，则隔离程度是可以设置的） Durablity : 就是存下来了。 多版本并发控制模型 Each query sees only transactions completed before it started On query start, PostgreSQL records: the transaction counter all transaction id’s that are in-process In a multi-statement transaction, a transaction’s own previous queries are also visible The above assumes the default read committed isolation level 使用 MVCC 多版本并发控制比锁定模型的主要优点是在 MVCC 里， 对检索（读）数据的锁要求与写数据的锁要求不冲突， 所以读不会阻塞写，而写也从不阻塞读。在数据库里也有表和行级别的锁定机制， 用于给那些无法轻松接受 MVCC 行为的应用。 不过，恰当地使用 MVCC 总会提供比锁更好地性能。 5.2 DDL 事务DDL 可以多条放在一起，然后直接 DDL, 据说可以在 sharding 时候用…. 5.3 事务使用123456begin;-- insert_somethings;savepoint my_savepoint01;-- wrong opsrollback to my_savepoint01;commit; 5.4 事务隔离级别 READ UNCOMMITED READ COMMITED REPEATABLE READ SEARLIZABLE 脏读 : 和程序的并发一致 默认是不可能的。 不可重复读 : 一个事物重新读取前面读过的数，但是发现被改过了。能读原来则是可重复读。读新的，则是不可重复读。 幻读 : （举一个为赋新词强说愁的例子）比如，先 count 一下，然后依照 count 值遍历 cursor, 结果发现数量发生变化。 读已提交，是默认。在这里，脏读（不会）、不可重复读（可能）、幻读（可能）。 5.5 锁机制 表级锁模式 行级锁模式 5.6 死锁死锁的典型案例就是： 当你找你爸要钱的时候，你爸说，要是你妈给你钱，我就给你钱。 当你找你妈要钱的时候，你妈说，要是你爸给你钱，我就给你钱。 死锁的四个必要条件： 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 避免死锁的方式，一般是按照顺序来。 当然，数据库可以自动检测出死锁，但是由于捕获死锁需要一定的代价。可能会导致应用程序过久地持有排他锁。 慎用排他锁。 0x06. Python Driver : psycopg2 , 与两个 ORM ( Django ORM / SQLAlchemy )0x07. 踩坑集 序列问题]]></content>
      <categories>
        <category>后台组件</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>CheatSheet</tag>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode Python 解法]]></title>
    <url>%2F2016%2F12%2F21%2FLeetCodePythonSolution%2F</url>
    <content type="text"><![CDATA[前言刷刷简单的算法问题，顺手提升一下编程的裸写代码的能力。 本文为 LeetCode 的 Easy 算法的解法集合。 Easy 集合1. Two Sum 29.4%123456789101112131415161718192021222324252627282930313233343536# 尝试：暴力解决# 结果：超时class Solution(object): def twoSum(self, nums, target): """ :type nums: List[int] :type target: int :rtype: List[int] """ begin = 0 end = 0 for i in range(len(nums)): for j in range(i,len(nums)): if i != j and target == nums[i] + nums[j]: return [i,j]# 尝试：字典也就是 HashMap 解决# 结果：读题不准确，数组不行class Solution(object): def twoSum(self, nums, target): """ :type nums: List[int] :type target: int :rtype: List[int] """ nums_dict = &#123;&#125; for i,num in enumerate(nums): nums_dict[num] = i for num in nums: item_num_1st = nums_dict.get(num) item_num_2st = nums_dict.get(target-num) if item_num_2st is not None and item_num_1st != item_num_2st: return [item_num_1st,item_num_2st]# 尝试：其他# 结果：其他 6. ZigZag Conversion 25.8%7 Reverse Integer 23.7% Easy123456789101112131415class Solution(object): def reverse(self, x): &quot;&quot;&quot; :type x: int :rtype: int &quot;&quot;&quot; preffix = &quot;&quot; if &quot;-&quot; in str(x): num = int(str(x).strip(&quot;-&quot;)[::-1]) preffix = &quot;-&quot; else: num = int(str(x)[::-1]) if num &gt;= 2147483648 or num &lt;= -2147483647: return 0 return int(preffix+str(num)) 8 String to Integer (atoi) 13.8% Easy9 Palindrome Number 34.0% Easy123456789# 使用了额外的存储，亟待优化class Solution(object): def isPalindrome(self, x): &quot;&quot;&quot; :type x: int :rtype: bool &quot;&quot;&quot; l_x = list(str(x)) return l_x == l_x[::-1] 13 Roman to Integer 43.2% Easy14 Longest Common Prefix 30.4% Easy123456789101112131415161718192021222324class Solution(object): def longestCommonPrefix(self, strs): &quot;&quot;&quot; :type strs: List[str] :rtype: str &quot;&quot;&quot; if len(strs) == 0: return &quot;&quot; current_clip = &quot;&quot; len_strs = [len(_str) for _str in strs] min_strs_len = min(len_strs) has_common_flag = False for _len in range(min_strs_len,0,-1): cliped_strs_set = set() for _str in strs: current_clip = _str[0:_len] cliped_strs_set.add(current_clip) if len(cliped_strs_set) == 1: has_common_flag = True break if has_common_flag: return current_clip else: return &quot;&quot; 19 Remove Nth Node From End of List 32.0% Easy20 Valid Parentheses 31.9% Easy21 Merge Two Sorted Lists 37.7% Easy24 Swap Nodes in Pairs 37.0% Easy26 Remove Duplicates from Sorted Array 35.2% Easy27 Remove Element 36.7% Easy28 Implement strStr() 26.8% Easy12345678910111213class Solution(object): def strStr(self, haystack, needle): &quot;&quot;&quot; :type haystack: str :type needle: str :rtype: int &quot;&quot;&quot; cur = -1 try: cur = haystack.index(needle) except Exception: pass return cur 36 Valid Sudoku 33.7% Easy1234567class Solution(object): def isValidSudoku(self, board): &quot;&quot;&quot; :type board: List[List[str]] :rtype: bool &quot;&quot;&quot; # 横向 38 Count and Say 32.3% Easy58 Length of Last Word 31.0% Easy66 Plus One 36.7% Easy67 Add Binary 30.2% Easy70 Climbing Stairs 38.5% Easy83 Remove Duplicates from Sorted List 38.7% Easy88 Merge Sorted Array 31.3% Easy100 Same Tree 45.1% Easy1234567891011121314151617181920# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def isSameTree(self, p, q): &quot;&quot;&quot; :type p: TreeNode :type q: TreeNode :rtype: bool &quot;&quot;&quot; if p is None and q is None: return True elif p is not None and q is not None: return p.val == q.val and self.isSameTree(p.left,q.left) and self.isSameTree(p.right,q.right) else: return False 101 Symmetric Tree 36.7% Easy102 Binary Tree Level Order Traversal 36.7% Easy104 Maximum Depth of Binary Tree 50.6% Easy107 Binary Tree Level Order Traversal II 37.5% Easy110 Balanced Binary Tree 36.1% Easy111 Minimum Depth of Binary Tree 32.2% Easy112 Path Sum 32.8% Easy118 Pascal’s Triangle 36.5% Easy119 Pascal’s Triangle II 34.8% Easy121 Best Time to Buy and Sell Stock 38.9% Easy125 Valid Palindrome 25.2% Easy136 Single Number 52.6% Easy141 Linked List Cycle 35.9% Easy155 Min Stack 26.0% Easy157 Read N Characters Given Read4 29.4% Easy160 Intersection of Two Linked Lists 30.0% Easy165 Compare Version Numbers 19.1% Easy168 Excel Sheet Column Title 24.2% Easy12345678910class Solution(object): def titleToNumber(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; result = 0 for i,c in enumerate(s[::-1]): result += (ord(c) - ord(&quot;A&quot;) + 1) * (26 ** i) return result 169 Majority Element 44.6% Easy12345678class Solution(object): def majorityElement(self, nums): """ :type nums: List[int] :rtype: int """ from collections import Counter return Counter(nums).most_common()[0][0] 170 Two Sum III - Data structure design 22.6% Easy171 Excel Sheet Column Number 45.0% Easy172 Factorial Trailing Zeroes 34.7% Easy189 Rotate Array 23.3% Easy190 Reverse Bits 29.5% Easy12345class Solution: # @param n, an integer # @return an integer def reverseBits(self, n): return int(bin(n).replace(&quot;0b&quot;,&quot;&quot;).zfill(32)[::-1],2) 191 Number of 1 Bits 38.4% Easy198 House Robber 37.2% Easy202 Happy Number 39.0% Easy123456789101112131415class Solution(object): def isHappy(self, n): &quot;&quot;&quot; :type n: int :rtype: bool &quot;&quot;&quot; return self.isHappyNum(self,n,[]) def isHappyNum(self,n,result_list): result = reduce(lambda x , y : x+ y,map(lambda x : int(x) ** 2 ,str(n).split())) if result in result_list: return False else: result_list.append(result) self.isHappyNum(result,result_list) 203 Remove Linked List Elements 30.8% Easy204 Count Primes 26.0% Easy205 Isomorphic Strings 32.3% Easy206 Reverse Linked List 43.2% Easy217 Contains Duplicate 43.5% Easy1234567class Solution(object): def containsDuplicate(self, nums): """ :type nums: List[int] :rtype: bool """ return nums is not None and len(nums) &gt;= 1 and len(nums) &gt; len(set(nums)) 219 Contains Duplicate II 31.3% Easy223 Rectangle Area 31.8% Easy225 Implement Stack using Queues 31.0% Easy226 Invert Binary Tree 49.5% Easy231 Power of Two 39.1% Easy1234567891011121314class Solution(object): def isPowerOfTwo(self, n): &quot;&quot;&quot; :type n: int :rtype: bool &quot;&quot;&quot; if n % 2 == 1 and n &gt; 1: return False elif n &lt;= 0: return False elif n in (2,1): return True else: return self.isPowerOfTwo(n / 2) 232 Implement Queue using Stacks 34.9% Easy234 Palindrome Linked List 31.4% Easy235 Lowest Common Ancestor of a Binary Search Tree 38.0% Easy237 Delete Node in a Linked List 45.2% Easy123456789101112131415# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def deleteNode(self, node): """ :type node: ListNode :rtype: void Do not return anything, modify node in-place instead. 这个方法是可以 Get 到 node 点的，但是题目的要求应该不是这个意思 """ if node.next is not None: node = node.next 242 Valid Anagram 44.6% Easy123456789class Solution(object): def isAnagram(self, s, t): &quot;&quot;&quot; :type s: str :type t: str :rtype: bool &quot;&quot;&quot; from collections import Counter return Counter(s) == Counter(t) 243 Shortest Word Distance 50.5% Easy246 Strobogrammatic Number 38.7% Easy249 Group Shifted Strings 38.1% Easy252 Meeting Rooms 45.2% Easy257 Binary Tree Paths 34.3% Easy258 Add Digits 50.1% Easy263 Ugly Number 38.3% Easy266 Palindrome Permutation 54.8% Easy270 Closest Binary Search Tree Value 37.8% Easy276 Paint Fence 33.7% Easy278 First Bad Version 24.2% Easy283 Move Zeroes 47.5% Easy12345678910111213141516171819202122232425262728# 首先想到的这个答案# 然后 leetcode 上面居然还是打印的原来的值，我猜测肯定是用后台进行 id 比对内存地址。好吧，这个方式最好。class Solution(object): def moveZeroes(self, nums): """ :type nums: List[int] :rtype: void Do not return anything, modify nums in-place instead. """ zero_count = nums.count(0) new_nums = [num for num in nums if num != 0] new_nums.extend([0]*zero_count) nums = new_nums## 蛋疼，三重排序class Solution(object): def moveZeroes(self, nums): """ :type nums: List[int] :rtype: void Do not return anything, modify nums in-place instead. """ begin_cur = 0 end_cur = len(nums) - 1 for i in range(len(nums)): for j in range(i,len(nums)): if nums[j] == 0 and nums[j+1] != 0: nums[j] , nums[j+1] = nums[j+1] , nums[j] print(nums) 288 Unique Word Abbreviation 15.3% Easy290 Word Pattern 31.9% Easy292 Nim Game 54.6% Easy293 Flip Game 53.7% Easy299 Bulls and Cows 33.0% Easy303 Range Sum Query - Immutable 26.1% Easy326 Power of Three 39.1% Easy339 Nested List Weight Sum 59.5% Easy342 Power of Four 37.2% Easy344 Reverse String 57.4% Easy1234567class Solution(object): def reverseString(self, s): &quot;&quot;&quot; :type s: str :rtype: str &quot;&quot;&quot; return s[::-1] 345 Reverse Vowels of a String 37.1% Easy346 Moving Average from Data Stream 57.1% Easy349 Intersection of Two Arrays 45.4% Easy12345678class Solution(object): def intersection(self, nums1, nums2): &quot;&quot;&quot; :type nums1: List[int] :type nums2: List[int] :rtype: List[int] &quot;&quot;&quot; return list(set(nums1) &amp; set(nums2)) 350 Intersection of Two Arrays II 43.4% Easy359 Logger Rate Limiter 58.0% Easy371 Sum of Two Integers 51.5% Easy374 Guess Number Higher or Lower 33.2% Easy383 Ransom Note 45.9% Easy387 First Unique Character in a String 45.1% Easy12345678910111213class Solution(object): def firstUniqChar(self, s): """ :type s: str :rtype: int """ flag = -1 from collections import Counter uniq_chars_set = set([k for k , v in Counter(s).items() if v == 1]) for i,c in enumerate(s): if c in uniq_chars_set: return i return flag 389 Find the Difference 50.3% Easy396 Rotate Function 30.1% Easy400 Nth Digit 30.6% Easy401 Binary Watch 43.1% Easy404 Sum of Left Leaves 45.6% Easy123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def sumOfLeftLeaves(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: int &quot;&quot;&quot; if root is None: return 0 return self.newSumOfLeftLeaves(root.left,-1) + self.newSumOfLeftLeaves(root.right,1) def newSumOfLeftLeaves(self,root,flag): if root is None: return 0 elif root.left is not None and root.right is not None: return self.newSumOfLeftLeaves(root.left,-1) + self.newSumOfLeftLeaves(root.right,1) elif root.left is None and root.right is None: if flag == -1: return root.val + self.newSumOfLeftLeaves(root.right,1) else: return 0 elif root.left is None and root.right is not None: return self.newSumOfLeftLeaves(root.right,1) elif root.left is not None and root.right is None: return self.newSumOfLeftLeaves(root.left,-1) 405 Convert a Number to Hexadecimal 40.6% Easy408 Valid Word Abbreviation 27.2% Easy409 Longest Palindrome 44.1% Easy1234567891011121314151617class Solution(object): def longestPalindrome(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; from collections import Counter max_len = 0 odd_count = 0 for _chr,_chrs_len in Counter(s).items(): if _chrs_len % 2 == 1: odd_count = 1 max_len += _chrs_len - 1 else: max_len += _chrs_len return max_len + odd_count 412 Fizz Buzz 58.0% Easy1234567891011121314151617181920212223class Solution(object): def fizzBuzz(self, n): &quot;&quot;&quot; :type n: int :rtype: List[str] &quot;&quot;&quot; arr = [] for i in range(1,n+1): item = None if i % 3 == 0 and i % 5 == 0: item = &quot;FizzBuzz&quot; arr.append(item) continue if i % 3 == 0: item = &quot;Fizz&quot; arr.append(item) continue if i % 5 == 0: item = &quot;Buzz&quot; arr.append(item) continue arr.append(str(i)) return arr 414 Third Maximum Number 26.7% Easy415 Add Strings 41.1% Easy12345678910111213141516171819# 哼，让我不用，我偏偏要用转 intclass Solution(object): def addStrings(self, num1, num2): &quot;&quot;&quot; :type num1: str :type num2: str :rtype: str &quot;&quot;&quot; return str(int(num1) + int(num2))# 我就不用 int 都可以 one lineclass Solution(object): def addStrings(self, num1, num2): &quot;&quot;&quot; :type num1: str :type num2: str :rtype: str &quot;&quot;&quot; return str(eval(&quot;&#123;&#125; + &#123;&#125;&quot;.format(num1,num2))) 422 Valid Word Square 36.2% Easy434 Number of Segments in a String 39.0% Easy437 Path Sum III 38.6% Easy438 Find All Anagrams in a String 33.4% Easy441 Arranging Coins 36.2% Easy447 Number of Boomerangs 41.8% Easy448 Find All Numbers Disappeared in an Array 61.3% Easy1234567891011class Solution(object): def findDisappearedNumbers(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; len_nums = len(nums) if len_nums &lt; 1: return [] l = list(set(range(1,len_nums + 1)) - set(nums)) return l 453 Minimum Moves to Equal Array Elements 45.9% Easy12345678class Solution(object): def minMoves(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int n - 1 个元素 ++ 等同于 1 个元素 -- &quot;&quot;&quot; return sum(nums) - len(nums) * min(nums) 455 Assign Cookies 48.7% Easy12345678910111213141516171819202122# 二叉树？class Solution(object): def findContentChildren(self, g, s): """ :type g: List[int] :type s: List[int] :rtype: int """ if len(g) == 0 or len(s) == 0: return 0 g.sort() s.sort() satisfied_count = 0 while len(s) &gt; 0: max_cookie = s.pop() while len(g) &gt; 0: max_child = g.pop() if max_child &lt;= max_cookie: satisfied_count += 1 break return satisfied_count 459 Repeated Substring Pattern 39.6% Easy461 Hamming Distance 74.8% Easy1234567891011121314151617class Solution(object): def hammingDistance(self, x, y): """ :type x: int :type y: int :rtype: int """ ma = str(bin(max(x,y))).replace("0b","").zfill(31) ma_len = len(ma) mi = str(bin(min(x,y))).replace("0b","").zfill(31) print(mi) print(ma) count = 0; for i, chr in enumerate(mi): if ma[i] != chr: count += 1 return count 463 Island Perimeter 56.3% Easy475 Heaters 30.3% Easy566. Reshape the Matrix12345678910111213141516171819202122class Solution(object): def matrixReshape(self, nums, r, c): """ :type nums: List[List[int]] :type r: int :type c: int :rtype: List[List[int]] """ row_len = len(nums) col_len = len(nums[0]) if row_len * col_len != r * c: return nums else: new_nums = [[0 for i in range(c)] for j in range(r)] cur = 0 for row_nu in range(row_len): for col_nu in range(col_len): cur += 1 new_row_nu = (cur - 1) // c new_col_nu = cur - new_row_nu * c - 1 new_nums[new_row_nu][new_col_nu] = nums[row_nu][col_nu] return new_nums Medium 集合2 Add Two Numbers 26.1% Medium3 Longest Substring Without Repeating Characters 23.6% Medium5 Longest Palindromic Substring 24.4% Medium11 Container With Most Water 36.0% Medium12 Integer to Roman 42.6% Medium15 3Sum 20.7% Medium16 3Sum Closest 30.4% Medium17 Letter Combinations of a Phone Number 32.1% Medium18 4Sum 25.5% Medium22 Generate Parentheses 41.5% Medium29 Divide Two Integers 15.9% Medium31 Next Permutation 28.0% Medium34 Search for a Range 30.8% Medium35 Search Insert Position 38.8% Medium39 Combination Sum 35.4% Medium40 Combination Sum II 31.0% Medium43 Multiply Strings 25.8% Medium46 Permutations 40.1% Medium47 Permutations II 30.8% Medium48 Rotate Image 36.9% Medium49 Group Anagrams 31.5% Medium50 Pow(x, n) 27.1% Medium53 Maximum Subarray 38.6% Medium54 Spiral Matrix 24.4% Medium55 Jump Game 29.1% Medium59 Spiral Matrix II 37.8% Medium60 Permutation Sequence 27.0% Medium61 Rotate List 24.0% Medium62 Unique Paths 39.0% Medium63 Unique Paths II 30.8% Medium64 Minimum Path Sum 37.0% Medium69 Sqrt(x) 26.8% Medium71 Simplify Path 23.9% Medium73 Set Matrix Zeroes 35.0% Medium74 Search a 2D Matrix 35.6% Medium75 Sort Colors 36.5% Medium77 Combinations 37.6% Medium78 Subsets 36.2% Medium79 Word Search 25.2% Medium80 Remove Duplicates from Sorted Array II 34.7% Medium81 Search in Rotated Sorted Array II 32.9% Medium82 Remove Duplicates from Sorted List II 28.5% Medium86 Partition List 31.4% Medium89 Gray Code 39.1% Medium90 Subsets II 33.6% Medium91 Decode Ways 18.8% Medium92 Reverse Linked List II 29.7% Medium93 Restore IP Addresses 25.7% Medium94 Binary Tree Inorder Traversal 43.5% Medium95 Unique Binary Search Trees II 30.5% Medium96 Unique Binary Search Trees 39.6% Medium98 Validate Binary Search Tree 22.2% Medium103 Binary Tree Zigzag Level Order Traversal 32.0% Medium105 Construct Binary Tree from Preorder and Inorder Traversal 30.6% Medium106 Construct Binary Tree from Inorder and Postorder Traversal 30.8% Medium108 Convert Sorted Array to Binary Search Tree 40.2% Medium109 Convert Sorted List to Binary Search Tree 32.6% Medium113 Path Sum II 31.2% Medium114 Flatten Binary Tree to Linked List 33.4% Medium116 Populating Next Right Pointers in Each Node 36.8% Medium120 Triangle 32.3% Medium122 Best Time to Buy and Sell Stock II 45.3% Medium127 Word Ladder 19.3% Medium129 Sum Root to Leaf Numbers 35.0% Medium130 Surrounded Regions 17.4% Medium131 Palindrome Partitioning 30.6% Medium133 Clone Graph 25.0% Medium134 Gas Station 28.5% Medium137 Single Number II 40.0% Medium139 Word Break 28.0% Medium142 Linked List Cycle II 31.2% Medium143 Reorder List 24.5% Medium144 Binary Tree Preorder Traversal 42.8% Medium147 Insertion Sort List 31.6% Medium148 Sort List 27.2% Medium150 Evaluate Reverse Polish Notation 25.7% Medium151 Reverse Words in a String 15.7% Medium152 Maximum Product Subarray 24.3% Medium153 Find Minimum in Rotated Sorted Array 38.4% Medium156 Binary Tree Upside Down 42.4% Medium161 One Edit Distance 30.3% Medium162 Find Peak Element 35.6% Medium163 Missing Ranges 28.5% Medium166 Fraction to Recurring Decimal 16.7% Medium167 Two Sum II - Input array is sorted 47.9% Medium173 Binary Search Tree Iterator 38.7% Medium179 Largest Number 21.3% Medium186 Reverse Words in a String II 28.5% Medium187 Repeated DNA Sequences 29.3% Medium199 Binary Tree Right Side View 38.4% Medium200 Number of Islands 32.0% Medium201 Bitwise AND of Numbers Range 33.0% Medium207 Course Schedule 30.2% Medium208 Implement Trie (Prefix Tree) 25.6% Medium209 Minimum Size Subarray Sum 28.4% Medium210 Course Schedule II 25.3% Medium211 Add and Search Word - Data structure design 20.1% Medium213 House Robber II 32.9% Medium215 Kth Largest Element in an Array 37.2% Medium216 Combination Sum III 41.5% Medium220 Contains Duplicate III 19.5% Medium221 Maximal Square 26.8% Medium222 Count Complete Tree Nodes 26.9% Medium227 Basic Calculator II 27.9% Medium228 Summary Ranges 27.8% Medium229 Majority Element II 27.6% Medium230 Kth Smallest Element in a BST 41.7% Medium236 Lowest Common Ancestor of a Binary Tree 29.2% Medium238 Product of Array Except Self 46.8% Medium240 Search a 2D Matrix II 37.8% Medium241 Different Ways to Add Parentheses 40.9% Medium244 Shortest Word Distance II 34.8% Medium245 Shortest Word Distance III 49.2% Medium247 Strobogrammatic Number II 38.0% Medium250 Count Univalue Subtrees 40.0% Medium251 Flatten 2D Vector 38.5% Medium253 Meeting Rooms II 38.0% Medium254 Factor Combinations 40.0% Medium255 Verify Preorder Sequence in Binary Search Tree 38.7% Medium256 Paint House 45.7% Medium259 3Sum Smaller 40.5% Medium260 Single Number III 48.9% Medium261 Graph Valid Tree 36.3% Medium264 Ugly Number II 31.3% Medium267 Palindrome Permutation II 30.8% Medium268 Missing Number 43.3% Medium271 Encode and Decode Strings 26.5% Medium274 H-Index 31.9% Medium275 H-Index II 33.5% Medium277 Find the Celebrity 35.4% Medium279 Perfect Squares 34.7% Medium280 Wiggle Sort 54.5% Medium281 Zigzag Iterator 47.9% Medium284 Peeking Iterator 35.0% Medium285 Inorder Successor in BST 36.2% Medium286 Walls and Gates 42.0% Medium289 Game of Life 36.2% Medium294 Flip Game II 44.9% Medium298 Binary Tree Longest Consecutive Sequence 39.7% Medium300 Longest Increasing Subsequence 37.2% Medium304 Range Sum Query 2D - Immutable 22.7% Medium306 Additive Number 27.1% Medium307 Range Sum Query - Mutable 18.5% Medium309 Best Time to Buy and Sell Stock with Cooldown 39.4% Medium310 Minimum Height Trees 28.3% Medium311 Sparse Matrix Multiplication 50.4% Medium313 Super Ugly Number 36.8% Medium314 Binary Tree Vertical Order Traversal 34.9% Medium318 Maximum Product of Word Lengths 41.9% Medium319 Bulb Switcher 41.8% Medium320 Generalized Abbreviation 43.0% Medium322 Coin Change 25.9% Medium323 Number of Connected Components in an Undirected Graph 46.2% Medium324 Wiggle Sort II 25.0% Medium325 Maximum Size Subarray Sum Equals k 41.4% Medium328 Odd Even Linked List 41.6% Medium331 Verify Preorder Serialization of a Binary Tree 34.9% Medium332 Reconstruct Itinerary 27.7% Medium333 Largest BST Subtree 29.6% Medium334 Increasing Triplet Subsequence 37.6% Medium337 House Robber III 41.3% Medium338 Counting Bits 59.3% Medium341 Flatten Nested List Iterator 38.2% Medium343 Integer Break 44.6% Medium347 Top K Frequent Elements 45.6% Medium348 Design Tic-Tac-Toe 45.0% Medium351 Android Unlock Patterns 42.3% Medium353 Design Snake Game 25.1% Medium355 Design Twitter 24.1% Medium356 Line Reflection 29.7% Medium357 Count Numbers with Unique Digits 44.8% Medium360 Sort Transformed Array 43.0% Medium361 Bomb Enemy 37.8% Medium362 Design Hit Counter 52.4% Medium364 Nested List Weight Sum II 50.2% Medium365 Water and Jug Problem 25.9% Medium366 Find Leaves of Binary Tree 56.7% Medium367 Valid Perfect Square 37.2% Medium368 Largest Divisible Subset 32.7% Medium369 Plus One Linked List 52.2% Medium370 Range Addition 52.8% Medium372 Super Pow 32.9% Medium373 Find K Pairs with Smallest Sums 29.5% Medium375 Guess Number Higher or Lower II 34.7% Medium376 Wiggle Subsequence 34.3% Medium377 Combination Sum IV 41.5% Medium378 Kth Smallest Element in a Sorted Matrix 42.9% Medium379 Design Phone Directory 29.1% Medium382 Linked List Random Node 46.1% Medium384 Shuffle an Array 44.7% Medium385 Mini Parser 29.4% Medium386 Lexicographical Numbers 39.0% Medium388 Longest Absolute File Path 34.4% Medium390 Elimination Game 37.4% Medium392 Is Subsequence 44.1% Medium393 UTF-8 Validation 35.2% Medium394 Decode String 39.7% Medium395 Longest Substring with At Least K Repeating Characters 35.3% Medium397 Integer Replacement 28.9% Medium398 Random Pick Index 39.0% Medium399 Evaluate Division 39.2% Medium402 Remove K Digits 25.9% Medium406 Queue Reconstruction by Height 54.1% Medium413 Arithmetic Slices 54.2% Medium416 Partition Equal Subset Sum 37.2% Medium417 Pacific Atlantic Water Flow 32.7% Medium418 Sentence Screen Fitting 26.9% Medium419 Battleships in a Board 59.8% Medium421 Maximum XOR of Two Numbers in an Array 40.6% Medium423 Reconstruct Original Digits from English 41.7% Medium424 Longest Repeating Character Replacement 39.6% Medium435 Non-overlapping Intervals 39.8% Medium436 Find Right Interval 41.9% Medium439 Ternary Expression Parser 49.3% Medium442 Find All Duplicates in an Array 45.6% Medium444 Sequence Reconstruction 20.1% Medium445 Add Two Numbers II 44.5% Medium449 Serialize and Deserialize BST 40.1% Medium450 Delete Node in a BST 32.4% Medium451 Sort Characters By Frequency 50.3% Medium452 Minimum Number of Arrows to Burst Balloons 41.9% Medium454 4Sum II 41.2% Medium456 132 Pattern 27.3% Medium462 Minimum Moves to Equal Array Elements II 50.3% Medium464 Can I Win 21.4% Medium467 Unique Substrings in Wraparound String 28.4% Medium468 Validate IP Address 21.8% Medium469 Convex Polygon 24.6% Medium473 Matchsticks to Square 27.5% Medium474 Ones and Zeroes 32.7% Medium477 Total Hamming Distance 40.1% MediumHard 集合4 Median of Two Sorted Arrays 20.7% Hard10 Regular Expression Matching 23.4% Hard23 Merge k Sorted Lists 25.7% Hard25 Reverse Nodes in k-Group 29.6% Hard30 Substring with Concatenation of All Words 21.6% Hard32 Longest Valid Parentheses 23.0% Hard33 Search in Rotated Sorted Array 31.8% Hard37 Sudoku Solver 27.8% Hard41 First Missing Positive 24.9% Hard42 Trapping Rain Water 35.1% Hard44 Wildcard Matching 18.9% Hard45 Jump Game II 26.0% Hard51 N-Queens 28.8% Hard52 N-Queens II 42.5% Hard56 Merge Intervals 28.2% Hard57 Insert Interval 26.2% Hard65 Valid Number 12.6% Hard68 Text Justification 17.9% Hard72 Edit Distance 30.5% Hard76 Minimum Window Substring 23.6% Hard84 Largest Rectangle in Histogram 25.5% Hard85 Maximal Rectangle 25.8% Hard87 Scramble String 28.1% Hard97 Interleaving String 23.9% Hard99 Recover Binary Search Tree 28.6% Hard115 Distinct Subsequences 30.5% Hard117 Populating Next Right Pointers in Each Node II 33.4% Hard123 Best Time to Buy and Sell Stock III 28.1% Hard124 Binary Tree Maximum Path Sum 24.9% Hard126 Word Ladder II 13.6% Hard128 Longest Consecutive Sequence 35.1% Hard132 Palindrome Partitioning II 23.3% Hard135 Candy 23.8% Hard138 Copy List with Random Pointer 26.5% Hard140 Word Break II 22.0% Hard145 Binary Tree Postorder Traversal 38.2% Hard146 LRU Cache 16.0% Hard149 Max Points on a Line 15.5% Hard154 Find Minimum in Rotated Sorted Array II 36.0% Hard158 Read N Characters Given Read4 II - Call multiple times 24.2% Hard159 Longest Substring with At Most Two Distinct Characters 39.3% Hard164 Maximum Gap 28.5% Hard174 Dungeon Game 22.8% Hard188 Best Time to Buy and Sell Stock IV 23.7% Hard212 Word Search II 22.1% Hard214 Shortest Palindrome 22.7% Hard218 The Skyline Problem 25.3% Hard224 Basic Calculator 25.3% Hard233 Number of Digit One 27.2% Hard239 Sliding Window Maximum 31.2% Hard248 Strobogrammatic Number III 30.2% Hard265 Paint House II 37.0% Hard269 Alien Dictionary 22.5% Hard272 Closest Binary Search Tree Value II 37.2% Hard273 Integer to English Words 20.9% Hard282 Expression Add Operators 28.3% Hard287 Find the Duplicate Number 41.6% Hard291 Word Pattern II 37.4% Hard295 Find Median from Data Stream 23.2% Hard296 Best Meeting Point 50.0% Hard297 Serialize and Deserialize Binary Tree 31.3% Hard301 Remove Invalid Parentheses 34.5% Hard302 Smallest Rectangle Enclosing Black Pixels 43.3% Hard305 Number of Islands II 37.9% Hard308 Range Sum Query 2D - Mutable 19.9% Hard312 Burst Balloons 41.4% Hard315 Count of Smaller Numbers After Self 33.4% Hard316 Remove Duplicate Letters 28.3% Hard317 Shortest Distance from All Buildings 33.2% Hard321 Create Maximum Number 23.8% Hard327 Count of Range Sum 28.6% Hard329 Longest Increasing Path in a Matrix 35.1% Hard330 Patching Array 31.3% Hard335 Self Crossing 23.7% Hard336 Palindrome Pairs 24.3% Hard340 Longest Substring with At Most K Distinct Characters 38.6% Hard352 Data Stream as Disjoint Intervals 38.7% Hard354 Russian Doll Envelopes 31.4% Hard358 Rearrange String k Distance Apart 31.7% Hard363 Max Sum of Rectangle No Larger Than K 32.0% Hard380 Insert Delete GetRandom O(1) 38.0% Hard381 Insert Delete GetRandom O(1) - Duplicates allowed 27.7% Hard391 Perfect Rectangle 23.3% Hard403 Frog Jump 30.2% Hard407 Trapping Rain Water II 35.0% Hard410 Split Array Largest Sum 31.1% Hard411 Minimum Unique Word Abbreviation 30.9% Hard420 Strong Password Checker 21.5% Hard425 Word Squares 42.0% Hard432 All O`one Data Structure 28.4% Hard440 K-th Smallest in Lexicographical Order 21.4% Hard446 Arithmetic Slices II - Subsequence 22.0% Hard465 Optimal Account Balancing 27.5% Hard466 Count The Repetitions 24.6% Hard471 Encode String with Shortest Length 45.9% Hard472 Concatenated Words 28.2% Hard]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>算法与数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cheatsheet]]></title>
    <url>%2F2016%2F12%2F11%2FRedisCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00. 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 MongoDB 相关命令。 Redis Shell Redis 配套工具 Redis-Py Django 中使用 Redis 进行缓存 踩坑记录 不定期更新。 0x01. Redis Shell RedisClient 通过网络或者 Dash 查看文档 Redis 官方自带工具 0x02. Redis 配套工具0x03. Redis-Py0x04. 踩坑记录1. 无法磁盘持久化用 scrapy 配合 scrapy-redis 抓取网页并且存储到 MongoDB 里面。 由于 scrapy-redis 重写了 scrapy 的几个核心模块，借助 redis 来实现多个 scrapy 节点从而实现分布式。 默认的 scrapy 设置会把 items 放在 redis 从而方便程序对 items 进行后续处理。这个设计很完美，只是美中不足的是，我常常需要抓取大量页面直接缓存到数据库中。这就导致了 redis 很快就满了。 于是很容易报出这么一个错误。 (error) MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error. 出错原因如同提示所言，无法磁盘持久化。 基本上问题可能就是： 磁盘满了。 redis 本身在某个地方配置了磁盘缓存的大小。 其他权限之类的问题。 最快的解决方式就是删除占用磁盘的部分。 123456# 进入 redis-cli 删除 itemsconfig set stop-writes-on-bgsave-error nodel xxx_html:itemsconfig set stop-writes-on-bgsave-error yes# 到 bash 下面检查磁盘，我的机器瞬间释放了 3GB 的磁盘空间df -hl 备注：del 一次即可，因为有程序正在运行，所以当 del 之后，原来阻塞的程序接着开始运行。 xxx_html:items 会不断出现新的值。 Scrapy 立马就开始工作了（无需重启）]]></content>
      <categories>
        <category>后台组件</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cheatsheet 集合篇]]></title>
    <url>%2F2016%2F12%2F10%2FCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00. 前言本文为 Cheatsheet 类型文章的集合。 编码最重要的是思路。 做什么不是呢？ 有人问：你想那么多不累吗？ 答：比起出乱子，想多当然是最省事的方式。 截止今日已经更新 7 篇 CheatSheet 文章，打算不断完善它们。 0x01. 目录 Ubuntu CheatSheet Mac CheatSheet Vim CheatSheet VSCode CheatSheet Shell CheatSheet Pandas CheatSheet XPath CheatSheet Docker CheatSheet MySQL CheatSheet PostgreSQL CheatSheet Mongo CheatSheet Redis CheatSheet]]></content>
      <categories>
        <category>编程利器</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB Cheatsheet]]></title>
    <url>%2F2016%2F12%2F09%2FMongoCheatSheet%2F</url>
    <content type="text"><![CDATA[前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 MongoDB 相关命令。 Mongo Shell Mongo 配套工具 Python API 不定期更新。 安装123456789# MacOS 安装brew install mongodbbrew services start mongodb# Ubuntu Server 16.04sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv EA312927echo "deb http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.2 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.listapt-get update -yapt-get install -y mongodb-orgservice mongod start 配置IP 地址MongoDB 配套工具 RoboMongo 通过网络或者 Dash 查看文档 Mongo 官方自带工具 MongoDB Shell基本查询db.users.find({“name”: /.m./})db.users.find({‘name’: {‘$regex’: ‘sometext’}}) https://docs.mongodb.com/manual/ 增删改查use myNewDatabasedb.myCollection.insert( { x: 1 } ); 聚合操作PyMongo1234567# 建索引的时候，会阻塞当前的操作，甚至是查询操作# 据说转为 background 方式不会阻塞但是，没有实践过"msg" : "Index Build Index Build: 167413/751748 22%","progress" : &#123; "done" : 167413, "total" : 751748&#125;,]]></content>
      <categories>
        <category>后台组件</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Text Processing CheatSheet]]></title>
    <url>%2F2016%2F12%2F03%2FTextProcessingCheatsheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中的文本处理相关思路。 本文的目录为： 正则处理相关 HTML/XML 处理相关 Python 中的文本处理 0x01 正则处理相关1.1. 正则表达式正则是个很奇葩的名字，为什么叫做正则表达式呢，首先是个表达式，其次，这是一种叫做正则 (regular expression, rational expression) 的表达式。名称为什么叫做 regular 呢，因为它基于 regular language. 而 regular language 是一种 formal language. 得，现在又开始是编译原理相关概念了。为了逃避概念，通过用途来简单定义正则表达式。 简而言之，就是一种用于字符串搜索的模式。或者就是一种领域专用编程语言。 https://en.wikipedia.org/wiki/Regular_expression 1.2. Python 中正则表达式语法1234567891011121314151617181920212223242526# 元字符. ^ $ * + ? &#123; &#125; [ ] \ | ( )* # 速记，天上一个星星都没有，0 到多个。+ # 一加手机..... 1 到多个。? # 有还是没有 即 0 or 1*? # 没有疑问就是贪婪，有疑问就是非贪婪+???&#123;m&#125; # m 份&#123;m,n&#125; # 优先匹配 a&#123;2,&#125;b 优先匹配 aaaab 中 aaaab&#123;m,n&#125;? # 优先匹配 a&#123;2,&#125;b 优先匹配 aaaab 中 aab[] # [a\-z] == [az-]# 1. [\w] [\S]# 2. [^5]# 3. [akm$] 在 [] 中 $ 并不具备元字符特点PattenA | PattenB(...) # 捕获 , 引用可以使用、1 , 但是还有一种扩展语法(?...) # 扩展# - (?aiLmsux)# - (?:...) 不捕获# - (?P&lt;quote&gt;...) 正则内引用 (?P=quote);python 内获取 m.group('quote') ,m.end('quote');re.sub 内 repl 参数为、g&lt;quote&gt; \g&lt;1&gt; \1 1.3. Python 中使用正则的方法1.3.1. re 模块的用法 sub 替换 match / fullmatch 匹配 search 搜索 split 分片 12re.split('(\W+)', '...words, words...')# ['', '...', 'words', ', ', 'words', '...', ''] match 为匹配起始字符 / fullmatch 为全部字符 / search 为搜索 1.3.2. match object 的用法123456789m.group(0)m.group(1, 2)&gt;&gt;&gt; m = re.match(r"(?P&lt;first_name&gt;\w+) (?P&lt;last_name&gt;\w+)", "Malcolm Reynolds")&gt;&gt;&gt; m.group('first_name')'Malcolm'&gt;&gt;&gt; m.group('last_name')'Reynolds'm.start() # 起始m.end() # 结尾 1.4. 正则表达式性能1234# 编译优于不编译prog = re.compile(pattern)result = prog.match(string)re.match(pattern,string) 0x02 HTML/XML 处理相关2.1. Beautifulsoup 处理 HTML解析往往伴随着各种各样奇葩的不奇葩的，诡异的不诡异的网页数据抽取，这个过程中，我们常使用两个库来解决问题，一个库叫做 lxml, 另一个库叫做 BeautifulSoup. beautifulsoup 可是让我们通过直接手动编写遍历 dom 树的方法来快速遍历 dom 树从而获得数据。相比自己写解析器而言，可以算得上非常的节省时间了。 只要能手动遍历 dom 树，基本上所有的数据都是可以获取的。痛点就是手动编写遍历 Dom 树并且完成测试的时间可能长一些。 但是开发效率就比较低了。 举个例子： 12345678&lt;div id="lal"&gt; &lt;span class="item" itemprop="street-address" title="浦东南路八佰伴西面"&gt; 地址：浦东南路八佰伴西面 &lt;/span&gt; &lt;div class="item" itemprop="street-address" title="浦东南路"&gt; 名称：xxxx &lt;/div &gt;&lt;/div&gt; 我想要地址属性，如果是 beautifulsoup, 则我们需要先定位到 id 为 lal 的 div 元素。然后获取每个元素的 text 部分，然后使用 if 判断地址属性，然后提取 text. 但是如果用 xpath, 则可以把对元素的简单定位简单判断直接写在 xpath 表达式。 123sel.xpath('//div[@id="lal"]/*[contains(text(),"地址")]/text()').extract_first()# 如果还需要添加筛选名称，则可是使用sel.xpath('//div[@id="lal"]/*[contains(text(),"名称")]/text()').extract_first() 这样可以极大的提升开发效率。 页面的结构越复杂，则 xpath 带来的开发效率越高。 2.2. XPath 处理 HTML2.2.1. 概念XPath 是一种通过路径表达式定位 XML 文档内容的语法。由于内置了大量的表达式函数，可以通过极少的代码完成定位。有七种节点类型: element attribute text namespace processing-instruction comment document nodes 有五种节点间关系: 父节点 Parent 子节点 Children 兄弟节点 Siblings 先祖节点，即父与父父节点。Ancestors 后代节点，即子与子子节点。Descendants 语法 描述 例子 nodename 节点名称 a / 根节点 / // 匹配所有 bookstore//book . 当前节点 .. 父节点 a/../a/.. @ 属性 a/@href [] 谓语 book[1] , book[last()-1] func() 表达式函数 postion() 12345response.xpath("//*[@id=\"landlb_B04_04\"]/span[2]/a[contains(@href,'market')]")response.xpath("//*[@id=\"landlb_B04_04\"]/span[2]/a[not(@class)]")response.xpath("//ul/li/b[contains(text(),'什么玩意')]/following-sibling::span/text()")response.xpath("//div[@class='address']/text()[preceding::span[@class='item' and contains(text(),'地址：')]]")response.xpath("//ul/li/b[contains(text(),'什么玩意：')]/following-sibling::a/text()") 12345//*[contains(text(),'ABC')]# http://stackoverflow.com/questions/3655549/xpath-containstext-some-string-doesnt-work-when-used-with-node-with-more/3655588#3655588&lt;div class="atag btag" /&gt;//div[contains(@class, 'atag') and contains(@class ,'btag')] 2.2.2. lxml parsel这两个库是 Python 中常用的解析表达式， parsel 依赖于 lxml , 安装完 lxml 后直接安装即可。 2.2.3. lxml 的番外众所周知，Mac 的 Homebrew 很方便，每一次遇到需要下载编译的组件的时候，只需要执行 brew install xxx, 很快就可以使用了。 但 homebrew 安装的软件都是最新的，这很容易导致部分软件由于版本更新带来的兼容性问题。 这不，最近在 Mac 上进行开发的时候每次调用初始化 lxml 的时候总是无法进行解析，最后经过排查发现问题是 lxml 在编译的时候使用的 libxml 2.9.4 但是 使用的版本为 2.9.2 , 于是每当我使用 lxml 的时候，就会报错。 不得已，找到 lxml 的 F&amp;Q 部分发现提 issue 之前需要先查看依赖版本。 于是进入 IPython 排查。12345678910111213141516import sysfrom lxml import etreeprint("%-20s: %s" % ('Python', sys.version_info))print("%-20s: %s" % ('lxml.etree', etree.LXML_VERSION))print("%-20s: %s" % ('libxml used', etree.LIBXML_VERSION))print("%-20s: %s" % ('libxml compiled', etree.LIBXML_COMPILED_VERSION))print("%-20s: %s" % ('libxslt used', etree.LIBXSLT_VERSION))print("%-20s: %s" % ('libxslt compiled', etree.LIBXSLT_COMPILED_VERSION))# Python : sys.version_info(major=3, minor=5, micro=1, releaselevel='final', serial=0)# lxml.etree : (3, 6, 2, 0)# libxml used : (2, 9, 2)# libxml compiled : (2, 9, 4) # 注意问题出在这里。# libxslt used : (1, 1, 28)# libxslt compiled : (1, 1, 28) 于是使用 pip 强制进行安装升级。 1STATIC_DEPS=true pip install -i http://pypi.douban.com/simple/ –trusted-host pypi.douban.com lxml –ignore-installed –no-cache-dir –upgrade -vvv 安装完毕即可。 2.3. 标准库处理 HTML]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>编程工具</tag>
        <tag>CheatSheet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 爬虫工程师的武器库]]></title>
    <url>%2F2016%2F11%2F25%2FPythonistAwesomeList%2F</url>
    <content type="text"><![CDATA[从大三接触 Python 到现在几乎已经有两年的接触经验了，除去中间有一年左右接私活写写 Android 和 Lamp 之外，有 Python 实际项目开发经验也算是 9 个多月，也稍微算得上是一个入门级别的 Python 程序员了。 网上不乏一些不错的 Awesome list, 但是说实话，这种类型的清单某些程度上不就相当于推荐自己没有看过的书单？ 而我对自己的 Awesome List 是有要求的。 不求大而全到让人摸不着头脑。 项目只收纳在真实开发项目中用过, 正在学习的，并且的的确确提升了我的开发效率的。 平台仅专注 Mac/Linux 上面的工具。 所选工具除非特意标注，皆兼容 Py3.4+ 我觉得这样的 Awesome List 比起那些涵盖各个方面的集合要好很多。 0x01. Python 库我平时的开发以爬虫和 Django 框架为主，偶尔写写 Flask 1.1. 爬虫类爬虫其实也并不是很需要技术水平的东西，对于小规模的爬虫，获取 - 解析 - 分析 - 入库即可。 只是抓取情景变化了之后，需要做的事情就是把各个模块解耦，甚至流程也在某种程度上发生了变化，变成了获取 - 入原始网页库 - 分析 - 入中间数据库 - 再获取 - 分析 - 入关系数据库。 在这个过程中，Python 中有很多很方便的库可以使用。 爬虫框架 Scrapy 爬虫框架王者，配合 Scrapy-Redis 可以很快写出分布式爬虫。 PySpider 用过一两次，觉得总有些奇奇怪怪的小问题。值得围观，不推荐。 当然，即便如此，也并不代表不需要编写定制自己的爬虫。 Scrapy 就像品牌机，是个通用型爬虫，抓取一些简单的网站很好，对付一些比较复杂反爬虫机制比较强的网站，用起来总是束手束脚的，感觉还是需要自己动手组合各个模块进行抓取的。 我是觉得 Scrapy 这种异步的程序调试起来是很费事情的，如果我的想法有错误的话，还请不吝赐教。 所以，下面是我在抓取解析分析入库这个流程中用到的工具第三方库： 爬虫分析网站常用： phantomjs （ Google 出了 Chrome HeadLess 之后，PhantomJS 停止维护） chrome charles 用于抓包和测试 爬虫获取常用： requests multiprocessing threading asyncio Py3.5 异步库 爬虫解析常用： 正则表达式 json nodejs 配合 v8 引擎可以复用一部分 js 代码得出真实数据。 beautifulsoup lxml pyquery w3lib 这也是 scrapy 用的库推荐 pytesseract 简单的图像识别 click 用于编写命令行工具 数据库驱动 mysqlclient-python psycopg2 PyMongo redis-py 数据清洗与入库 Pandas https://github.com/kennethreitz/records https://github.com/kennethreitz/tablib IPython Notebook 数据提取与可视化 xlsxwriter Matplotlib Seaborn ECharts 虽然不是 Python 语言的，但是可以嵌入到 IPython Notebook 中进行可视化。详情请参照我在简书上写的这篇文章 IPython Notebook 引入 ECharts 做可视化 爬虫的部署与监控： psutil supervisor Ansible, Ansible 快支持 Py3 了，所以值得关注。将自己平时部署更新的脚本转成 Ansible 脚本的话，大大提高了部署的速度与准确度。 1.2. 网站开发类 Django django-autocomplete-light django-celery django-compressor django-coverage-plugin django-crispy-forms django-debug-toolbar django-environ django-extensions django-filebrowser django-filter django-formtools django-grappelli django-guardian django-import-export django-model-utils django-mptt django-redis django-reversion djangorestframework django-compressor django-pipeline 由于并非专注开发 Flask 程序，所以不推荐 Flask 相关资源。 1.3. Jupyter 的生态圈由于 Jupyter 原来叫做 IPython Notebook 1.4. 其他 Python 库命令行工具： httpie mycli 如果现在进入 MySQL 终端进行查询的话，首选 MyCLI 小工具： douban.fm 终端 douban.fm douyu.fm 这是我写的一个关于斗鱼 TV 弹幕获取的终端小程序 0x02. 网站 / 订阅对于网站与订阅，求精不求多。 董明伟的博客 http://www.dongwm.com/ 知乎上关于 Python 的专题 https://www.zhihu.com/topic/19552832 个人比较看东西找书或者是找代码的时候有两个习惯： 找牛的人看的资料，而不仅仅是牛人的资料。牛人一般情况下推荐的资料也是上上作品。类似于 PageRank, 一直看下去收获相当大。 求精不求多。毕竟技术日新月异，学好一两个领域足矣。 0x03. 书单其实程序员的阅读量并不完全在纸质书上，主要在各种技术文章上，在各种官网的 Tutorial,Guide,API, 和 Source Code 上面，但是有一些书籍多读几遍还是很有帮助的。 [x] 鸟哥的私房菜 两本 [x] Python Cookbook [x] Python 算法教程 [x] Python 可视化编程 [x] Python Web 开发实战 [x] Python For Data Analysis [x] MySQL 技术内幕 : SQL 编程 [x] MySQL 技术内幕 : InnoDB 技术内幕 [x] 深入浅出 MySQL [x] SQL 反模式 [x] Linux 集群和自动化运维 [x] Practical Vim [x] 大型网站技术架构。核心原理与案例分析 0x04. 进阶源码单书单是进阶的读者推荐给入门读者的读物。源码单是进阶的程序员推荐给入门读者的读物。 下面是董明伟推荐的两个源码单： 初级 Pythoner 源码单 kennethreitz/pip-pop: Tools for managing requirements files. kennethreitz/envoy: Python Subprocesses for Humans™. kennethreitz/records: SQL for Humans™ mitsuhiko/pluginbase: A simple but flexible plugin system for Python. mitsuhiko/pipsi: pip script installer mitsuhiko/unp: Unpacks things. chrisallenlane/cheat jek/blinker: A fast Python in-process signal/event dispatching system. mitsuhiko/platter: A useful helper for wheel deployments. kennethreitz/tablib: Python Module for Tabular Datasets in XLS, CSV, JSON, YAML, &amp;c. 进阶 Pythoner 源码单 faif/python-patterns 使用 Python 实现一些设计模式的例子。 pallets/werkzeug flask 的 WSGI 工具集。其中包含了实现非常好的 LocalProxy,cached_property,import_string,find_modules,TypeConversionDict 等。 bottlepy/bottle 阅读一个 Web 框架对 Web 开发就会有更深刻的理解，flask 太大，bottle 就 4k 多行，当然如果你有毅力和兴趣直接看 flask 是最好了的。 msiemens/tinydb 了解用 Python 实现数据库。 coleifer/peewee 了解 ORM 的实现。 pallets/click click 已经内置于在 flask 0.11 里，提供命令行功能，值得阅读。 以及一个非常神奇的进阶项目 500lineshttps://github.com/aosabook/500lines 0xDD. 常用的一些 Python 配置12# 更新所有 pip 包到最新pip freeze --local | grep -v '^\-e' | cut -d = -f 1 | xargs -n1 pip install -U -i https://pypi.doubanio.com/simple 0xEE. 结论 这就是我，一个 Python 爬虫工程师常用的以及现在主要在学习的关于 Python 方面的 Awesome List. 整理出来分享给大家。 本文不定期更新 生命苦短，我用 Python]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>学习资源</tag>
        <tag>Awesome List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新整理，再度出发]]></title>
    <url>%2F2016%2F11%2F23%2F%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E5%86%8D%E5%BA%A6%E5%87%BA%E5%8F%91%2F</url>
    <content type="text"><![CDATA[整理自己的心情，整理自己的经历，也要整理自己的博客。 重新整理，再度出发。 来到上海的第 9 个月，对自己的水平还是不是很满意。 前几天回常州遇到几个不错的学弟，问了问他们的状况，也大致如此，总觉得自己的水平还是太烂太烂。 李笑来在《把时间当做朋友》这本书里面写过，一个优秀的人，因为对自己的要求高，所以即便他有一门技术 90 分，其他的技术都是 70 分，但是相对于一个普通的人，他的最牛技术为 80 分，而他的其他技术都是 60 分，但由于本身对自己要求就不高，也就心安理得的很接纳自己。 这让我意识到了这一点：恰好是我的高要求让我成为了一个出色的我。 每次到了夜深人静的时候我总是睡不着，我怀疑是不是只有我的明天没有变得更好。 重新捡起博客，只想证明给自己看，我想做的事情，我一定要去做。 人生总是那么短暂，如果不抓紧时间做一些事情，总觉得自己没有存在过。 Get Busy Living, Or Get Busy Dying. 写这篇文章，重新理清楚自己编写文章的分类和标签。也准备把很多太监在自己的笔记里面的技术知识转为代码和文章陆陆续续放出来。 分类如下： 善用佳软 深入理解 macOS Python 黑魔法 Linux DevOps 进击的 JavaScript 后端框架之 Django 进阶 前端框架之 Vue 进阶 Python 爬虫 其他编程语言 后台组件 数据科学 编程漫谈 逆向工程 源码阅读 写在人生的边上 标签如下： MongoDB MySQL RabbitMQ Redis ElasticSearch 分布式 前端开发 可视化 后台组件 后端开发 影评 性能优化 数据分析 机器学习 算法与数据结构 编程工具 编辑器 重构技巧 知乎专业回答 书单与简评 碎碎念 沟通交流 UPDATE: 2016-11-23 : 更新标签内容 2016-12-03 : 修订标签内容 2017-01-15 : 更新分类与标签内容 2017-12-19 : 更新分类与标签内容]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPython Notebook 引入 ECharts 做可视化]]></title>
    <url>%2F2016%2F09%2F20%2FIPynb%E5%92%8CECharts%2F</url>
    <content type="text"><![CDATA[前言Python 的开发生态圈有相当多的好用的数据分析挖掘工具。Pandas,Numpy,Scikit-Learn 等等。 在进行数据分析挖掘的方面，我们选用 IPython Notebook 对数据进行前期的探索和挖掘。以及内部的可视化交流。 也需要经常新的进行一些可视化来使得探索过程更加的顺利。面对海量的数据可视化，也依照目的使用不同的工具。 对于后台开发 / 数据挖掘 / 爬虫工程师而言，内部沟通的过程中注重信息交流沟通的快捷和准确，而不需要考虑可视化的美观程度，所以使用 IPython Notebook 配上 Matplotlib 或者是 Seaborn 进行可视化。 与其他非开发的技术人员交流沟通的时候，这个时候优美的图表就成为了重中之重。 可是 Seaborn Matplotlib 这些库画出来的图，如同那些其貌不扬的高手，包含大量信息，美中不足的就是不美。那可不可以使用更加漂亮的图来可视化呢？ 有，ECharts案例地址戳这里 想拥有 IPython Notebook 的优点上，还能够最大化 IPython Notebook 的美观程度，这就是我们想在 IPython Notebook 中引入 ECharts 作为可视化的初衷。 如果你使用过 IPython Notebook，细心的你一定大致了解，核心困难点在于如何在 IPython Notebook 中引入 ECharts. 今天我们使用 IPython NoteBook 来演示一个简单的 ECharts 饼图案例。本文的数据来自大众点评闵行区部分美食店铺。 代码思路IPython 中，我们知道，可以通过 IPython.display 导入 HTML.1234from IPython.display import HTMLHTML("""&lt;div&gt;这是一小块 HTML&lt;/div&gt;""") 执行就 IPython Notebook 中看到： 1&lt;div&gt;这是一小块 HTML&lt;/div&gt; 但问题来了，我们知道，在通常的情况下，是不能动态引入 JS 脚本的。因此我们在开发 HTML 静态页面的时候，往往脚本都是在 Head 或者 Body 结束标签之前就写死了。如果要在 IPython 中增加 ECharts, 是不是需要修改一些配置文件，让 IPython Notebook 在 Header 部分引入 ECharts 脚本呢？ 答案是不需要. 为何？因为 IPython Notebook 本身自带一个 Js 模块，叫做 RequireJS. 通过这个模块可以动态引入并执行 JS. 具体原理不详细介绍，但是这个模块为 IPython Notebook 动态引入其他 JS 框架和代码带来了无限的可能性。注意，再次强调，这个模块可以帮助我们可以动态引入并执行 JS. 于是通过下面的代码，我们就轻松的将 ECharts 引入到 IPython Notebook 中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162chart_header_html = """&lt;div id="chart" style="width:800px; height:600px;"&gt;&lt;/div&gt;&lt;script&gt; require.config(&#123; paths:&#123; echarts: '//cdn.bootcss.com/echarts/3.2.3/echarts.min', &#125; &#125;); require(['echarts'],function(ec)&#123;var myChart = ec.init(document.getElementById('chart')); var option = &#123; title: &#123; text: '闵行区美食类人均消费餐馆分布', subtext: '数据来自大众点评', x: 'center' &#125;, tooltip: &#123; trigger: 'item', formatter: "&#123;a&#125; &lt;br/&gt;&#123;b&#125; : &#123;c&#125; (&#123;d&#125;%)" &#125;, legend: &#123; orient: 'vertical', left: 'left', data: ['人均消费不明','人均消费 0~50 元', '人均消费 50~100 元', '人均消费 100~150 元', '人均消费 150~200 元', '人均消费 200 元以上'] &#125;, series: [ &#123; name: '店铺比例', type: 'pie', radius: '55%', center: ['50%', '60%'], data: ["""chart_content_html = """ &#123;value: %s, name: '人均消费不明'&#125;, &#123;value: %s, name: '人均消费 0~50 元'&#125;, &#123;value: %s, name: '人均消费 50~100 元'&#125;, &#123;value: %s, name: '人均消费 100~150 元'&#125;, &#123;value: %s, name: '人均消费 150~200 元'&#125;, &#123;value: %s, name: '人均消费 200 元以上'&#125;""" % (consume_unknown_restaurant_count,consume_0_50_restaurant_count,consume_50_100_restaurant_count,consume_100_150_restaurant_count,consume_150_200_restaurant_count,consume_200_greater_restaurant_count)chart_footer_html = """ ], itemStyle: &#123; emphasis: &#123; shadowBlur: 10, shadowOffsetX: 0, shadowColor: 'rgba(0, 0, 0, 0.5)' &#125; &#125; &#125; ] &#125;; myChart.setOption(option); &#125;);&lt;/script&gt;"""HTML( chart_header_html + chart_content_html + chart_footer_html) 看一看代码，首先，配置对应的脚本。引入 requirejs 的配置模块。12345require.config(&#123; paths:&#123; echarts: '//cdn.bootcss.com/echarts/3.2.3/echarts.min', &#125;&#125;); 接着使用如下代码进行引入和执行代码，具体的 Demo 可以参考文章末尾的代码： 1234567require(['echarts'],function(ec)&#123; var option = &#123;//... 图表配置&#125;//... 获取图表 div//... 为所获取的图表 DIV 设置&#125; 效果于是，美观漂亮的可视化图就出来了。 代码附上 IPythonNotebook 以及 Excel 表用于大家分析。 对应的 IPythonNotebook 对应的 Excel 表]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据可视化</tag>
        <tag>IPytho Notebook</tag>
        <tag>ECharts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Cheatsheet]]></title>
    <url>%2F2016%2F09%2F12%2FMySQLCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 MySQL 相关命令。主要包含： MySQL Shell, 其实就是 SQL 命令。 MySQL 配套工具 Python API 不定期更新。 0x01 安装，配置，基本 shell 命令字符编码 UTF-8 , Please 真的很讨厌那些用 GBK 的程序员啊！ 12345678# 注意，下面的设置 MySQL 是无法保存 emoji 的 /[mysql]default-character-set=utf8[mysqld]collation-server = utf8_general_ciinit-connect='SET NAMES utf8'character-set-server = utf8 然后在 mysql console 执行： 1show variables like "%character%";show variables like "%collation%"; 如下即可 0x02 MySQL 配套工具 JetBrain 的 Datagrip 作为 编写大段 SQL 语句的 IDE 通过网络或者 Dash 查看文档 强烈推荐 mycli 作为正常情况下的 MySQL 命令的替代品。 MySQL 官方自带工具 只挑选几个重要的，常用的说一说。 123456789101112131415# 启动 MYSQL# 常规 mysqlmysql -u username -p password## 命令的用户名和密码最好与命令合在一起mysqlshow -uroot -psomepass some_db;# 导入数据mysql -u username -p password &lt; filename# 优雅的导入数据，可以查看进度条的 Hackspv -i 1 -p -t -e /Users/twocucao/Codes/update_new_date.sql | mysql -uadmin -p123456 -h 192.168.2.254 --port=3306 some_db# 导出数据mysqldump -u username -p password database [tables] &gt; filenamemysqldump database table_bame --where="date_column BETWEEN '2012-07-01 00:00:00' and '2012-12-01 00:00:00'"# ref : http://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_where 0x03 MySQL 常用代码1234567SHOW DATABASES;CREATE DATABASE database;USE database;SHOW TABLES;DESCRIBE table;SHOW COLUMN FROM table;DROP DATEBASE; 0x04 常用代码片段1. 数据清洗常用脚本1234-- 少量去重CREATE TABLE everyday_info_temp AS SELECT * FROM everyday_info GROUP BY id,date,numbers;-- 大量去重CREATE TABLE everyday_info_temp AS SELECT * FROM everyday_info GROUP BY id,date,numbers ORDER BY null; http://stackoverflow.com/questions/16568228/how-to-transpose-mysql-table-rows-into-columns 123456SELECT @max := MAX(ID)+ 1 FROM ABC;PREPARE stmt FROM &apos;ALTER TABLE ABC AUTO_INCREMENT = ?&apos;;EXECUTE stmt USING @max;DEALLOCATE PREPARE stmt; mysql&gt; delete from shophtml;Query OK, 117141 rows affected (4 min 2.92 sec)TRUNCATE shophtml; 2. 用户管理常用脚本1SELECT User FROM mysql.user; 3. 备份迁移常用脚本1234567891011121314151617#! /bin/bashTIMESTAMP=$(date +&quot;%F&quot;)BACKUP_DIR=&quot;/mnt/$TIMESTAMP&quot;MYSQL_USER=&quot;root&quot;MYSQL=/usr/bin/mysqlMYSQL_PASSWORD=&quot;password&quot;MYSQLDUMP=/usr/bin/mysqldumpDATABASE=&quot;cyjoycity&quot;mkdir -p &quot;$BACKUP_DIR/mysql&quot;for t in $($MYSQL -NBA -u $MYSQL_USER -p$MYSQL_PASSWORD -D $DATABASE -e &apos;show tables&apos;)do echo &quot;DUMPING TABLE: $DB.$t&quot; $MYSQLDUMP --force --opt --user=$MYSQL_USER -p$MYSQL_PASSWORD $DATABASE $t | gzip &gt; &quot;$BACKUP_DIR/mysql/$t.sql.gz&quot;done 4. 性能优化常用脚本SHOW FULL PROCESSLIST; 5. 其他脚本123456789101112131415# 6. 随机选择 10 组记录-- 慢速SELECT * FROM Table_Name ORDER BY RAND() LIMIT 0,10;-- 快速SELECT name FROM random AS r1 JOIN (SELECT CEIL(RAND() * (SELECT MAX(id) FROM random)) AS id) AS r2 WHERE r1.id &gt;= r2.id ORDER BY r1.id ASC LIMIT 1 1234567891011121314151617181920212223242526272829# 1. 查询时间select date_format(create_time, '%Y-%m-%d') as day from table_nameselect from_unixtime(create_time, '%Y-%m-%d') as day from table_name# 2. CASE WHEN 案例## 2.1 返回同一列多个结果## 2.2 行列值颠倒# 3. 替换某字段内容update table_name set content = REPLACE(content, 'aaa', 'bbb') where (content like '%aaa%')# 4. 获取表中某字段包含某字符串的数据SELECT * FROM `表名` WHERE LOCATE('关键字', 字段名）# 5. 字符串处理SELECT SUBSTRING（字段名，1,4) FROM 表名# 6. 求解数字的连续范围select min(number) start_range,max(number) end_rangefrom( select number,rn,number-rn diff from ( select number,@number:=@number+1 rn from test_number,(select @number:=0) as number ) b) c group by diff; 0x05 性能优化切入点应用的切入点也比较简单和暴力： 优化应用层面的查询。 优化数据库的 SQL 查询。 优化数据库的存储结构。 优化单个数据库服务器的性能。 遵循『机多运算大』的原则，上几台机器。 更好的机器，即加内存条，上好的 CPU。 优化前三点，则需要理解取数据的客户端从发送 SQL 语句到接受数据之间都发生了什么？流程如下： 开启连接 发送查询给服务器 分析查询 执行查询 传输数据 关闭连接 优化应用层面的查询在同样工作量的情况下不断的减少数据库的连接，将多个动作放在一起使用 TRANSACTION 可以显著提高速度。 对于 OLTP 类型的数据库设计的数据库，一些耗时查询往往是可以在应用层面查询进行优化的，比如在手写代码应用级缓存，借助外部组件 (redis) 应用内缓存。 对于一些有性能要求的场景，不要使用 select * from xxx 这种查询，服务器到客户端传输也是需要时间的，而是要选择需要的字段。 如果有必要，不要在循环内部进行数据库查询，而是直接取出来放在内存中进行运算。学过的算法与数据结构用起来！! 优化数据库的 SQL 查询如同前文所见，到了 SQL 命令这层切入点能够优化的地方只有步骤 4. 对于查找，效率取决于： 取记录数量 搜索到这些记录的时间。 对于插入，执行查询则插入记录和更新索引两个部分，也是插入的瓶颈所在： 插入记录 速度取决于记录数量，记录大小 更新索引 速度取决于索引数量。 对于更新，执行查询则有查找，更新记录和更新索引两个部分，也是更新的瓶颈所在： 查找 需要参考查找 更新记录 速度取决于记录数量，记录大小 更新索引 速度取决于更新索引字段的数量。 对于删除，执行查询则有查找，删除记录和删除索引两个部分，也是删除的瓶颈所在： 查找 需要参考查找 删除记录 速度取决于记录数量，记录大小 更新索引 速度取决于更新索引字段的数量。 查询的优化索引的代价 在计算机这个神奇的世界里面，没有一个算法与数据结构的挑选是没有代价的。便于查询，则不便于插入更新。 有的人把索引比作字典。说字典的索引页面就好像是数据表中的索引。 这个比方很贴切，可以用在索引的比方上，也可以用在索引的代价上。 一个没有索引的页面，即是一个只有页码，编号的字典。当我们查询一个新字的时候，只能从第一页翻到结尾，效率很低。 一个有一个索引的页面，即是一个有页码，编号，拼音索引的字典。当我们查询一个新字的时候，先查询索引，然后从索引查页码，于是很快找到字。当我们增加 / 删除 / 更新一个字之后，还需要更新拼音索引。 一个有多个索引的页面，即是一个有页码，编号，拼音索引和部首索引以及其他索引的字典。当我们增加 / 删除 / 更新一个字之后，还需要更新拼音索引，部首索引等等索引。 计算机世界就是这样，没有完美的算法，也没有完美的模型。 数据存储结构硬件优化留空，这个可能比较接近运维或者 DBA 的工作 配置优化留空，这个可能比较接近运维或者 DBA 的工作 0x06 常见问题密码忘了怎么办？1234567/etc/init.d/mysql stopmysqld_safe --skip-grant-tables &amp;# 在另一个终端 输入 mysql 进入终端在另一端执行 SQL 命令UPDATE mysql.user SET password=PASSWORD('nouveau') WHERE user='root';## Kill mysqld_safe from the terminal, using Control + \/etc/init.d/mysql start 0xEE 参考链接关于 SQL 与数据库的有趣解释 Inner Join 和 Outer Join 如何防止 SQL 注入 索引是怎么工作的 Mysql 常用 SQL 语句集锦（本文部分 SQL 语句取自此博文） http://stackoverflow.com/questions/194852/concatenate-many-rows-into-a-single-text-string]]></content>
      <categories>
        <category>后台组件</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
        <tag>MySQL</tag>
        <tag>关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python 监控 Mac 一天的运行（下）]]></title>
    <url>%2F2016%2F07%2F15%2FMacPythonMonitorPart2%2F</url>
    <content type="text"><![CDATA[前言如果有不清楚本文介绍的是什么的？请移步（使用 Python 监控 Mac 一天的运行 - 上）[http://www.jianshu.com/p/9ebb527e93a0] 任务回顾一下： 隔一段时间使用 Python 脚本，统计当前电脑的运行情况，CPU, 内存，硬盘，网络使用状况，然后在每天的下午六点通过 Email 把统计情况汇总，并且必须要有监控图，并通过 Email 发送给我的邮箱。 好了，这篇文章，我们讲解的是具体的 Python 脚本完成这些任务。因为代码可能稍微复杂一点点，老规矩，讲解思路和必要注意点，其他的请参阅代码。 目标确定与任务分解目标就如同上面两段所写。 那么把任务分解一下： 首先，你得知道如何获取计算机的运行信息。 其次，你得知道如何把这些数据保存下来（不保存怎么分析）. 接着，你得知道如何分析并制图。 最后，你得知道如何发送邮件。 好了，本文的目录也就应运而生了。 前言 目标确定和任务分解 Python 获取计算机运行信息 RRDTool 保存计算机运行信息 为什么是 RRDTool 而不是 sqlite-RRD 怎么保存信息-RRD 怎么保存计算机运行信息 RRDTool 制图功能 汇总并发送 Email 思考与不足 代码 Python 获取计算机运行信息我们知道有很多 shell 命令可以获取当前时间点，或者当前时间段的计算机各种情况，但是呢，我们只需要某个时间点的计算机的运行情况，Python 中有一个比较好的神器叫做 psutil, 果断安装之。 1pip3 install psutil 运行如下脚本，你就可以看出来你的电脑运行的当前状况了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!/usr/bin/env python3# -*- coding: utf-8 -*-import platformimport rrdtoolimport osimport sysimport timefrom urllib.request import urlopen,URLErrorimport socketimport getpassimport psutilimport loggingnow = str(time.strftime("%Y%m%d%H%M%S"))today = str(time.strftime("%Y%m%d"))logging.basicConfig( format="%(asctime)s - \[%(process)d]%(filename)s:%(lineno)d - %(levelname)s: %(message)s", datefmt='%Y-%m-%d %H:%I:%S', filename=os.path.expanduser('~/OhMyCode/PyTools/logs/'+today+'.log'), level=logging.INFO)logger = logging.getLogger('monitor_my_mac')if sys.version_info &lt; (3,): raise RuntimeError("at least Python3.0 is required!!")APP_DESC = """ ---- A Terminal Tools For Monitoring Mac Daily@author Micheal Gardner (twocucao@gmail.com) last_update 2016-02-28"""def linux_distribution(): try: return platform.linux_distribution() except: return "N/A"def check_connectivity(reference): """检查是否连接到网络""" try: urlopen(reference, timeout=1) return True except URLError: return Falsedef secs2str(secs): """ 将秒转化为字符串 """ if int(secs) &lt; 0: return "" return str(time.strftime("%Y-%m-%d %H:%M:%S",time.localtime(secs)))def fetch_all_info(): network_connectivity = check_connectivity("http://119.75.218.70") public_ip_addr = urlopen('http://ip.42.pl/raw').read().decode("utf-8") #=============&gt;操作系统信息&lt;==============# print("========&gt;MACHINE&lt;==========") print(getpass.getuser()) print(platform.uname()) # print(os.uname()) print("""Python version: %s dist: %s linux_distribution: %s system: %s machine: %s platform: %s uname: %s version: %s mac_ver: %s """ % ( sys.version.split('\n'), str(platform.dist()), linux_distribution(), platform.system(), platform.machine(), platform.platform(), platform.uname(), platform.version(), platform.mac_ver(), )) os_boot_time = psutil.boot_time() print("Boottime: " + str(os_boot_time) +"-&gt;"+secs2str(os_boot_time) ) print("========&gt;CPU&lt;==========") print(psutil.cpu_times()) print(psutil.cpu_count()) print(psutil.cpu_count(logical=False)) print(psutil.cpu_times_percent()) print("========&gt;MEM&lt;==========") print(psutil.virtual_memory()) print(psutil.swap_memory()) print("========&gt;DISK&lt;==========") print(psutil.disk_partitions()) print(psutil.disk_usage("/")) print(psutil.disk_io_counters()) print(psutil.disk_io_counters(perdisk=True)) print("========&gt;NET&lt;==========") print(psutil.net_io_counters()) print(psutil.net_io_counters(pernic=True)) print(psutil.users()) print("hostname:" + socket.gethostname()) print("internal ip address: " + socket.gethostbyname(socket.gethostname())) print("connected to internet?: " + str(network_connectivity)) print("public ip: " + public_ip_addr )def main(): print(APP_DESC) fetch_all_info()if __name__ == "__main__": main() 好的，下面我就想把这些数据保存下来。 RRDTool 保存计算机运行信息对于 RRDTool, 引自 RRDTool 的官网 RRDtool is the OpenSource industry standard, high performance data logging and graphing system for time series data. RRDtool can be easily integrated in shell scripts, perl, python, ruby, lua or tcl applications. 注意： 如果你看不懂下面关于 RRDTool 的相关内容，请立即反复参考下面的链接，大致留下 rrd 的印象。注意，是反复，是反复，是反复, 重要的事情听说要说三遍的。 http://oss.oetiker.ch/rrdtool/tut/rrdtutorial.en.html wait,wait,don’t tell me, 你怎么使用这个什么 RRDTool, 这又是什么东西？既然你一天只存储一点点的东西，为什么不使用 sqlite? 为什么是 RRDTool 而不是 sqlite答案很简单，因为我们采用的是监控，采用 sqlite 不是说不可以，只是 sqlite 在监控领域不是很专业。那为什么不够专业呢？ 因为在这个场景下，仅仅有存储数据的功能是不够的。 还需要根据监控的场景，进行各种绘图功能。 如果使用 sqlite, 还要安装各种 python 绘图，运算库 (seaborn,numpy,pandas 等）进行统计绘图，那样就不够轻量级了。 而 rrdtool 作为运维监控的常用工具，则成为首选数据库。 RRD 怎么保存信息既然，这是一种叫做数据库的东西，那么，最好的学习方式就是和在实战中练习并且和之前学过的同类型数据进行对比。 那好，我们要回想一下，在学习过的关系型数据库里面，我们是怎么进行数据的怎删改查的。 首先，对于关系型数据库，DBA 创建数据库并指派给某些权限用户，接着由 DB 用户创建表，表中需要各种数据的定义数据类型，最后插入数据，并且进行大量的 curd. 在 sqlite 这种依靠单个文件作为存储介质的关系型数据库，则是由 DB 用户创建表，表中需要各种数据的定义数据类型，最后依赖 SQL 语句插入数据，并且进行大量的 curd.（注：没有谈到事务不代表事务不重要） rrdtool 也是这个道理。它也是依靠单文件作为存储介质的一种 rrd 数据库的实现。先看下面的实例： 这个实例来自于官网的 tutorial : http://oss.oetiker.ch/rrdtool/tut/rrdtutorial.en.html 仔细阅读官方教程，我们大致可以得出以下结论。 对于创建数据库： 12345rrdtool create test.rrd \ --start 920804400 \ DS:speed:COUNTER:600:0:U \ RRA:AVERAGE:0.5:1:24 \ RRA:AVERAGE:0.5:6:10 创建一个数据库文件，文件名为 test, 开始时间为 unix 时间戳 920804400 , 存储的行车速度（额，其实这里我觉得用行车路程表示比较好） 用两个 rra 用来保存”当保存行车路程的时候，经过计算的值”. 一个 databese 是一个 rrd 文件，一个 rrd 文件中存储多个 rra（类似于关系型数据库中，一个数据库里面有多张表）, 但是这里的”表”是用来存储不同的时间间隔的数据，所有的数据来源由创建数据库的时候指定的，(rr 代表 round robin,a 代表 achive) 第一个 RRA 存储的是平均值（也可以存储 MAX 和 MIN),CDP 中的 PDP 超过一半的时候，则 CDP 标记为 UNKNOWNA（这里咱默认 0.5 就好）, 每隔 1 X 300 秒的时候，存一次平均值，存 24 次。 对于更新数据： 12345rrdtool update test.rrd 920804700:12345 920805000:12357 920805300:12363rrdtool update test.rrd 920805600:12363 920805900:12363 920806200:12373rrdtool update test.rrd 920806500:12383 920806800:12393 920807100:12399rrdtool update test.rrd 920807400:12405 920807700:12411 920808000:12415rrdtool update test.rrd 920808300:12420 920808600:12422 920808900:12423 你可能有疑惑：官网里面的 speed 指的不是速度么，怎么会用来代表路程.（回顾一下：路程 = 时间 X 速度）, 官网的教程插入数据的时候，使用的是某个时间点已经行驶的路程。说实话，我也觉得很疑惑。请注意：它更新的数据都是累加的 (COUNTOR), 也就是说， 对于绘图： 1234rrdtool graph speed.png \ --start 920804400 --end 920808000 \ DEF:myspeed=test.rrd:speed:AVERAGE \ LINE2:myspeed#FF0000 123456rrdtool graph speed2.png \ --start 920804400 --end 920808000 \ --vertical-label m/s \ DEF:myspeed=test.rrd:speed:AVERAGE \ CDEF:realspeed=myspeed,1000,\* \ LINE2:realspeed#FF0000 12345678910rrdtool graph speed3.png \ --start 920804400 --end 920808000 \ --vertical-label km/h \ DEF:myspeed=test.rrd:speed:AVERAGE \ "CDEF:kmh=myspeed,3600,*" \ CDEF:fast=kmh,100,GT,kmh,0,IF \ CDEF:good=kmh,100,GT,0,kmh,IF \ HRULE:100#0000FF:"Maximum allowed" \ AREA:good#00FF00:"Good speed" \ AREA:fast#FF0000:"Too fast" 12345678910111213rrdtool graph speed4.png \ --start 920804400 --end 920808000 \ --vertical-label km/h \ DEF:myspeed=test.rrd:speed:AVERAGE \ CDEF:nonans=myspeed,UN,0,myspeed,IF \ CDEF:kmh=nonans,3600,* \ CDEF:fast=kmh,100,GT,100,0,IF \ CDEF:over=kmh,100,GT,kmh,100,-,0,IF \ CDEF:good=kmh,100,GT,0,kmh,IF \ HRULE:100#0000FF:"Maximum allowed" \ AREA:good#00FF00:"Good speed" \ AREA:fast#550000:"Too fast" \ STACK:over#FF0000:"Over speed" RRD 怎么保存计算机运行信息在这里，仅仅使用带宽的统计作为演示案例（案例来自使用 Python 自动化运维这本书）. 创建数据库更新数据库RRDTool 制图汇总并发送 Email思考与不足代码代码地址为： 参考资料https://github.com/yorkoliu/pyauto/blob/master/%E7%AC%AC%E4%B8%89%E7%AB%A0/rrdtool/graph.py http://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python ChangeLog: 2017-03-14 本文已经彻底烂尾了，哈哈哈]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>小玩具</tag>
        <tag>编程工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac Cheatsheet]]></title>
    <url>%2F2016%2F07%2F01%2FMacCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00. 前言 好的工匠懂得挑选合适的工具。 做软件行业之间长了，见多了各种操作系统孰优孰劣 / 编程语言哪家强的论战，也就渐渐懂得了这个异常朴素的道理。也懒得去争论。有争论的时间，不如好好的编写代码，多看些技术书籍。以及熟悉自己的工具。 如果说，你现在问我到底是哪个 OS 好，我只能说： 好的工匠懂得挑选合适的工具。而不是炫耀自己的工具。 BTW : 大约在 2015 年 12 月份有了第一台 MAC, 如今更加喜爱。 本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Mac 快捷键和工具。 不定期更新。 0x01. 必备软件1.1. 常见应用非技术流 启动器 Alfred 3 浏览器 Chrome Firefox 输入法 搜狗输入法 系统清理 AppCleaner 系统增强 Caffeine / PopClip / BetterZip / Amphetamine 手机管理工具 HandShaker / AirDroid 邮件客户端 Airmail 2 录屏截图 Annotate / Camtasia 2 / Snagit / ScreenFlow 下载工具 Aria2GUI / 迅雷 影音处理 Adobe PhotoShop CC , Adobe PhotoShop , Adobe LightingRoom , Final Cut Pro 影音浏览 MPlayerX, QuickTime , IQIYI , NeteaseMusic , iina 远程协助 TeamViewer 办公软件 Wiznote , PDF Expert , Office（虚拟机内部）OmniFocus , OmniGraffle , EuDic , MacTex : Latex 云存储 iCloud , 百度云 手机管理 HandShaker 技术流 终端：iTerm2 GIS 相关 QGIS , PostgreSQL + PostGIS IDE 选择 JetBrain 家的软件 PyCharm, IntellijIDEA 编辑器 MacVim （主力）, 配合 C-VIM 作为日常编写文字的利器。 数据库 MySQL , PostgreSQL（主力） , Redis , MongoDB 数据管理 Navicat,Datagrip,RoboMongo,rdm 文档查看 Dash 网络工具 SS QT 不解释 网络抓包 Charles, Wireshark, Chrome 代码仓库 Github SourceTree 数据分析 Tableau 虚拟机 Vmware Fusion 抓包工具 Wireshark mac 独有命令行 open pbcopy pbpaste screencapture launchctl mdfind（还是 linux 的 find 好用） sip （还是比较推荐 imagemagic) 1.2. Homebrew 和 iTerm2iterm2 下载 12# homebrew 安装/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 另起终端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# aerial 屏保# https://github.com/JohnCoates/Aerialbrew cask install aerial# https://github.com/sindresorhus/quick-look-pluginsbrew cask install qlcolorcode qlstephen qlmarkdown quicklook-json qlprettypatch quicklook-csv betterzipql qlimagesize webpquicklook suspicious-package quicklookase qlvideo# Install some other useful utilities like `sponge`.brew install moreutils# Install GNU `find`, `locate`, `updatedb`, and `xargs`, `g`-prefixed.brew install findutils# Install GNU `sed`, overwriting the built-in `sed`.brew install gnu-sed --with-default-namesbrew install bash zshbrew install wget --with-iri# Install Pythonbrew install pythonbrew install python3brew tap bramstein/webfonttoolsbrew install sfnt2woffbrew install sfnt2woff-zopflibrew install woff2# Install other useful binaries.brew install ackbrew install dark-mode#brew install exiv2brew install gitbrew install git-lfsbrew install git-flowbrew install git-extrasbrew install hubbrew install imagemagick --with-webpbrew install luabrew install lynxbrew install p7zipbrew install pigzbrew install pvbrew install renamebrew install rhinobrew install speedtest_clibrew install ssh-copy-idbrew install treebrew install webkit2pngbrew install zopflibrew install pkg-config libffibrew install pandoc# Lxml and Libxsltbrew install libxml2brew install libxsltbrew link libxml2 --forcebrew link libxslt --forcebrew cleanup# 如果需要升级brew update &amp;&amp; brew upgrade --all &amp;&amp; brew cleanup &amp;&amp; brew prune 有时候 /usr/local 的可能会存在权限问题，建议如果可能出现问题，则需要执行下面的命令修复权限。 1sudo chown -R $(whoami):admin /usr/local/ 0x02. 开发者必备2.0. Shell 注意：MAC 使用的大多命令来自于 FreeBSD , 并不是来自 GNU , 所以很多命令会与常规的 linux 命令不太一样。 所以，Shell 命令请在安装完 Gnu 的工具集之后，可以到我的文章 Shell CheatSheat 查看语法。 关于 shell 脚本，请参考我的另一篇文章。 Shell CheatSheat 2.1. Python 笔者虽然也接触过很多语言，都是粗浅一过，但无一精通，唯一可以稍微谈谈的就是 Python 语言。 当然，安装完毕自然是可以参考一下我的 Python 武器库啦 Python 工程师的武器库 2.1.1. Python 安装1234567891011121314151617181920212223242526272829303132333435git clone https://github.com/yyuu/pyenv.git ~/.pyenvgit clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenvecho 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.zshrcecho 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv init -)"' &gt;&gt; ~/.zshrcecho 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.zshrc# 接着另开终端# 不喜写兼容代码，所有代码均向 3.5+ 靠拢v=3.5.2|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=3.6.0|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $vv=2.7.11|wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v# 可以先用迅雷把 官网的 Anaconda3-4.4.0-MacOSX-x86_64.sh 下载下来，然后mv Anaconda3-4.4.0-MacOSX-x86_64.sh ~/.pyenv/cache/ &amp;&amp; pyenv install anaconda3-4.4.0# 设置 Global Python 为 2.7.11, 备注：尽量不要把 Py3 设置为全局，否则由于 Homebrew 本身有一些依赖是依赖于 Py2 的，这样容易出现一些奇怪的问题。pyenv global 2.7.11pip install -i https://pypi.doubanio.com/simple requests# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hy# 创建最常用 Py3 虚拟环境pyenv virtualenv 3.5.2 py3-dailypyenv activate py3-dailypip install -i https://pypi.doubanio.com/simple requestspip install -i https://pypi.doubanio.com/simple beatutifulsoup4pip install -i https://pypi.doubanio.com/simple ipython[notebook]pip install -i https://pypi.doubanio.com/simple jupyter# 下面这个是用于安装基本的代码补全功能pip install -i https://pypi.doubanio.com/simple --upgrade "jedi&gt;=0.9.0" "json-rpc&gt;=1.8.1" "service_factory&gt;=0.1.5" flake8 pytest autoflake hy# 创建 Anaconda 的数据科学 AI 环境pyenv virtualenv anaconda3-4.4.0 py3-aipyenv activate anaconda3-4.4.0/envs/py3-aipyenv deactivate 2.1.2 Python 环境的坑Homebrew 的 Python 问题如果本机安装了 Homebrew 如果后面使用 PyEnv 或者 Anaconda 设置当前环境为默认 Python 为 Python3（不建议这么搞）, 但是如果偏偏要把默认的 Python 版本换成 Python3, 会弹出一些 pythonpath 的问题，执行下面命令即可暂时屏蔽这个问题，但是后没有隐患则不清楚。mv /usr/local/lib/python2.7/site-packages/sitecustomize.py /usr/local/lib/python2.7/site-packages/sitecustomize.py.back 网络问题在 Python 中执行下面的代码的时候总是报错： 12ip = socket.gethostbyname(socket.gethostname())# socket.gaierror: [Errno 8] nodename nor servname provided, or not known 最后发现是因为设置主机名没有设置好 12345sudo scutil --set ComputerName "newname"sudo scutil --set LocalHostName "newname"sudo scutil --set HostName "newname"dscacheutil -flushcache# 然后重启电脑即可 0x03. 高效率软件 &amp;&amp; 专业软件3.1. OmniFocus3.2. OmniGraffle3.3. Final Cut Pro3.4. Keynote0xDD. 参考链接 https://github.com/donnemartin/dev-setup 0xEE. 扩展阅读 关于 Mac 我的回答 关于 Ubuntu 我的回答 关于 Win10 我的回答 ChangeLog: 2017-06-28 Python 环境 和 Homebrew 安装环境]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>CheatSheet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python 监控 Mac 一天的运行（上）]]></title>
    <url>%2F2016%2F04%2F15%2FMacPythonMonitorPart1%2F</url>
    <content type="text"><![CDATA[前言一不小心写成上下两篇了。真是有些过意不去。毕竟，写的太多就少了一部分读者（少了一部分赞额）. 之所以拆成上下两篇，主要是因为在研究的过程中越发感到在一篇中强行植入那么多的东西，自己的文章结构组织起来有些困难，对读者来说，也是不容易理解。那倒不如拆分成两部分。 任务分解我的需求如此简单，统计 Mac 上面一天的运行情况，然后在每天的下午六点把统计的情况汇总通过 Email 发送给我。 用更加具体来说，就是， 隔一段时间使用 Python 脚本，统计当前电脑的运行情况，CPU, 内存，硬盘，网络使用状况，然后在每天的下午六点通过 Email 把统计情况汇总，并且必须要有监控图，并通过 Email 发送给我的邮箱。 初看这玩意是挺简单的，但是自己动手写了以后就知道，其实还是稍微有些费时间的。 比如： linux 下面定时执行一个脚本只需要 crontab 或者 at 以下就好了.mac 上是是什么？怎么运行一个任务？ 统计的数据存哪儿？用什么存？ 表格绘图怎么画出来？ Email 怎么发送，如果要发送好看一点点的 Email 怎么办？ 既然那么多，那就分成两篇，一篇用来介绍 Mac 上面的定时任务（简单，短文）, 另一篇用 Python 来监控 Mac 电脑，并持久化监控数据，绘图，汇总，发送 email.(稍微复杂一点，带图长文） 上篇讲在 Mac 上如何让一个脚本定时运行。 下篇讲如何写一个 Python 监控脚本。 本文结构 前言 本文结构 为什么需要定时任务？ Mac 上面如何进行定时任务。 疑问和解答 扩展阅读 为什么需要定时任务？所谓的定时任务，分为两种： 指定时间执行的程序 每隔一段时间执行的程序 执行的内容，通常情况下和要做什么事情有关，但是从内容上，分为两种： 任务之间的数据没有什么关联的 比如，你想去抓一些数据（迅雷会员账号）但是懒得自己动手，于是就写了一个小脚本，放在每天早上的 8 点钟，去抓来账号。 任务之间的数据有关联的，甚至某种程度上可以绘制图像。 比如，下一篇要说的使用 Python 监控自己的电脑情况，e.g: 流量。隔一段时间就查看一下自己的电脑运行情况，把情况存下来。甚至，在某个时间点，把结果汇总发给某个人。 Mac 上面如何进行定时任务。 首先，你要写一个任务。 其次，让这个任务定时执行。 好，简单的写一个任务 get_time.sh. 12#!/bin/bashdate &gt;&gt; /Users/twocucao/Downloads/dates.txt 接着加上可执行。1chmod a+x get_time.sh 那么，怎么让 Mac 通过 launchd 隔一段时间就执行脚本呢？ 创建一个特殊的 xml 文件叫做 com.twocucao.apple.getdates.plist, 给你所要运行的命令建立一个进程。 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt;&lt;dict&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;com.twocucao.apple.getdates&lt;/string&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;/Users/twocucao/OhMyCode/Bash/get_time.sh&lt;/string&gt; &lt;/array&gt; &lt;key&gt;StartInterval&lt;/key&gt; &lt;integer&gt;10&lt;/integer&gt;&lt;/dict&gt;&lt;/plist&gt; 对于这个 com.twocucao.apple.getdates 随你命名的，保证唯一就好。通常情况下选择反转域名（和 Java 编程类似）, 其他的，依照你的脚本位置和间隔时间修改。 拷贝到 LaunchDaemons, 加载定时工作，然后检查是否加载成功 1234cp com.twocucao.apple.getdates.plist /Library/LaunchDaemonslaunchctl load -w /Library/LaunchDaemons/com.twocucao.apple.getdates.plist#列出定时任务，并且筛选一下。确认是否加载成功。launchctl list | grep twocucao 由于这个脚本实在是太弱智了仅仅是为了演示，所以，记得把他给卸载，删除 12launchctl unload -w /Library/LaunchDaemons/com.twocucao.apple.getdates.plistrm /Library/LaunchDaemons/com.twocucao.apple.getdates.plist 疑问和解答 问：为什么要把脚本的配置放在 /Library/LaunchAgents 呢？ 答：当然，你可以拷贝到其他的地方， 如果你的需求是该用户登录时候执行的话，那么拷贝到：~/Library/LaunchAgents, 这叫做 User Agents. 如果你的需求是该用户登录时候执行的话，那么拷贝到：/Library/LaunchAgents, 这叫做 Global Agents 如果你的需求是让 Root 用户或者指定用户登录时候执行的话，那么拷贝到：/Library/LaunchDaemons , 这叫做 Global Daemons 如果你的需求是用户登录执行，那么拷贝到：/System/Library/LaunchAgents ,System Agents 如果你的需求是让 Root 用户或者指定用户登录时候执行的话，那么拷贝到：/System/Library/LaunchDaemons, 这叫做 System Daemons. user-agents 是级别最低，其他所需权限依次递增。 问：怎么检查任务执行结果？ 答：tail -f /Users/twocucao/Downloads/dates.txt 问：如何确定 launchd 存在这个任务 答：launchctl list 问：既然是隔一段时间就能执行脚本，那么，我可以先用简单的 shell 脚本，配置好相关执行信息，让他定时执行，接着修改 shell 脚本执行新的逻辑么？ 答：可以。 问：bash 命令监控多么方便，为何下一篇要使用 Python 作为监控工具。 答：shell 命令编写代码不直观，编写效率低.Python 有很好的第三方库可以使用。 扩展阅读（精选优质资料） 一个关于 Linux 命令的各种奇技的网站 http://www.commandlinefu.com/commands/browse Linux 工具快速教程 http://linuxtools-rst.readthedocs.org/zh_CN/latest/index.html 关于 launchd 的参考链接， http://launchd.info/ http://www.splinter.com.au/using-launchd-to-run-a-script-every-5-mins-on/ https://developer.apple.com/library/mac/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html http://linuxtools-rst.readthedocs.org/zh_CN/latest/index.html 命令行的艺术 https://github.com/jlevy/the-art-of-command-line ChangeLog: 2016-12-05 重新排版。]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>编程工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 上面的远程控制 Teamviewer]]></title>
    <url>%2F2016%2F04%2F02%2FMacRemoteControl%2F</url>
    <content type="text"><![CDATA[0x00 前言前段时间一直在抓取一个站点，这个站点非常难爬取，原因如下： 第一点，网站 Ajax 超级多。 第二点，所有的 API 都是 js 加密后才能访问。 第三点，这也是最最要命的一点，访问特别特别不稳定。有的时候加载时间特别长，70 秒请求一个 API 这点我会告诉你吗？动不动就 404 not found 我能和你说？ 当然，这些都难不倒我，我最后挑选了 Phantomjs, 编写 Js 调用脚本，从命令行调用程序，将抓取结果输出到标准输出流中，接着获取使用 beautifulsoup 进行基本的解析。剩下的就是入库了。 这里的技术点也是蛮多的，以后有机会就介绍一下.（汗，因为毕业设计这回事情实在是耽误了不少梳理博文的时间，攒了不少开了个头的文章，但自己又不忍心把不好的文章放出来污染大众视野.) 0x01 事情开始变化了程序在运行了很长一段时间之后，有一定几率崩溃。再次开启的时候，有一些需要人工检查的参数，用 supervisor 并不是很方便。 0x02 那怎么该如何是好？公司的电脑上写了每个小时将自己的抓取情况发送给我的邮箱，但是糟心的问题是，一旦我在家中，程序崩溃了，我也就只能浪费掉我那接近半天的抓取时间了。我必须要远程控制公司的电脑。怎么办呢？ 第一种，使用 ssh, 这样我在家里就可以远程控制公司的电脑了。 第二种，使用远程控制软件。 我首先想到的是使用 ssh, 因为这个比较常用，用起来会习惯一些。 2.1 在家里配置 ssh 到公司的电脑上需要哪些方法呢？请注意： ssh 无法穿透路由器 什么意思？很简单，对于你在家里这个外网来说，你只能”看到”公司在公网的这台路由器，无法看到经过 NAT 转换的公司内网的服务器。 于是，我们可以得出远程方法如下： 公司路由器的公网地址固定，那么可以在路由器上直接做一个端口映射，将路由器的 ip 的 22 端口（也可以是其他端口）映射到公司局域网内部的一台机器。这样你就可以直接 ssh 公司的路由器，但最终访问的就是你的 mac 或者 linux 机器了。 那如果公司的路由器是拨号上网的呢（比如我现在待得这个小公司，使用的是电信宽带光纤拨号上网）? 很简单，通常情况下你需要及时获取公司公网的 ip 地址。所以，你只需要在你的公司电脑上写个脚本定时把公网的 ip 地址发给你的邮箱里就好了。 在操作的时候，直接使用 tmux 或者 screen 就可以查看这些耗时软件的运行情况了。 但，我最后没有使用这个方案呢？因为电信把路由器的高级功能给阉割掉了，端口映射做不了。并且，由于公司的路由器均为普通网线口，并非光纤接口，唯一有光纤接口的就仅仅只有电信的路由器。 虽然 ssh 很方便，可是打电话找电信太麻烦，于是这个方案被我否定了。 2.2 那么远程控制软件怎么样呢？经过不断的搜索，我发现了一款非常棒的穿透力特别强远程操作又相对稳定的软件。可能你也听说过这款软件 teamviewer. 前段时间也用这个软件给学弟们操作搭建部署环境的时候用到的，非常好用。比 qq 的远程协助稳定多了。 并且，可以通过注册账号，直接把机器分配给账号。 然后直接登录账号进行连接就好了。 ╮(╯▽╰)╭所以，我就可以安安心心在家里阅读抓取情况的邮件，当邮件抓取数量出现异常的时候，我就直接开远程过去查看了，修整软件就好了。 0x03 结论当然，其实最好的方式还是通过 ssh 配合 tmux 进行管理，但是如果你没有路由器的操作权限（不能做端口映射）, 或者像我一样公司的上网环境比较坑（电信路由器）的话，teamviewer 也算是图形界面中优雅的远控方式。并且，可以使用 windows 控制 mac, 也可使用 mac 控制 windows, 这点实在让人非常心动。 &gt; 后续：其实可以用路由器做两次端口转发的，当时没有想到这个两层端口转发。ChangeLog: 2017-03-14 重修文字，修正部分错误的说法]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>编程工具</tag>
        <tag>远程控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何发布一个 Python 命令行工具]]></title>
    <url>%2F2016%2F03%2F15%2F%E5%A6%82%E4%BD%95%E5%8F%91%E5%B8%83%E4%B8%80%E4%B8%AAPy%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[本文简介上次写的一个终端里面斗鱼 TV 弹幕 Python 版本和 Ruby 版本，并且发布到 PIP 和 RubyGems 上面。在发布 PIP 包的时候，居然 Google 不到一篇可以非常好的讲解这个流程的文章。于是整理这篇文章，并且方便后来自己检索，并且方便他人找资料。 自推荐下依照本文定制的命令行工具 danmu.fm 的 github 地址： https://github.com/twocucao/danmu.fm 本文的目的也是非常简单： 写一个 Python 命令行工具，并且发布到 PIP 上面.并且在这个过程中给出我自己的一些思考。 如何分解这个发布任务？只需要进行如下的两个步骤便可以： 写好一个 Python 命令行工具。 发布它。 当然，这样不够细致。再细分一下。 写好一个 Python 命令行工具 1.1. 命令行的特点，以及 Python 的如何编写命令行 1.2. 如何组织代码结构。 发布 2.1. 注册 pypi 账户 2.2. 注册在账户下面注册 Python 包 2.3. 上传打包好的 Python 命令行工具。 完善代码 1. 写好一个 Python 命令行工具写好一个命令行工具首先要知道命令行工具是什么？ 在我看来，命令行工具就是一种完成某种类型的任务的终端程序。 也就是基本上没有什么用户界面的程序。 由于基本上没有什么用户界面，所以导致单个命令行的交互能力及其低下。但这种低下的交互性对于一些固定工作而言，简直就是最灵活的工具。只需要输入一些命令便可以完成某种类型的工作。实在是方便的很。 所以，某种程度上，终端程序低交互的缺点反而成了优点。 1.1.Python 的如何编写一个简单的命令行对于 Python 和命令行交互，我们很容易想出一个比较方便的方案。 sys.argv 就是这样的嘛！ 我们很容易这样写代码。 1python testargv.py thisisaargv1 甚至我们也可以这样写命令行， 1python testargv.py thisisaargv1 -d -f 0 那么，这样写的后果就是，不方便解析出（不是不能，是不方便） -d -f 0 以及 thisisaargv1. 不信的话，你解析一个下面场景的命令行试试， 1234# 用户可能这样输入danmu.fm http://www.douyutv.com/xiaocang -q 1 -v 2danmu.fm -q 1 -v 2 http://www.douyutv.com/xiaocang# 当然，肯定还有漏写啦，等等，你得需要转类型，增加各种 blablabla 的描述吧，添加默认的参数值吧。 于是 Python 就提供了一个非常好用的模块可以使用。叫做 argparse. 上面的描述就变成了这个样子12345678910111213141516171819import argparseAPP_DESC="""这就是描述"""print(APP_DESC)if len(sys.argv) == 1: sys.argv.append('--help')parser = argparse.ArgumentParser()parser.add_argument('-q','--quality',type=int,default=0,help="download video quality : 1 for the standard-definition; 3 for the super-definition")parser.add_argument('-v','--verbose', default=0,help="print more debuging information")parser.add_argument('-s','--store',help="保存流媒体文件到指定位置")parser.add_argument('-c','--config',default=0,help="读取~/.danmu.fm 配置，请~/.danmu.fm 指定数据库")parser.add_argument('url',metavar='URL',nargs='+', help="zhubo page URL (http://www.douyutv.com/*/)")args = parser.parse_args()# 获取对应参数只需要 args.quality,args.url 之类。url = (args.url)[0]print(url)#其他执行逻辑 保存为 danmu.py 这样就可以执行命令1python danmu.py http://www.douyutv.com/xiaocang -q 1 -v 2 通过 args 就可以获取参数，然后进行终端程序的参数初始化。 可是这和我们的要求还是不同嘛，我们不想多写 Python XXX, 我们想直接 XXX. 就像这样。 1danmu.fm -q 1 -v 2 http://www.douyutv.com/xiaocang 不急，下面就是了。 1.2. 如何组织代码结构。于是，现在就要开始组织代码结构了。 我们在最终的代码目录大概是这样的。 1234567891011121314151617181920212223danmu.fm├── README.md├── danmufm│ ├── __init__.py│ ├── client│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── douyu_client.py│ │ └── douyu_danmu_client.py│ ├── danmu.py│ ├── misc│ │ ├── __init__.py│ │ ├── color_printer.py│ │ ├── downloaders.py│ │ └── player.py│ └── model│ ├── __init__.py│ └── douyu_msg.py├── docs├── setup.cfg├── setup.py├── sh.py└── tests 这就是我上次写的 danmu.fm 的代码目录。 聪明的你这时候你注意到了： 主要的程序不是放在根目录下面，而是放在第二目录 danmufm 下面。2.setup.cfg 是什么鬼东西3.setup.py 是什么鬼东西 对于上面几点，我们分别进行解释 ###1.2.1 为什么主要程序在第二目录下 为了把主要的程序分离出来，放在第二目录下面，这样的待会打包以后多出很多文件夹就不会对源码造成干扰。 当然，由于把程序放在了第二目录下面，所以，脚本里面的 from import 语句应该使用相对路径导入。 相对路径导入的的时候需要注意运行的时候使用如下命令 1python3 -m danmufm.danmu [xxxx] ###1.2.2 setup.cfg 填写如下内容即可。 12[metadata]description-file = README.md 然后去写 Markdown 的 Readme 就好了。 ###1.2.3 setup.py 这个是重头戏了。 setup 这个 py 文件就是打包配置文件。对这个程序是谁的，有什么依赖，入口是什么，等等等等的配置。 12345678910111213141516171819202122232425262728293031#-*- encoding: UTF-8 -*-from setuptools import setup, find_packages"""打包的用的 setup 必须引入，"""VERSION = '0.1.1'setup(name='danmu.fm', version=VERSION, description="a tiny and smart cli player of douyutv,ximalayad,anmu based on Python", long_description='just enjoy', classifiers=[], # Get strings from http://pypi.python.org/pypi?%3Aaction=list_classifiers keywords='python douyu danmu danmu.fm terminal', author='twocucao', author_email='twocucao@gmail.com', url='https://github.com/twocucao/doumu.fm', license='MIT', packages=find_packages(), include_package_data=True, zip_safe=True, install_requires=[ 'requests', ], entry_points=&#123; 'console_scripts':[ 'danmu.fm = danmufm.danmu:main' ] &#125;,) 官方有 distutils 这个包管理器工具，设置也非常的简单，只是，它不支持 entry_points 属性，由于无法使用 entry_point, 也就无法通过命令来跳转到指定模块运行程序，这也就意味着，官方工具不方便写成命令行。还是 setuptools 好。 上面需要注意的就是 install_requires 可以添加依赖。其他的你猜都可以猜出来是做什么的。自己去看代码，我就不多说了。 2. 发布所谓的发布，就是将打包好的程序的某个版本发布到某个仓库中。 2.1. 注册 pypi 账户到这个上面注册账号：https://pypi.python.org/pypi 2.2. 注册在账户下面注册 Python 包进入对应项目根文件，然后执行1python3 setup.py register 这一步程序会让你输入刚刚注册的账号和密码，然后注册该包。注册该包以后，你就有了一个小仓库。可以存放不同版本的 danmu.fm. 注册的仓库是可以在这个地址看到的，https://pypi.python.org/pypi?%3Aaction=pkg_edit&amp;name=danmu.fm 2.3. 上传打包好的 Python 命令行工具。这里需要借助一个小工具，twine.twine 是一个更加安全方便上传打包好的代码的工具。 1pip3 install twine 接着开始打包，打包成两个版本，一个是不需要 build 的版本，另一个是需要 build 的版本（顺带吐槽下，这两个诡异的命名）. 1python setup.py sdist bdist_wheel 于是剩下来的就显而易见了，上传 build 完毕的程序到仓库中。 1twine upload dist/danmu.fm-0.1.2* 于是，安装一下，测试是否成功 1pip3 install danmu.fm --upgrade 命令行的工具是这样使用的。 1danmu.fm -q 2 -v 1 http://www.douyutv.com/16789 3. 完善不断的完善代码，然后打包终端程序发布到仓库给别人用，这就是整个的 PIP 打包发布流程。 这个时候，你可能需要使用版本控制软件。 你可能需要增多的代码的测试。]]></content>
      <categories>
        <category>我的开源项目</category>
      </categories>
      <tags>
        <tag>pip</tag>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于背单词软件，你不知道的惊人真相]]></title>
    <url>%2F2016%2F02%2F24%2F%E5%85%B3%E4%BA%8E%E8%83%8C%E5%8D%95%E8%AF%8D%E8%BD%AF%E4%BB%B6%2C%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E6%83%8A%E4%BA%BA%E7%9C%9F%E7%9B%B8%2F</url>
    <content type="text"><![CDATA[0x00 前言 你想知道背单词软件有大概多少人注册第一天都没有背完嘛？ 你想知道背单词软件这么火，这么多人在使用，真的有多少人真的在背诵嘛？ 别急，Python 程序员用数据给你说话。 文章目录如下： 0x00 前言 0x01 问题的提出和任务的分解 0x02 任务一，信息爬取 ox03 任务二，清理和存储 0x04 任务三，分析 0x05 任务四，结论 0x06 整个流程的不足和反思。 0x07 代码。 0x01 问题的提出和任务的分解前两天，就在一个雷电交加的夜晚，我躺在床上，草草的看了一篇英文文章，突然想到一个非常有意思的问题： 是不是大部分的人做事真的不能坚持呢？比如，背单词。 好，那我就看看到底有多少人是坚持不下来的？ 那么，我们的问题就变成了这样子： 有多少人是在坚持或者曾经坚持过背单词呢？（假设 100 天以上算的上是背单词的话） 有多少梦想，毁于不能坚持？ 背单词的人们学习的量，是不是符合正太分布呢？ 于是我选中了业内的标杆扇贝软件作为分析的对象。抽取其中的大约 1/30 的用户的公开数据，也就是游客用户都可以看得到的数据，进行抽样调查。 调查的具体内容如下： 打卡最高 / 成长值最高 / 学习单词数量最高 平均每个人打卡次数 / 成长值 / 学习单词数量 打卡 / 成长值 / 学习单词数量的分布（也就是已经坚持了多少天了） 那么，我的任务也就可以分解如下： 爬取数据 使用 Python2 的 Scrapy 进行爬站 清理数据 sql 语句和 pandas 运算 分析数据 pandas + seaborn + ipython book 得出结论 0x02 任务一，信息爬取，清理和存储每个用户的信息都在这里： http://www.shanbay.com/bdc/review/progress/2 使用 beautifulsoup4 进行解析即可。其他部分参考代码。 扇贝的工程师反爬虫做的还不错，主要有两点： 访问数量超标，封禁 IP 半个小时。对应的方法就是代理服务器.（代码中已经删除代理服务器，所以，如果你运行不了代码，那你应该知道怎么做了.) cookie 如果不禁用很快就无法爬取。对应的方法就是禁用 Cookie. 0x03 任务二，清理和存储对于数据库，使用 Postgresql 存储就好了。也没有什么大问题。参考代码。有问题在评论下面问。 通常情况下在存入数据库的时候需要进行数据的净化，不处理也没有什么大问题。 0x04 任务三，分析分析阶段，使用 IPython notebook. 通常情况下，我们使用的是 Anaconda 里面的 Python3 版本 . 可以到这里下载，注意，mac 和 ubuntu 下载的是命令行版本。 https://www.continuum.io/downloads 安装完毕以后，重启终端。环境变量生效。 12#直接安装 seabornpip install seaborn 切换到指定目录然后敲入命令 ipython notebook 打开浏览器进行编辑。 至于怎么使用，请看代码。 0x05 任务三，结论在这里省去部分的分析过程直接贴出结论。 总共抓取 1111111 张网页，成功获取 610888 个用户的信息。 于是得出结论如下： 扇贝之最： 最高打卡天数：chainyu 1830 天 最高成长值：Lerystal 成长值 28767 最高单词数量：chenmaoboss 单词量 38313 平均到每一个人身上 平均每人打卡天数：14.18, 而超过成长平均值的人数为 71342, 占总抽样人数的，额，11.69% 平均成长值：121.79, 而超过平均成长的人数为 13351, 占总抽样人数的，额，11.42% 平均学习单词数量：78.92, 而背超过平均单词的人数为 13351, 占总抽样人数的，额，2.19%（注意，真的是 2% 左右） 那么，我们来看看打卡，成长值，单词数量的，分布吧. 第一个，所有人的打卡数量直方图。 简直惨不忍睹。 第二个，非零用户的打卡数量直方图。 这真是一段悲伤的故事。由于坚持不了几天的用户实在是太多，简直就是反比例函数嘛，导致图像严重畸形。那么，我们只能分段了看用户打卡天数在 0~20,20~100,100~500,500~2000 范围的分布图了。 分别如下： 其他成长值的各种分布也是如此，在此就不贴出来了。 正如你所看到的，我再来总结一下， 在抽样中， 英语梦死在前 0 天的有 416351 人，占总比 68.15%; 英语梦死在前 1 天的有 466761 人，占总比 76.40%; 英语梦死在前 2 天的有 484535 人，占总比 79.31%; 英语梦死在前 5 天的有 510230 人，占总比 83.52%; 英语梦死在前 10 天的有 531219 人，占总比 86.95%; 英语梦死在前 20 天的有 551557 人，占总比 90.28%; 英语梦死在前 50 天的有 575975 人，占总比的 94.28%; 英语梦死在前 100 天的有 590700 人，占总比 96.69%; 英语梦死在前 200 天的有 575975 人，占总比 98.36%; 英语梦死在前 263 天的有 600875 人，占总比 98.81%; 你可以大致感受到残酷的现实，几乎没有多少人可以坚持到 200 天以后。 但是，你还需要注意到的事情是： 抽样的来源是 ID 为 1~1111111 之间的 60W 成员 众所周知的事情是： 早期的用户往往质量相对会高一些。而且，注册的 ID 越大，证明注册时间距离现在越近。获得 200 天的几率也就低了不少。 那么，这样的话，英语梦死在 200 天之前的人数比例还会大上不少。 回到文章开始： 问：背单词软件有大概多少人注册第一天都没有背完嘛？答：68.15% 问：有多少人是在坚持或者曾经坚持过背单词呢？（假设 100 天以上算的上是背单词的话）答：保守估计，不足 3.4% 问：有多少梦想，毁于不能坚持？答：不妨干了这碗鸡汤，歌唱青春一去不复返。 问：背单词的人们学习的量，是不是符合正太分布呢？答：不是，简直就是反比例函数。 抛出一个结论： 以绝大部分人努力之低，根本就用不着拼天赋。 赠给你我，共勉。 0x06 整个流程的不足和反思。扇贝的工程师反爬虫做的还不错，主要有两点： 访问数量超标，封禁 IP 半个小时。对应的方法就是代理服务器。 cookie 如果不禁用很快就无法爬取。对应的方法就是禁用 Cookie. 爬虫框架使用 Scrapy, 这样就免去了大量的繁琐的线程调度问题，直接写获取信息的逻辑代码，以及存储信息的逻辑代码就好了。 在编写爬虫的过程中，有一些经验： 在爬虫开启以后，由于我暴力的关闭，导致还是有不少的 item 没有完成请求处理和存储。 我在处理异常的时候忘了应当把失败的 item 存放放在文件中，方便我第二次补充，这样的话就不会丢失一部分的用户信息了。 代理服务器需要自己写脚本进行测试，否则你可能有很多很多的请求都会超时（毕竟很多代理服务器还是很不靠谱的）. 我的分析数据能力并不是很强，仅仅是从 CS109 里面偷学了一点点，然后使用 Seaborn 画图，但是这整个过程中还是觉得自己分析不过来，不是写不出代码，而是不清楚使用什么样的数据模型进行分析更好。 0x07 代码代码放在了 Github 上面，咳咳，注意，没有把代理服务器放进去。如果你跑一下会发现只能半小时抓取 300+ 页面，这不是我的问题，是你没有把代理服务器填好。代码比较粗糙，还请轻拍。 代码的地址为： https://github.com/twocucao/DataScience/ 仓库里包含了抓取网站的代码和分析数据的 IPython Notebook, 自己阅读吧。 如果喜欢本文，就点个喜欢吧。]]></content>
      <categories>
        <category>我的开源项目</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 程序员如何优雅的看斗鱼 TV]]></title>
    <url>%2F2016%2F02%2F15%2FPython%E6%96%97%E9%B1%BC%E5%BC%B9%E5%B9%95%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[0x00 前言过年的一段时间抽空研究写了一些关于斗鱼 TV 的弹幕的获取。分别使用 Python 和 Ruby 写了弹幕获取的客户端。 文章地址为： Python 版本：http://www.jianshu.com/p/2e0d14978ae9 Ruby 版本附加原理讲解：http://www.jianshu.com/p/ef0225b6bb0e 文章末尾写到了我有一个痛点 –rtmp 直播视频无法获取，后来在网友 往事侞湮] 的友善提醒下，终于 Get 到了。 于是，稍微完善了一下，我就发布了第一个命令行版本的斗鱼 TV 浏览弹幕小助手。 如果你是 MacOSX 的用户，你只需要 123456brew install mplayerpip3 install danmu.fm# danmu.fm -q 1 -v 1 [url]# 比如danmu.fm -q 2 -v 1 http://www.douyutv.com/16789# -q 参数 0 为不调用 mplayer 进行播放，1 为使用 mplayer 进行普清视频的播放，2 为使用 mplayer 进行高清视频的播放，3 为使用 mplayer 进行超清视频的播放 如果你是 Ubuntu 用户，你只需要 123456sudo apt-get install mplayerpip3 install danmu.fm# danmu.fm -v 1 [url]# 比如danmu.fm -v 1 -q http://www.douyutv.com/16789#ubuntu 上 mplayer 播放器可以正常播放 如果你是 Win 用户， 唉，windows 上面糟糕的编码问题。那单纯来看字幕的话也不是不可以的。只是我暂时没有对 Win 进行兼容。还是换 Linux 吧。 0x01 演示效果 0xEE 代码地址https://github.com/twocucao/danmu.fm 如果喜欢，请点个喜欢或者 star 一下 ChangeLog: Update 20160609 : 更新 Python 客户端，修复由于斗鱼网页版面修改带来的小问题，直接开启海量弹幕模式（请大家不要问我为什么端午节这一天为什么闲着没事更新代码，这个真的和情人节是同一个原因）. Update 20160220 : 更新 Python 客户端，增加直播视频的 Live 获取，以及 Mac 平台下面的 Mplayer 的视频播放。代码均放在 Github 上面。GitHub - twocucao/danmu.fm: douyutv danmu 斗鱼 TV 弹幕助手** Update 20160214 : 更新 Python 和 Ruby 客户端（请大家不要问我为什么情人节这一天为什么闲着没事更新代码）**]]></content>
      <categories>
        <category>我的开源项目</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Wireshark</tag>
        <tag>逆向工程</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斗鱼 TV 弹幕助手]]></title>
    <url>%2F2016%2F02%2F04%2F%E6%96%97%E9%B1%BCTV%E5%BC%B9%E5%B9%95%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[斗鱼弹幕助手0. 前言前几天闲着无聊，看到舍友们都在看斗鱼 TV，虽然我对那些网络游戏东西都不是非常感兴趣。只是我突然间想到，如果我可以获取上面的弹幕内容。不就有点意思了么？ 1. 分析阶段如果我想要抓取网页上面的东西，无非就是两种方法 使用浏览器，手工（自己点击）或者非手工（使用 JS 脚本），存取我想要的东西。 编写 HTTP 客户端（斗鱼无 HTTPS 通讯） 第一种方法是万能的，但显然是不行的， 原因如下： 手动保存实在是不可行，程序员不为也。 浏览器与本地交互有限，换而言之，也就是即使我抓取了对应的弹幕，我也没有办法解决持久化的问题。 假设你选择的是 Chrome 或者 firefox 浏览器，也不是不能实现持久化，但这需要写扩展，Chrome 扩展没有写过，也不是很感兴趣。 第二种方法显然是一个正常的程序员的做法。 写一个客户端，也就是写一个小爬虫，使用的场景： 用户在终端执行命令 12 回想一下抓取网站的方法 四步走：请求网页（原始数据） - 提取数据（提纯数据） - 保存数据 - 分析数据 很显然，只要解决了请求网页，其他的也就无非解析和 SQL 语句什么的。 1.1. 斗鱼 TV 弹幕抓取的思路确定如果是像我上面说的那么简单，也就不必再写一篇文章。毕竟，网页小爬虫没有什么技术含量。分布式爬虫才有。 通常情况下的网页小爬虫无非要解决如下问题： 请求，如果对方有一定策略的反爬虫，那需要反反爬虫。比如， header 带上 host，带上 refer，带上其他 需要验证，那就申请用户名和密码，然后登陆 如果在登录时期有防跨站机制，那就先获取一次登录页面，然后解析出 token，带上对应的 token 然后登陆。 在程序中加入 Log，并且存到本地。防止出现各种各样的反爬虫机制 ban 掉了程序，从而方便进行下一步防反爬虫对策。 并且，由于请求响应机制的存在，通常情况下，每一个请求对应一个响应，如果出错了，要么超时，要么有状态码，所以 web 爬虫实在也相对而言比较容易些。 那么，斗鱼 TV 的站点是不是这样子的容易爬取呢？ 你猜到了，答案是“不是”。 由于弹幕具有实时性，就决定了斗鱼 TV 的弹幕无法通过保存完整指定时间端弹幕的 XML（比如 BILIBILI 的一个视频弹幕是存在一段 xml 中的）或者 Json 数据来显示弹幕。要不然的话，那主播操作很出色的时候，观众的弹幕岂不是无法实时显示了么？ 那么，肯定就是 WebSocket 了，于是，我一如既往的打开 F12，查看网络流量。 正如你想到的那样，没有任何的弹幕流量来往。一个 WebSocket 的消息都没有。 那么，消息肯定是有的，但是消息并不是通过 HTTP 协议或者 WebSocket 协议传输的，那么问题会出在哪呢？ 分析前端的代码，找出获取弹幕的 JS 代码，苦于代码太多，找了很久没有找到。那也就是执行逻辑可能在 flash 里面。 于是祭出大杀器 WireShark，抓一下流量。终于看到弹幕的样子了。 是这样的。 原来使用的是 Flash 的 Socket 功能。 多分析几组数据，但还是对发送消息内容缺乏把握，特别是在用户认证，用户接收弹幕这一块。在搜索引擎上搜索了一阵，发现知乎上有个帖子，读完终于解了我的疑惑。 省略若干消息分析过程。 总结后得出斗鱼 TV 网站的服务器分布。 1.2. 房间信息和弹幕认证服务器获取首先我们拿随便一个主播房间来说，比如，mkk Ta 的房间链接分为两种 http://www.douyutv.com/mkk http://www.douyutv.com/『房间 id] 对这个主播房间页面请求，正常，所有的有用信息都不是放在 HTML 中渲染出来，而是放在 HTML 中内置的 JS 脚本中，这是为了减少服务器渲染 HTML 的压力？可是渲染放在 JS 里面不也一样需要渲染？（不明白）总之，就是程序先加载没有具体数据填充页面，然后 JS 更新数据。 内置的两段 JS 脚本，JS 脚本中有两个变量，该变量很容易转换成 JSON 数据，也就是两段 JSON 数据，一个是关于主播的个人信息，另一个是关于弹幕认证服务器的列表（该列表中的任意一个服务器均可以认证，但每一次请求主播页面得到的认证服务器列表都不一样） 通过这步，我们就拿到了主播的信息以及弹幕服务器的认证地址，端口。 1.3. 发送 Socket 消息的流程简介我们通过抓包，分析那一大坨数据包，可以确定以下通过以下的流程便可以获取弹幕消息。（分析过程比较繁琐） 首先建立两个 Socket。一个用于认证 (@danmu_auth_socket)，另一个用户获取弹幕 (@danmu_client)。 步骤 1: @danmu_auth_socket 发送消息登陆，获取消息 1 解析出匿名用户的用户名，再获取消息 2 解析出 gid 步骤 2: @danmu_auth_socket 发送 qrl 消息，获取两个没有什么用的消息 步骤 3: @danmu_auth_socket 发送 keeplive 消息 步骤 4: @danmu_socket 发送伪登陆消息（所有匿名用户都一样只需要输入步骤一中用户名就行了，因为认证已经在上面做过了） 步骤 5: @danmu_socket 发送 join_group 消息需要步骤一中国的 gid 步骤 6: @danmu_socket 不断的 recv 消息就可以获取弹幕消息了 后面会详细解释 2.1. 消息 Socket 消息格式以及发送一条消息既然是发消息，那么每条消息总是有些格式的。 斗鱼的消息格式大致如下： 并遵循下面的格式： 通信协议长度，后四个部分的长度，四个字节 第二部分与第一部分一样 请求代码，发送给斗鱼的话，内容为 0xb1,0x02, 斗鱼返回的代码为 0xb2,0x02 发送内容 末尾字节 12345678910111213141516171819202122# -*- encoding : utf-8 -*-class Message # 向斗鱼发送的消息 # 1. 通信协议长度，后四个部分的长度，四个字节 # 2. 第二部分与第一部分一样 # 3. 请求代码，发送给斗鱼的话，内容为 0xb1,0x02, 斗鱼返回的代码为 0xb2,0x02 # 4. 发送内容 # 5. 末尾字节 #pack('c*') 是字节数组转字符串的一种诡异的转化方式 def initialize(content) @length = [content.size + 9,0x00,0x00,0x00].pack('c*') @code = @length.dup @magic = [0xb1,0x02,0x00,0x00].pack('c*') @content = content @end = [0x00].pack('c*') end def to_s @length + @code + @magic + @content + @end endend 经过封装，我们仅仅关注那些可见的字符串，也就是 Content 部分就可以了。content 部分，也就是发送消息的内容，在文章后面将会详解。 开启两个 Socket，一个用户认证，另一个用于弹幕的获取。 用于用户弹幕认证的，是 2.1 中所说的认证服务器列表中任意一个。挑选出来一组 ip 和端口 @danmu_auth_socket = TCPSocket.new @auth_dst_ip,@auth_dst_port 用户获取弹幕的只要为 1234danmu.douyutv.com:8601danmu.douyutv.com:8602danmu.douyutv.com:12601danmu.douyutv.com:12602 四组域名：端口均可以作为如下的 DANMU_SERVER 和 PORT @danmu_socket = TCPSocket.new DANMU_SERVER,DANMU_PORT 发送一条消息只需如此 123data = "type@=loginreq/username@="+@username+"/password@=1234567890123456/roomid@=" + @room_id.to_s + "/"all_data = message(data)@danmu_socket.write all_data 接下来，我们需处理上面说的六个步骤 2.2. 发送消息详细流程之步骤一发送消息内容为： type@=loginreq/username@=/ct@=0/password@=/roomid@=156277/devid@=DF9E4515E0EE766B39F8D8A2E928BB7C/rt@=1453795822/vk@=4fc6e613fc650a058757331ed6c8a619/ver@=20150929/ 我们需要注意的内容如下： 123456789type 表示消息的类型登陆消息为 loginrequsername 不需要，请求登陆以后系统会自动的返回对应的游客账号。ct 不清楚什么意思，默认为 0 并无影响password 不需要roomid 房间的 iddevid 为设备标识，无所谓，所以我们使用随机的 UUID 生成rt 应该是 runtime 吧，时间戳vk 为时间戳 +"7oE9nPEG9xXV69phU31FYCLUagKeYtsF"+devid 的字符串拼接结果的 MD5 值（这个是参考了一篇文章，关于这一处我也不大明白怎么探究出来的）ver 默认 通过这一步，我们可以获取两条消息，并从消息中使用正则表达式获取对应的用户名以及 gid 1234str = @danmu_auth_socket.recv(4000)@username= str[/\/username@=(.+)\/nickname/,1]str = @danmu_auth_socket.recv(4000)@gid = str[/\/gid@=(\d+)\//,1] 2.3. 发送消息详细流程之步骤二发送的消息内容为 “type@=qrl/rid@=” + @room_id.to_s + “/“ 无需多说，类型为 qrl，rid 为 roomid，直接发送这条消息就好。返回的两条消息也没有什么价值。 123send_message(:qrl,@danmu_auth_socket,"")str = @danmu_auth_socket.recv(4000)str = @danmu_auth_socket.recv(4000) 2.4. 发送消息详细流程之步骤三发送的消息内容为 “type@=keeplive/tick@=” + timestamp + “/vbw@=0/k@=19beba41da8ac2b4c7895a66cab81e23/“ 直接发送。无太大意义。 12send_message(:keeplive,@danmu_auth_socket,"")str = @danmu_auth_socket.recv(4000) 前三步，也就是 2.2-2.3-2.4 三步骤，也就是使用 @danmu_auth_socket 完成获取 username 和 gid 的重要步骤。获取这两个字段以后，也就完成了它存在的使命。 接下来的就是 @danmu_socket 获取弹幕的时候了！ 2.5. 发送消息详细流程之步骤四消息内容为：”type@=loginreq/username@=”+@username+”/password@=1234567890123456/roomid@=” + @room_id.to_s + “/“ 和上面 2.2 中略有不同。但是，需要注意的是123username 为 2.2 中所得到的 usernamepassword 的变化少了几个字段 1234data = "type@=loginreq/username@="+@username+"/password@=1234567890123456/roomid@=" + @room_id.to_s + "/"all_data = message(data)@danmu_socket.write all_datastr = @danmu_socket.recv(4000) 2.6. 发送消息详细流程之步骤五接下来就是完成认证的最后一步了，join_group 的消息内容为 “type@=joingroup/rid@=” + @room_id.to_s + “/gid@=”+@gid+”/“ gid 为 2.2 中所得到的 gid。 1send_message(:join_group,@danmu_socket,"") 2.7. 发送消息详细流程之步骤六获取弹幕，并且打印出来。 123danmu_data = @danmu_socket.recv(4000)type = danmu_data[danmu_data.index("type@=")..-3]puts type.gsub('sui','').gsub('@S','/').gsub('@A=',':').gsub('@=',':').split('/') 后三步，则是 @danmu_socket 获取弹幕的步骤。 于是，通过这些步骤，就可以完成了简单的 douutv 的和新代码，接下来的步骤就是完善，重构这些代码了。 总结1. 痛点一，头疼的过度封装我们知道，在编写 Ruby 的 Socket Server 和 Client 的时候，非常方便，特别是传输的 socket 消息内容为字符串的时候。 但是，当处理的消息内容不可打印的字符串的时候，必须要转化成字节数组的时候，让我着实混乱了一阵，直到使用了 pack(”c*“) 和 unpack(“c*“), 并且通过 wireshark 抓包验证了自己的发送的数据包和接受的数据包才安心使用 pack 与 unpack。 2. 痛点二，至今还没有解决 rtmp 地址的获取找了很久没有办法解决 rtmp 地址的自动获取： 路径如下 http://www.douyutv.com/swf_api/room/301712?cdn=&amp;nofan=yes&amp;_t=24243097&amp;sign=3b2efb130cb25a85e621f477f95c7341 这一处的请求不是 XHR，也就是不是 JS 脚本通过 XMLHttpRequest 异步加载；那么，八成是 flash 通过 http 协议获取的。我估计八成执行逻辑应该是在 flash 之中。 代码核心代码的地址为： 重构版本即将出炉。 还请轻拍。 参考链接PS: 如果有问题可以在下方留言或者发送 email 到 twocucao@gmail.com 给我。 ChangeLog2016-02-09 09:01:00 - 重写部分内容。增加 Ruby Socket 部分。]]></content>
      <categories>
        <category>我的开源项目</category>
      </categories>
      <tags>
        <tag>Wireshark</tag>
        <tag>逆向工程</tag>
        <tag>爬虫</tag>
        <tag>Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oh My Mac!]]></title>
    <url>%2F2016%2F02%2F01%2FPC2MAC%2F</url>
    <content type="text"><![CDATA[前言我会想念 Windows 上面的一切，但我选择了 Mac。 从某种程度上讲，我并不是讨厌 Windows。尽管我是一个伪装成、*nix 程序员的技术菜鸟。 我还记得高一时候家里给我买的第一台二手电脑，那是一台烂到令人发指的破电脑，你可能见过那种俗称大屁股的电脑，512M 内存，64M 显存。我就在那一台机器上打了仙剑三通关和仙剑四的青鸾峰到寿阳城阶段，千佛寺时候家里电脑实在是烂到令人发指，于是电脑就报废了。后来，家里面换了一台电脑，128 显存，内存 2g 的联想杨天电脑。我就在这一台机器上打了仙剑四的寿阳城之后的剧情。 正如你可以看出来的，我并不讨厌 Windows，甚至某种程度上，我非常喜欢 Windows，正是盗版时代风靡全球的 Windows 才给了我电脑的启蒙。 喜欢 Windows 的部分原因也是因为穷，只能用盗版（我当年以为是免费，后来才知道这叫做盗版）。就像当我知道仙剑四团队因为我这样只知道免费的盗版人群解散了以后，心痛不已。自此以后，如果经济上可以，我一定会买正版。倒也不是为了买给别人看，这只是代表我对软件开发者的最崇高的敬意。也是弥补我因为无知犯下的错误的愧疚感。 Windows 对我来说就是启蒙老师。 但 Windows 的种种环境配置，日常使用和我inux 的技术栈完全不兼容了。从 XP 到 Vista 再到 7 再到 8 再到 10，这种情况依旧没有发生什么本质的变化。这样的我不得不选择模拟、nix 工具，虚拟机或者双系统。但，模拟的nix 实在太难用，虚拟机里面的系统用起来根本操作根本就不丝滑，双系统一会切换到 Win，一会切换到 Ubuntu 这种情况简直让我非常的抓狂。nux 的环境又不能不要，可 Win 的桌面软件实在是难以割舍。 于是，一个切换到 OSX 的想法在我的脑海中不断的浮现。但是正如你所知道的一个很现实的情况： 没钱，也不愿意给父母添麻烦。 但 幽灵，一个想买 MacBook Pro 的想法，像幽灵一样，在脑海中不断的浮现。 直到前几天才攒够足够的钱买了一台二手 mbp 改装一下 SSD。作为丐帮 Mac 第一新人，进入了 MAC 的世界里。 对，我受够了 Windows 里面各种奇葩的问题，也受够了 Ubuntu 等 Linux 系统的糟糕的桌面体验。 对于一个不研究。net 的人来说，Windows 完成了他伟大的启蒙任务。也是时候与你告别了。 只是人总要和以前的一些人和事情不断的做告别，不是吗？ 以前看过很多比较浅显的讲解，正是那些讲解，让我逐渐入了门，然后我就不得不与他们做告别。 他们完成了他们伟大的任务，他们的伟大之处永远都在为新手敞开大门，所以，我们成长之后不应该去鄙视那些给你带来进步的事物，而是礼貌的挥挥手向他们告别。 开始迁移那么，依照我丰富的 Windows 使用经验来说，我需要解决的问题就是把原有的 Windows 和 Ubuntu 上的东西搬运到我的新电脑上。 使用电脑 = 软件 + 操作学会使用电脑 = 描述问题 + 搜索引擎 + 笔记 0. 自带的软件各种 Hack其实，自带的软件往往有不可忽略的强大之处。比如，Windows 世界里面的 Win+R 按键。 目前来说，发现苹果上面自带软件不错的地方如下： 自带软件，苹果的一些应用，itunes，iphoto，isg 等等。使用这些软件简直就是易如反掌。没什么好说，不错的软件就是 spotlight 了，这个软件非常的强大。可以说是进阶版本的 Windows 上面的搜索 +Win+R。但是然并卵，我们用 alfred2 这个神一样的东西，逐渐就把这基本的软件废弃了。我使用的也就是自带的 finder。 Mac 上的软件的快捷键可以通过一个叫做 cheatsheet 的的软件进行查看，安装好这个软件，打开一个软件，然后长按 cmd 按键。 0.0 系统设置调整从 Win 过来人在一些细节操作上与 Mac 的设计有一些不同。这些可以在系统里面进行设置。 比如， 鼠标滚轮调整 preference - mouse - 取消勾选：scroll direction ：natural 0.1 文件的操作windows 里面管理文件的东西叫做 explorer.mac 里面叫做 finder.二者，图形操作上大致相同。但是结合快捷键的操作就不同了。 12345678910111213141516171819202122232425262728293031323334353637383940# cmd 为 command 按键，通常情况下为所有桌面程序通用性的快捷键。# ctrl ，通常情况下是针对程序的功能进行加强，并且此功能往往是非 cmd 类（窗口操作，选择，复制粘贴等等）操作。# shift 按键通常用于加强操作。一般会让操作更进一步 or 相反操作。cmd+tab =~ alt+tab 程序之间的切换cmd+` 应用内窗口切换cmd+h 窗口 hidecmd+m 窗口 minimizecmd+n 新建窗口cmd+o 打开cmd+s 保存cmd+shift+s 另存为cmd+p 打印 printcmd+w 关闭cmd+q quitcmd+a select allcmd+i show infocmd+n create a new foldercmd+f searchcmd+c copycmd+v pastecmd+delete 删除选中文件cmd+shift+delete 清空回收站cmd+= 放大cmd+- 缩小cmd+t 新建选项卡cmd+r 刷新cmd+shift+3 截取整个屏幕cmd+shift+4 截取选择区域cmd+shift+4+SPACE 截取选择窗口cmd+ 鼠标点击 -&gt; 选中不连续文件control+ 鼠标点击 -&gt; 相当于 win 中右键点击fn+left homefn+right endfn+up pageupfn+down pagedown 0.2 Trackpad到 trackpad 中设置对应鼠标手势 点击 单指点击 - 单击单指滑动 - 滑动鼠标光标双指点击 - 相当于 Windows 的鼠标右键三指点击 - 划词查找 滑动与缩放 双指上下滑动 - 滚动双指缩放 - 与 Android 上图片缩放一致双指双击 - 只能缩放双指旋转 - 旋转双指左右滑动 - 应用内切换网页双指头从右往左三指头左右滑动 - 全屏幕 App 切换大拇指和食中无名缩放 - launchpad 1. 日常软件1.1 一些满足日常生活的软件Alfred - 让你的 spotlight 更上一层楼，程序打开 / 切换、文件搜索、互联网搜索、与其他软件交互的利器。weixin，qq - 这是必须的。CleanMyMac - 系统清理软件。欧陆词典 - 国产词典领域最牛。别说有道词典了好伐。calibre - 电子书必备，下载免费经济学人。Wiznote - 为知笔记，实在是国产良心之作。可惜，Mac 上面的功能比较少。PS，Sketch - P 图必备吧？Safari，Chrome+ 大量的插件 - 不多说，Chrome 简直就是我的第二操作系统。那犀利的插件，Get 到痛点的功能，用起来纵享丝滑一般的流畅，都深深的迷住了我。除了吃内存，其他都好。PDF reader，ibook - 文档查看必备。MS OFFICE，Work 套件：包括 pages, numbers, keynote. 其实 Windows 的生产力之说大抵也就是 Office 系列 VS 系列了，虽然我不喜欢 Office，但是不得不说，Excel 做的真的是世界级的牛。其他，PPT，Word 嘛？反正我不喜欢，奈何别人都用这个。我只好在电脑上安装一份了。虚拟机：parallels desktop迅雷 本来挺简洁的，最近出来一个商城。哦，看来距离我卸载他的日期已经不多了。管理 Android 手机：airdroid 用于管理我的坚果手机。写作与编码，Sublime+ 插件，MacVim+ 插件邮件：airmail 好简洁，好强大，和 Gmail 简直就是无缝对接嘛。思维导图：xmind - 一直在用。依赖 Java 环境。解压缩：BetterZip 7z 解压缩 我比较喜欢 7z你懂的：shadowsocks 不多说了，看小粉红出墙征战四方寸草不生的优良工具。其他系统自带软件 2. 开发环境ide 类：xcode 和 xcode-cli 工具（用于安装 homebrew 和 homebrew cask） 2.1 homebrew少什么？homebrew 一下就好。 如果你想更深一步，那就使用 homebrew cask 2.2 sublime textsublime text 作为我很长一段时间的主力编辑器，优点如下： 快，打开文件比较快。当然，比 notepad++ 要慢 多光标编辑。 强大的插件库 对，加上第三点，sublime 成为了编辑器世界的女神级别人物。哎，想起我对别人大力推荐这个编辑器别人还是一如既往的使用 npp，实在是糟心。 插件库里面的主题我比较喜欢 sodarized喜欢的功能性插件为 pretty 系插件，比如，对 json,html,js.css 进行一键格式化。哦，简直帅爆了。当然其他能留下深刻印象的就是 lint 系列插件和部分对编辑器的侧边栏，右键菜单，以及对应语言的库进行补充的插件了。 现在继续使用这一款软件的原因也是如此。 2.3 macvim + spf13-vim我对计算机上古时代的前辈们总是有很崇高的敬意。这在我是用来了 Vim 以后才逐渐有这种想法。 对，Vim 真的很神奇。但是 Vim 是我见过的为数不多的使用难度超越了我认识到的所有软件的软件。之前排名在 top 1 的应该是 Windows 上面的 Totalcmd。 出于 Vim 及其陡峭的学习路径，我认为 Vim 本身适合可以盲打，并且是键盘流爱好者的情况下再学习。否则，学习效率会极其的低下。为什么我知道？一把辛酸泪。 在这个时代，最宝贵的就是有用的信息，对，我遇到了 SPF13Vim 这个已经配置好的 VIm 版本。并且从中学习到了一些奇技淫巧。 现在基本上是离不开 Vim 了。甚至面对没有 Vim 类型操作的编辑器或者浏览器的时候，简直无法忍受。 尽管现在我还是一个 Vim 菜鸟。有机会我会整理好自己的 Vim 配置，放在 github 上面。 Vim 使用一定要改按键！！！ CapsLock 按键没有什么用，改成 Escape 按键或者改成 Ctrl 按键，推荐改成 Ctrl，因为 ESC 除了 Vim 里面使用的比较少，但是使用 Ctrl 的场景就比较多了（Vim 中 ESC 可以使用 Ctrl+\『代替，而且不需要使用第三方工具），这样让小拇指很舒服。 2.4 Chrome由于一些众所周知，或者你不知道我也懒得告诉你的原因。我们比较信赖国外的好的产品。 Chrome 就是这样的产品。 我以前的文章也写过，只是由于硬盘发生了一次数据丢失事件，关于 chrome 的笔记都已经丢掉了，我就再也没有写过 chrome 的那些牛的要死的功能。 但是我还是要推荐一些我喜欢的插件。 adblock - 去广告标准配置了吧autoPatchWork - 自动拼接下一页到本页capture，explain and send screenshots - 截图cssviewer - 查看 css 的工具Dream Afar New Tab - 美化新标签页面必备json editor - 格式化 json 专用isometric contribution - 其实也就是美化 github 上面提交的工具One Click extensions Manager - 由于 chrome 的标签数量惊人，所以有的时候为了提升速度还是禁用掉一些比较好。Pocket - read it later PS：虽然我自从用了为知笔记以后就不用 pocket 了。但 pocket 真的值得一用Vimium - 快速浏览网页的神器Web Timer - 记录花在每个站点的时间。Wiznote WebCliper - Pocket 的替代品Octotree - 如果你玩 github 没装这个插件，是时候使用这个插件然后感叹时光一去永不回了。SwitchyOMega - 你懂得 2.5 Lang 环境Lang 环境，顾名思义，就是各种语言的环境。 我们程序员需要懂和计算机交流的本事，所以，我们需要学很多的语言。但，问题也就因此而来。选择什么样的软件来管理不同的软件环境呢？如果是 Ruby 环境，我们又怎么配置 Ruby 不同版本呢？ 计算机世界的铁律： 只要有树叶飞舞的地方，火就会燃烧 额，等等，说串场了 只要有痛点，就有解决痛点的工具。 Java 这个需要切换版本的要求比较低。无所谓。何况，已经很久没有写 Java 了。 我一般情况下使用的是 Java8rvm ruby 社区的人都喜欢使用最新最潮的技术，所以，切换版本这种事情必须要做，rbenv 和 rvm 都是非常有用 ruby 版本管理器。我喜欢 rvm。nvm nodejs 比较火，虽然我对 nodejs 并不是很感冒，但是我不得不承认，有些人写出来的 nodejs 工具实在是方便的要死。比如，gitbook-cli，hexo-cli，二者都是记录自己的笔记的好东西。Lang 对于 Python，我选择了 anaconda，anaconda 为特殊的 Python 分发包。里面的库比较全面，不需要我特地为一个包找教程来安装。 2.6 终端首先，我们对终端的认识可能还停留在 unix 机器或者 ubuntu 桌面进不了的时代。Mac 上面 iterm2 作为一个终端模拟器，则是做到了同类中的最强者。好用到想让人哭。 shell 一般情况下使用的 bash，但是那是对运维人员来说的，我们开发者使用的是 zsh。配置 zsh 的文件使用是 OhMyZsh. 好用到想哭。 结束语从我的角度来看 Win 和 Mac 的好于不好 Win 的好在于系统优良的兼容性，以及入门就可以上手的强大的操作性。由于出自于什么都爱做的微软公司，从整体来说，VS，.NET, 游戏性，兼容性，性能，新手上手速度来说，都是遥遥领先 Mac 的。也可惜了，微软的战线实在是拉的太长，什么都想做，什么都想垄断。于是，与之服务密切相关的公司也就受到了 MS 的牵制。这对大公司来说，几乎是不能够忍受的行为。于是硅谷的公司使用微软服务的也就接近 5%（可能有误差）。并且，糟糕的终端环境（DOS）和无法与、nux 世界的脚本友好相处使得系统的可定制性和进阶操作性大大降低。虽然有 Everything，TotalCMD，AHK 这种神级辅助工具可以满足定制要求。但由于过高的学习成本（AHK 语言真的很混乱啊，TC 实在是太难用了）但也无法满足、nux 程序员的要求。这就是我不得不切换到 Mac 上面的理由。 Mac 的好在于终端和美观的图形的结合。也就是开发基于、*nux 应用的非常方便以及非常容易与脚本文件配合出强大的组合技能，反观 Win 上，则这种组合技能则在环境配置上和操作流畅度上差了很多。缺点也是相当容易看出来的 – 娱乐项目实在是少的要死。再者说，我们也不需要娱乐性那么强的软件，不是么？ 哦，终于集齐了 PC，Linux，Mac 的配置文章 关于 Ubuntu 我的回答 关于 Win10 我的回答 就酱紫。 更新2016-02-03 : 更新 Trackpad 部分，修改部分文字2016-02-07 : 重写快捷键部分，将快捷键按照程序划分。2017-04-01 : 重写碎碎念部分。2017-05-01 : 已经更换最新款 Macbook Pro, 算是实现了一个小目标吧。]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>macOS</tag>
        <tag>开发环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015-2019 年书单]]></title>
    <url>%2F2015%2F12%2F31%2F%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[前言记下一些看过的和没有看过的书籍。 标记如下： [o] 看过，并且留有读书笔记 [x] 没看过，或者准备再看一次 [-] 正在看 技术类其实程序员的编程类知识的获取大多来源于官网的 api docment 以及 guide, 但也并不完全如此。 有的官网的 tutorial 写的不够入门，guide 写的缺乏案例，api document 写的相当及简略。 很多时候，还是需要去阅读源码的。 但下面的一些书籍，或多或少让我觉得应该和官网结合起来看。 Web 与爬虫 [x] 鸟哥的私房菜 两本 [x] Python Cookbook [x] Python 算法教程 [x] Python 可视化编程 [x] Python Web 开发实战 [x] Python For Data Analysis [x] Flask Web 开发 [x] MySQL 技术内幕 : SQL 编程 [x] MySQL 技术内幕 : InnoDB 技术内幕 [x] 深入浅出 MySQL [x] SQL 反模式 [x] Linux 集群和自动化运维 [x] Practical Vim [x] Javascript 语言精髓与编程实践 [x] Javascript 高级程序设计 [x] Javascript 设计模式与开发实践 [x] Javascript 设计模式 [x] 高性能 Javascript 基本功 [x] 深入理解计算机系统 [x] 计算机网络 [x] 设计模式 [x] 重构 [x] 算法（第四版） 科技与人文 [x] MacTalk 人生元编程 非技术类未分类 [x] 异类 [x] 眨眼之间 [x] 引爆点 [x] 逆转 [x] 大开眼界 励志鸡汤 [x] 技巧：如何用一年的时间获得十年的经验 思考与写作 [x] 学会独立思考 [x] 清醒思考的艺术 [x] 厚黑学 [x] 如何阅读一本书 我的笔记 [x] 把时间当作朋友 我的笔记 [x] 正解：从写作文到写作 [x] 小说课 [x] 精进：如何成为一个很厉害的人 [x] Beyond Feelings [x] 公正：该如何做是好？ 沟通与交流 [x] 好好说话 我的笔记 [x] 沟通的艺术（插图修订第 14 版） : 看入人里，看出人外 [x] 非暴力沟通 [x] 所谓情商高，就是会说话 [x] 演讲的力量 : 如何让公众表达变成影响力 [x] 谈话的力量 [x] 高难度谈话 [x] 沟通圣经 : 听说读写全方位沟通技巧（修订第 5 版） [x] 关键对话 : 如何高效能沟通（原书第 2 版） [x] 谈判是什么 [x] 沃顿商学院最受欢迎的谈判课 [x] 遇谁都能聊得开 : 92 个技巧让你的谈话充满魅力 [x] 沃顿商学院最受欢迎的谈判课 小说 金庸 飞雪连天射白鹿，笑书神侠倚碧鸳 [x] 飞狐外传 [x] 雪山飞狐 [x] 连城诀 [x] 天龙八部 [x] 射雕英雄传 [x] 白马啸西风 [x] 鹿鼎记 [x] 笑傲江湖 [x] 书剑恩仇录 [x] 神雕侠侣 [x] 倚天屠龙记 [x] 碧血剑 [x] 鸳鸯刀 古龙 [x] 天涯明月刀 [x] 绝代双骄 [x] 陆小凤传奇 [x] 萧十一郎 [x] 火并萧十一郎 [x] 多情剑客无情剑 [x] 小李飞刀 [x] 楚留香传奇 [x] 天涯明月刀 福尔摩斯 [x] 柯南道尔 福尔摩斯探案集 [x] BBC 神探夏洛克 历史 历史虚构类 [x] 明朝那些事儿 [x] 唐浩明 - 曾国藩 [x] 唐浩明 - 杨度 [x] 唐浩明 - 张之洞 世界史 [x] 全球通史 中国史 - 先秦 [x] 《易中天中华史·第一卷 ：祖先》 [x] 《易中天中华史·第二卷 ：国家》 [x] 《易中天中华史·第三卷 ：奠基者》 [x] 《易中天中华史·第四卷 ：青春志》 [x] 《易中天中华史·第五卷 ：从春秋到战国》 [x] 《易中天中华史·第六卷 ：百家争鸣》 中国史 - 秦汉魏晋南北朝 [x] 《易中天中华史·第七卷 ：秦并天下》 [x] 《易中天中华史·第八卷 ：汉武的帝国》 [x] 《易中天中华史·第九卷 ：两汉两罗马》 [x] 《易中天中华史·第十卷 ：三国纪》 [x] 《易中天中华史·第十一卷 ：魏晋风度》 [x] 《易中天中华史·第十二卷 ：南朝，北朝》 中国史 - 隋唐 [x] 《易中天中华史·第十三卷 ：隋唐定局》 [x] 《易中天中华史·第十四卷 ：禅宗兴起》 [x] 《易中天中华史·第十五卷 ：女皇武则天》 [x] 《易中天中华史·第十六卷 ：安史之乱》 中国史 - 宋元 [x] 《易中天中华史·第十七卷 ：大宋革新》 杂文 [x] 李敖 - 活着你就得有趣 [x] 李敖 - 活着你就得有种 [x] 李敖 - 活着你就得有料 新技能 Get [x] 和你一样，爱上手机拍照 [x] 居家超级整理术 运动健身 [x] 硬派健身 [x] 一平米健身 UPDATE: 日期 类型 详细操作 2017-02-10 创建 初始化本文 2017-02-18 更新 添加两篇读书笔记地址，细化读书书目]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>书评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『博人传』影评]]></title>
    <url>%2F2015%2F09%2F19%2F%E5%8D%9A%E4%BA%BA%E4%BC%A0%E5%BD%B1%E8%AF%84%2F</url>
    <content type="text"><![CDATA[全国最大忍者村火影忍者村倒闭了！！！ 博人传影评内无剧透。 故事发生在鸣人当上火影之后。天天忙于公务，一直没有时间陪自己的孩子。 也是在这时，世界的科技日新月异，转眼间木叶的电脑技术已经杰出到世人无法理解的地步。 宇智波童参考这查克拉的结构，结合中国功夫中的内功，外功，亦欲以究天人之际，通古今之变，终于在 SCI 上发表论文《查克拉的数学原理和中国周易的必然联系》，该论文深刻阐述了查克拉的本质，查克拉由两个东西构成，一个叫做阴，另一个叫做阳，而所有人的查克拉都可以都可以通过一定量的排序组合变成不同属性的查克拉。 宇智波童在此基础上提出了查克拉论，并建立不同属性的查克拉与两极四象五行之间的联系。他还写到，在人发出忍术的时候，首先将自己的体内的阴阳进行排序，接着转为两极能，接着再添加方向编码，变为四象能，附加自身的体质就可以转为具象的查克拉能。也就是，人们看到的查克拉，本质上就是『阴阳组合』四象』体质』。阴阳组合的长度代表一组忍术的强度，四象也就是四个方向，组合的越好，忍术就越灵活，而体质方面，像鸣人那样的风一样的男子，使用的就是风遁，像佐助那样的脾气火爆，做事比较雷人的使用的就是火遁和雷遁，像鹿丸那样聪明的，经常求别人心里阴影面积的人，使用的就是影子系术。既然查克拉是通过阴阳编码而成，那么，就可以对自己忍术的查克拉进行充分的抽样研究，从而不断优化自己忍术的编码。通过优化自己忍术的编码，就可以通过少量的查克拉调用比较强大的忍术方法。 论文发表的第二年，宇智波童发明了一种卷轴纸，这种卷轴纸张的正面在查克拉的激发下可以留下痕迹，而且不同的忍术留下的痕迹也是不相同，除非摔在地上破碎，否则几乎痕迹不会发生变化。于是宇智波童在这张纸上将自己的忍术口遁 - 一本正经胡说八道之术 通过查克拉留在了卷轴纸上。并将此种类型的纸张命名为磁卷轴。磁卷轴在背面接触查克拉的同时会释放忍术。也就是通与激发卷轴痕迹同等查克拉的时候，释放忍术。 第三年，宇智波童对卷轴进行大幅度改造，卷轴已经具有极小的体积，极大的容量了，并且造出了世界上第一个磁性忍术卷轴 3D 解释器。 就如同你看到的，只需要你把卷轴放进去。解释器就会对卷轴进行解释。可是释放多种不同类型的忍术。对这些都不需要和与激发卷轴痕迹同等查克拉，我们在解释阶段做了大量的优化，比如，为了提高执行速度，我们引入了 just-in-time 技术，由于忍术 = 『 『 『阴阳组合』四象』体质』，大幅度提升阴阳组合构成就可以无敌于战场，我们引入了压缩技术，通过大量的压缩算法，把自然能源压缩到卷轴中，基本上，使用者只需使用极少的查克拉就可以释放极大的忍术。 如同你所看到的，只需一点点，卷轴，就可以有无限的能量。 木叶忍者村开发出这种技术以后，把技术的步骤放到 NinjutsuHub 上，于是，世界忍者纷纷加入到这种磁性忍术卷轴 3D 解释器的开发商，当然，正如你所知道的，在遥远的东方某国在技术公开以后第二天就有不要脸的忍术公司发表文章说他们自主研发了一套磁性忍术卷轴 3D 技术。 磁性忍术卷轴 3D 解释器风靡全国之后，木叶忍者村的忍者渐渐也不需要会什么忍术的人了。人才日渐凋零。火影漩涡鸣人不堪重负。逃离木叶。于是，宇智波童携带着一流的技术和人才，流浪到遥远的东方。 突然的出现， 在街角的咖啡店， 也带着笑脸， 用大喇叭大声吼道： 木叶忍村，木叶忍村，全球最牛忍者村，木叶忍者村倒闭啦，王八蛋火影吃喝嫖赌欠下三点五个亿的赌债，带着他的老婆佐助逃跑了，我们没有办法，拿着忍术抵现金，原来五影才能使用的忍术，无需背口诀，无需结印，不开刀，无痛苦，第一天买装备，第二天无痛打怪，全场清仓大甩卖，统统只要三十元，统统只要三十元，统统只要三十元。 PS：鸣人和佐助终于在一起了。 ChangeLog: 2017-03-19 重修文字，祝贺鸣人君和雏田君终成眷属]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>影评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用 Windows 10]]></title>
    <url>%2F2015%2F06%2F14%2F%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E4%BD%BF%E7%94%A8Windows10%2F</url>
    <content type="text"><![CDATA[0x00. 前言刚开始 Win10 发布没有多久的时候我就写了这篇回答，放在知乎上，后来又搬运到 jianshu 上，现在搬运到自己的博客上，也算是落叶归根。 已经过了折腾的年龄，答案仅仅从提升效率方面来说，是否优雅就看诸位的审美了。 本文目录 文件夹与文件一定要分类命名好。 Win10 自带功能怎样提升效率。 2.1 快捷键 2.2 触摸板手势 2.3 Win+R 非 Windows 自带的必备的提升效率，节省时间的软件。 3.1 文档，图片，文本，以及通用文件管理器 3.2 Everything is OK 3.3 Chrome （Google 出品，必属精品） 3.4 阅读方面 calibre ， 欧路词典 3.5 笔记软件 xmind，wiznote 3.6 播放器 3.7 其他想到再补充 不写点代码优化一下工作流程，你都不好意思说自己逼格高。 4.1 autohotkey 0x01. 文件命名 文件夹与文件一定要分类命名好 贴上我的几张图来看一下我的文件夹命名： 一级文件夹如下： 二级文件夹如下： 三级或者三级以上文件夹 文件命名规范（因为涉及到后面使用 Everything，所以我们的命名尽量追求便于搜索） 举个例子，对于读书笔记 ：读书笔记、_设计模式、_20150303_v2.1.xmind 对于照片这种文件比较多的，优先命名文件夹，其次按照地址人物日期命名，比如：大明湖胖、_夏雨荷、_20150101 无需刻意追求命名，方便搜索，方便管理就好。 不妨参考下面文章： 电脑上的文件夹该如何命名（整理）才能做到很久都不用重新整理的那种？ - 文件整理 嗯这样你在搜索笔记的时候在 Everything 里面只需要键入 2015 笔记就可以查看 2015 笔记文件。 是不是很方便？ 当然桌面上尽量少放或者不放文件夹，我的桌面上仅仅有一个链接到 OneDrive 里面的 TEMP 文件夹的快捷方式，用于存放临时没有整理的文件。 0x02. Win10 自带功能怎样提升效率 2.1 快捷键其他答主说的都可以，你就直接参考他们的答案中的关于快捷键。我仅仅说一些重点快捷键。Win+ 数字键 把常用的软件附在任务栏上。建议四个以内，方便单手操作。Win+X Alt+tab 切换窗口 WIn+R 运行 2.2 触摸板手势参考最高票的答案。虽然我觉得增加的那么多的触摸手势比较鸡肋。 2.3 Win+RWin+R 主要用于启动一些程序或者一些 DOS 小命令。 我将所有的便携与非便携软件的快捷方式放在这里并且配置环境变量。比如，我需要启动为知笔记，我就仅仅需要闭上眼睛输入 Win+R + wz + 其他软件同理。 12345# sublime text 打开需要输入 Win+R + st +&lt;Enter&gt;# 欧路词典 打开需要输入 Win+R + ol +&lt;Enter&gt;# 这里省去若干软件打开方式。 关于 Win+R 你可以参考善用佳软 最绿色最高效，用 win+r 启动常用程序和文档 的介绍。 0x03. 非 Windows 自带的必备软件 非 Windows 自带的必备的提升效率，节省时间的软件。 3.1 文档，图片，文本，以及通用文件管理器如果文件多，就一定需要一个用于管理这种类型文件的管理器 - 托马斯。电脑达人 图片管理用 Picasa 文本管理直接使用笔记软件比如为知笔记，或者印象笔记。 文件管理进阶的话可以使用 totalcmd，不过学习路线比较陡峭，没有足够的需求，不要搞 TC. 用 Everything。或者 listary 3.2 Everything is OK 无坚不摧，为快不破。 everything 是搜索效率最快的软件。没有之一。合理的命名可以为你的生活节省一半找资料的时间。 3.3 Chrome （Google 出品，必属精品） 浏览器本身速度快，配合强大的插件库。让你在实力派装逼的道路上越走越远 这玩意的强大在哪到处都有，直接在知乎上搜一下就好了。 3.4 阅读方面 calibre ， 欧路词典， calibre 主要是用来看经济学人，老乡恶魔的奶爸推荐。 欧路词典可以外挂其他的开源词库，查词速度超级快。 3.5 笔记软件 xmind，wiznote 用于记录笔记。前者用于梳理思路，把一本书读薄，后者用于将自己的知识体系梳理一遍，把书读厚。消化资料。 3.6 播放器 QQ 影音 – 满足普通播放需求 kmplayer – 用于视频截图 foobar2000 – 逼格提升必备 网易云音乐 – 这货真的不错。 3.7 其他想到再补充 0x04. 不写点代码优化一下工作流程，你都不好意思说自己逼格高。不写点代码优化一下工作流程，你都不好意思说自己逼格高。- autohotkey 可以针对快捷键进行编程。有了它，妈妈再也不担心我操作速度慢的要死了。 有如下场景：一大段文字中有一个网址，你需要访问它，我的解决方法就是选中那些文字，然后一个 Win+b，直接打开 chrome 进行搜索，如果文字中没有网址，那么对选中文字进行百度。同理可以推淘宝，京东 github 等等。或者这样一个场景，你需要大量的文本编辑，但是上下左右离自己的工作区比较远，你可以小拇指按住大写锁定按键，然后使用 HJKL 进行移动。 教程参考 AutoHotkey 之美 - 知乎专栏 新手可以先拿我搜刮整理的 AHK 代码看看。twocucao/ChortHotKey · GitHub PS：我上面提到的软件几乎都是神级软件，都是入门容易精通难的深坑，想调教好也不是想象中呢么简单的，但，书到用时方恨少，你可以先挑一些使用。如果你以后有不少的文件需要管理，在未来，你一定会用到。 至于哪些图标怎么搞定？步骤如下：制作出那样的图片文件 （PS）转换成 ico 文件（Iconmaster），把 ico 文件拷贝到指定文件夹内部（这步是为了方便修改文件夹切换电脑带来的文件夹图标恢复原样）ico 设置到文件夹上 （修改文件夹内部的 desktop.ini 文件） 附上制作的 PSD 文件，ICONMASTER 以及一个样板文件夹（注意要开启显示系统文件以及隐藏文件两个选项，然后查看样板文件夹中的 desktop.ini 以及 ico 文件。修改的话，也就是修改 desktop.ini 文件里面的对应文件名称就好了） 链接： 百度云地址 密码：g9up foobar 链接：百度云地址 密码：e0as 文件图标受此答案启发：如何整理电脑文件夹？ - 计算机 2016-01-04 已经更换 Macbook Pro, 依然挂念 Windows.2017-05-01 21:42:00 已经更换 2016 年 Macbook Pro With Multi-Touchbar, 再无挂念 Windows. 0x05. 后续所谓用 Windows 还是 MacOS 都是一种选择而已，孰高孰下谁知道呢。并不是说用了一个操作系统，用了某个软件，就会显得自己多么高明，如果不能为自己的日常工作提高效率，让自己节省下来的时间留给自己，那又有什么意义呢？ 当我在 Windows 上的时候一味追求 APM, 即高效的操作，但其实最高效的还是自己的思路清晰，想好了再动手。 谋定而后动 如是而已。 抓到老鼠的猫才是好猫呀！ ChangeLog: 2017-03-08 09:32:15 整理知乎回答，搬运到博客上。 2017-05-01 09:32:15 补充现在使用的电脑信息 2017-06-10 09:32:15 重新排版，增加后续章节。]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索引擎的一些技巧]]></title>
    <url>%2F2015%2F05%2F04%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[0x01 Google 搜索引擎技巧123456intitle: 古文观止 site: pan.baidu.com+ orlink:http://www.reanren.cominurl""『长城防*墙』 0x02 Baidu 搜索引擎技巧1site: ChangeLog: 2016-12-22 几乎重修文字，修改标题为 搜索引擎的一些技巧。]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>编程工具</tag>
        <tag>高效</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell CheatSheet]]></title>
    <url>%2F2015%2F04%2F18%2FShellCheatSheet%2F</url>
    <content type="text"><![CDATA[0x00. 前言本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Shell 单行命令。 脚本主要适用于 BASH 环境，因为 Server 端的 Bash 主要还是 Bash 脚本居多。 不定期更新。 声明：Bash 命令适合那些十来行代码可以搞定的比较简单的逻辑，一般情况下用于处理一些服务的开启。至于部署，强烈推荐 Ansible. 目前在项目中使用 Ansible 从零开始无人值守部署一台机器。基本上完美到极致。 0x01. 快捷键操作 「c-c」 : 中断当前命令。 「c-z」 : 当前程序暂停，bg 切换后台运行，使用 fg 可以调回 「tab」 : 补全 「tabx2」 : 补全提示 「c-r」 : 搜索命令行 「c-w」 : 同 vim 「c-u」 : 删除整行 「a-b/a-f」 : 移动一个词 「c-a」 : 移动至行首 「c-e」 : 移动至行尾 「c-k」 : 删除光标到行尾 「c-l」 : 清屏 「c-x,c-e」 : 用默认编辑器编辑当前命令（这样就可以把其他文本移动扔掉了。) 0x02. Linux 命令如果你使用的是 MAC, 先安装下面的程序。 12345678910111213141516brew install findutils --with-default-namesbrew install gnu-sed --with-default-namesbrew install gnu-tar --with-default-namesbrew install gnu-which --with-default-namesbrew install gnutls --with-default-namesbrew install grep --with-default-namesbrew install coreutilsbrew install binutilsbrew install diffutilsbrew install gzipbrew install watchbrew install tmuxbrew install wgetbrew install nmapbrew install gpgbrew install htop 经过上面一步，则基本上 find sed tar which 这些命令使用的 gnu 版本 (linux 版本）, 而非系统自带的 unix 版本了。 基本命令123456man pythonwhatis pythonwhich pythoninfo pythonwhere python 文件与目录管理123456789101112131415161718192021222324252627282930313233343536373839404142# 创建和删除mkdirmkdir -p a/b/crmrm -rf dir/file/regexrm *log# 等价find ./ -name "*log" -exec rm &#123;&#125;;mv## mv 可以用于移动文件，也可以进行重命名cpfind ./ | wc -lcp -r source_dir dest_dirrsync --progress -a source_dir dest_dir# 目录切换cdcd -cd / cd ~pwdls -lrtfind ./ -name "*.o" -exec rm &#123;&#125; \;moreheadtailtail -f filenamediffchownchmodchown -R tuxapp source/chmod a+x myscriptln cc ccAln -s cc ccTocat -v record.log | grep AAA | grep -v BBB | wc -l 123456789101112#!/bin/bashlftp &lt;&lt;SCRIPTset ftps:initial-prot ""set ftp:ssl-force trueset ftp:ssl-protect-data trueset ssl:verify-certificate noopen ftp://192.168.2.254user xxx xxxlcd /Users/xxx/Codes/Workspace/put /Users/xxx/Codes/Workspace/all_codes.zipexitSCRIPT 查找文件之 find (gfind)12345678910111213141516171819202122232425262728293031323334353637383940414243## Findfind . \( -name "*.txt" -o -name "*.pdf" \) -print# 正则方式查找。txt 和。pdffind . -regex ".*\(\.txt|\.pdf\)$"find . ! -name "*.txt" -printfind . -maxdepth 1 -type f# 定制搜索## 按照类型搜索find . -type f -print #只列出所有文件find . -type d -print #只列出所有目录find . -type l -print #只列出所有符号链接## 按照时间搜索find . -atime 7 -type f -print # 最近第 7 天被访问过的所有文件：find . -atime -7 -type f -print # 最近 7 天内被访问过的所有文件：find . -atime +7 type f -print # 查询 7 天前被访问过的所有文件：# w,k,M,Gfind . -type f -size +2kfind . -type f -perm 644 -print # 找具有可执行权限的所有文件find . -type f -user weber -print # 找用户 weber 所拥有的文件# 后续动作## 删除find . -type f -name "*.swp" -delete## 执行动作find . -type f -name "*.swp" | xargs rmfind . -type f -user root -exec chown weber &#123;&#125; \;## eg: copy 到另一个目录find . -type f -mtime +10 -name "*.txt" -exec cp &#123;&#125; OLD \;## -exec ./commands.sh &#123;&#125; \;# 2. 删除内部为空的文件夹# 递归删除 a/b/cfind . -type d -empty -delete# 使用.gitkeep 进行填充find . -type d -empty -exec touch &#123;&#125;/.gitkeep \;find . -type d -empty -not -path '*/\.*' -exec touch &#123;&#125;/.gitkeep \; # 不初始化.git/# 3. 寻找 TOP 10find . -type f -printf '%s %p\n'| sort -nr | head -10 | awk '&#123;$1/=1024*1024;printf "%.2fMB - %s\n",$1,$2&#125;'# 4. 寻找文件夹 TOP 10 文本处理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960## Grepgrep match_pattern file-o 只输出匹配的文本行-v 只输出没有匹配的文本行-c 统计文件中包含文本的次数-n 打印匹配行号-i 搜索时符合大小写-l 之打印文件名grep "class" . -R -n # 多级目录中对文本递归搜索grep -e "class" -e "vitural" file # 匹配多个模式grep "test" file* -lZ| xargs -0 rm # grep 输出以、0 作为结尾符的文件名：（-z）-d 定义定界符-n 输出为多行-l &#123;&#125; 指定替换字符串cat file.txt | xargs # 打印多行cat file.txt | xargs -n 3 # 分割多行cat file.txt | xargs -I &#123;&#125; ./command.sh -p &#123;&#125; -1-0 指定、0 为输入定界符find source_dir/ -type f -name "*.cpp" -print0 |xargs -0 wc -lsort 排序-n 按数字进行排序-d 按字典序进行排序-r 逆序排序-k N 指定按照第 N 列排序sort -nrk 1 data.txtsort -bd data // 忽略像空格之类的前导空白字符sort unsort.txt | uniq &gt; sorted.txt # 消除重复行sort unsort.txt | uniq -c # 统计各行在文件中出现的次数sort unsort.txt | uniq -d # 找出重复行# 用 tr 进行转换# cut 按列切分文本cut -f2,4 filename #截取文件的第 2 列和第 4 列cut -f3 --complement filename #去文件除第 3 列的所有列cut -f2 -d";" filename -d #指定定界符cut -c1-5 file #打印第一到 5 个字符cut -c-2 file #打印前 2 个字符# paste 按列拼接文本paste file1 file2 -d ","# wc 统计行和字符的工具wc -l file # 统计行数wc -w file # 统计单词数wc -c file # 统计字符数# sed 文本替换利器sed 's/text/replace_text/' file # 首处替换sed 's/text/replace_text/g' file # 全局替换sed -i 's/text/repalce_text/g' file # 替换文件sed '/^$/d' file # 移除空白行 查看磁盘空间123456789101112#查看磁盘空间df -h#查看目录大小du -shdu -sh `ls` | sort#打包tar -cvf#解包tar -xvf#压缩gzip#解压缩 gunzip bzip tar 是将多个文件放在一起变成一个 tar 文件 (Tape Archiver) gzip 是讲一个文件变成一个压缩文件 则 foo.tar.gz 指的是 先把文件转为 tar 文件，然后 gzip 之 https://askubuntu.com/questions/122141/whats-the-difference-between-tar-gz-and-gz-or-tar-7z-and-7z 进程管理工具ps -fe| grep posgres 性能监控内存瓶颈 12htopfree # 从 /proc/meminfo 读取数据 IO 瓶颈 12# ubuntu 下 可以 mac 下不可以iostat -d -x -k 1 1 如果 %iowait 的值过高，表示硬盘存在 I/O 瓶颈。如果 %util 接近 100%，说明产生的 I/O 请求太多，I/O 系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，io 响应太慢，则需要进行必要优化。如果 avgqu-sz 比较大，也表示有大量 io 在等待。 网络工具1netstat -a 用户管理工具所有用户和用户组信息保存在：/etc/passwd , /etc/group 用户 123useradd -m yaweb # 创建相关账号，和用户目录 /home/yawebpasswd yawebuserdel -r yaweb # 删除 用户组 123usermod -g groupName username # 变更组usermod -G groupName username # 添加到组usermod -aG sudo yaweb # 添加 yaweb 到 sudo 组 用户权限 1chown userMark(+|-)PermissionsMark userMark 取值： u：用户 g：组 o：其它用户 a：所有用户 PermissionsMark 取值： r: 读 w：写 x：执行 123chmod a+x main 对所有用户给文件 main 增加可执行权限chmod g+w blogs 对组用户给文件 blogs 增加可写权限chown -R weber server/ 系统管理以及 IPC 资源管理12345678910111213141516171819ps -ef | grep twocucaops -lu twocucao# 完整显示ps -ajxtophtoplsof -i:3306lsof -u twocucaokill -9 pidnum# 将用户 colin115 下的所有进程名以 av_开头的进程终止：ps -u colin115 | awk &apos;/av_/ &#123;print &quot;kill -9 &quot; $1&#125;&apos; | sh# 将用户 colin115 下所有进程名中包含 HOST 的进程终止：ps -fe| grep colin115|grep HOST |awk &apos;&#123;print $2&#125;&apos; | xargs kill -9; 其他一些技巧有趣的重命名常用 mv 进行重命名，有的时候这个功能显得很不实用，比如，我要把当前的文件夹内的所有图片命名为 0001.png-9999.png, 这个 mv 时候就相当的鸡肋。 1brew install renameutils mmv rename 如果对于大批的文件需要重命名，比如有接近 10000 个文件，大量乱码文件改为 0001.jpg - 9999.jpg 这种东西放在 IPython 里面写 Python 脚本也还 OK, 但是总想直接一行命令解决 常用组合技12# 查看 windows txt 文件中的查看二字的数量cat * | iconv -f GBK | grep 查看 | wc -l Python 常用 Shell 命令1234# 升级当前所有第三方包pip install -i https://pypi.doubanio.com/simple -U pippip freeze --local | grep -v '^\-e' | cut -d = -f 1 | xargs -n1 pip install -U -i https://pypi.doubanio.com/simple ### 12345tig 字符模式下交互查看 git 项目jq 可以用于 json 文件处理以及何世华显示python -m json.toolaxel -n 20 http://centos.ustc.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1511.isocloc 用于统计代码 Tips &amp;&amp; Hacks网络篇/etc/hostname /etc/hosts 磁盘篇1234# 查看当前目录大小du -sh# 查看当前目录的下一级文件和子目录的磁盘容量du -lh --max-depth=1 文本篇sed -i ‘s/twocucao/micheal/g’ xx.dump.sqlsed -n 634428,887831p insert_doc_ids_new.sql &gt; uninserted_sql.sql 用户篇12# 添加 yaweb 为 sudo 用户usermod -aG sudo yaweb ps au | grep phantomjs | awk ‘{ print $2 }’ | xargs kill -9 拷贝本地文件到远程服务器rsync -vr –progress JudgementLibraryCrawler twocucao@192.168.2.151:/Users/twocucao/Codes/ sshssh -l root 192.168.2.253 扫描器sudo nmap -v -sS -O 192.168.2.0/24 FTP Client 自动化提交12345678910111213#!/bin/bashlftp &lt;&lt;SCRIPTset ftps:initial-prot &quot;&quot;set ftp:ssl-force trueset ftp:ssl-protect-data trueset ssl:verify-certificate noopen ftp://xxx.xxx.xxx.xxx:21user ftpuser ftppasslcd /Users/&lt;username&gt;/Ftps/Workspace/libsput /Users/&lt;username&gt;/Ftps/Workspace/repos/xxx.jarexitSCRIPT 资料推荐 一个关于 Linux 命令的各种奇技的网站 http://www.commandlinefu.com/commands/browse Linux 工具快速教程 http://linuxtools-rst.readthedocs.org/zh_CN/latest/index.html 一个 Awesome List, https://github.com/jaywcjlove/linux-command 命令行的艺术 https://github.com/jlevy/the-art-of-command-line man command 需要好好研读，特别是 man bash 至少要研读几遍]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>Cheatsheet</tag>
        <tag>macOS</tag>
        <tag>Ubuntu</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扇贝背单词小助手]]></title>
    <url>%2F2015%2F03%2F17%2F%E6%89%87%E8%B4%9D%E8%83%8C%E5%8D%95%E8%AF%8D%E5%B0%8F%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[本文内容思路 英文单词的处理 shanbay 单词本的提交 英文单词的处理正则表达式进行提取，然后通过 Python 的自然语言处理工具 ntlk 进行单词原型的转换 shanbay 单词的处理由于使用了传说中的 requests，使得代码简洁程度大大提升。 代码如下英文单词处理模块 shanbay 登录以及单词的提交 这是 v0.1 版本，有不少细节需要调整。有时间我会继续更新代码 9 逻辑比较简单，自己阅读代码吧 请来 github 这里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import osimport re__author__ = 'micheal'from nltk.stem import WordNetLemmatizerlemmatizer = WordNetLemmatizer()## 常量设置BOOKS_FOLDER = "Books/"OUTPUTS_FOLDER = "OutPuts/"COVER_FILE = "cover.jpg"EXCLUDED_LIB_FILE = "excluded_libs.txt"SUMMARY_FILE = "SUMMARY.json"ALL_LIB_FILE = "all.txt"### 初始化数据，# 创建 ALLFiledef createMergeFile(): fo = open(ALL_LIB_FILE, 'w') for name in os.listdir(BOOKS_FOLDER): fi = open(BOOKS_FOLDER + name, "r") while True: s = fi.read(16 * 1024) if not s: break fo.write(s) fi.close() fo.close() passdef get_sorted_words_list_from(txt_path): with open(txt_path, "r") as f: strs = f.read() s = re.findall("\w+", str.lower(strs), flags=re.ASCII) ss = [] for item in s: ss.append(lemmatizer.lemmatize(item)) l = sorted(list(set(ss))) ll = [] for i in l: m = re.search("\d+", i) n = re.search("\W+", i, flags=re.ASCII) if not m and not n and len(i) &gt; 4: ll.append(i) # 不属于数字也不属于非（英文 + 数字）并且字母长度大于 4 的集合 return lldef WordCountInit(): createMergeFile() excluded_words = get_sorted_words_list_from("excluded_libs.txt") file = &#123;&#125; folder_list = os.listdir(BOOKS_FOLDER) for item in folder_list: file[item] = get_sorted_words_list_from(BOOKS_FOLDER + item) words = file[item] real_words = [] for word in words: if word not in excluded_words: real_words.append(word) # print("excluded_words\n"+str(excluded_words)) print("real_words\n" + str(real_words)) excluded_words.extend(file[item]) with open(OUTPUTS_FOLDER + item, "w") as f: f.write(str(sorted(list(real_words)))) return True # print(file) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159from datetime import datetimeimport jsonimport osimport requestsfrom WordsCount import get_sorted_words_list_from, WordCountInit__author__ = 'micheal'word_book_url = "http://www.shanbay.com/wordbook/99004/"from nltk.stem import WordNetLemmatizerlemmatizer = WordNetLemmatizer()class ShanBay: # 初始化 shanbay 的基本信息 # 1. 登录， # 2，创建 wordbook # 3，创建 wordlist， # 4，用集合填充 wordlist # 5，填充策略 # def __init__(self): print("基本数据正在初始化") WordCountInit() print("初始化完毕") self.headers = &#123; "User-Agent": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36", "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8", "Accept-Language": "en-US,en;q=0.5", "Accept-Encoding": "gzip, deflate", "Connection": "keep-alive", "Cache-Control": "max-age=0", &#125; self.index_url = "http://www.shanbay.com/" self.login_url = "http://www.shanbay.com/accounts/login/" self.sb_session = requests.Session() self.sb_session.headers.update(self.headers) self.sb_session.get(self.login_url) # 开始登录 # 初始化登录 print("正在登录中") self.doLogin("test", "test") print("单词书 情况如下 \n") with open("SUMMARY.json", "r") as f: decodejson = json.loads(f.read()) self.book_info_title = decodejson["title"] self.book_info_category = decodejson["category"] self.book_info_description = decodejson["description"] self.book_info_price = decodejson["price"] print( "标题：" + self.book_info_title + "\n 类型：" + self.book_info_category + "\n 描述：" + self.book_info_description + "\n 价格：" + self.book_info_price) self.createWordBook() ## 判断有多少个路进然后接着进行一系列的操作 word_list_list = os.listdir("Books/") for word_list in word_list_list: print("正在创建" + word_list) dt = datetime.now() list_id = self.createWordList(self.word_book_id, "List" + dt.strftime('%Y%m%d%H%M%S'), "这仅仅是一个比较简单的描述" + dt.strftime('%Y%m%d%H%M%S')) self.fillWordListById(list_id, get_sorted_words_list_from("OutPuts/" + word_list)) # print(self.sb_session.get(self.index_url).text) def doLogin(self, username, password): self.login_form = &#123; "csrfmiddlewaretoken": self.sb_session.cookies["csrftoken"], "username": username, "password": password, &#125; self.sb_session.post(self.login_url, self.login_form) return True def fillWordListById(self, _id, words): # "172981" for word in words: post_data = &#123; "id": _id, "word": word, &#125; self.sb_session.post("http://www.shanbay.com/api/v1/wordlist/vocabulary/", post_data) return 0 def createWordBook(self): # http://www.shanbay.com/wordbook/create/basicinfo/ createWordBookForm = &#123; "csrfmiddlewaretoken": self.sb_session.cookies["csrftoken"], "title": self.book_info_title, "category": self.book_info_category, "description": self.book_info_description, "price": self.book_info_price, &#125; t = self.sb_session.post("http://www.shanbay.com/wordbook/create/basicinfo/", createWordBookForm) self.word_book_id = str(t.url).split("/")[-3] # 封面没有办法提交...... 以后再说 coverFiles = &#123; "csrfmiddlewaretoken": self.sb_session.cookies["csrftoken"], "cover": ('cover.jpg', open('cover.jpg', 'rb'), 'image/jpeg', &#123;'Expires': '0'&#125;), "wordbook_id": self.word_book_id, "description": self.book_info_description, &#125; # files = &#123;'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', &#123;'Expires': '0'&#125;)&#125; self.sb_session.post("http://www.shanbay.com/wordbook/create/" + self.word_book_id + "/uploadcover/", files=coverFiles) return True def doMenu(self): # while True: # # print("""\ # # 请输入相关操作： # 1.createWordBook # 2.createWordList # # # """) # self.word_book_id = input("word_book_id") # # # pass def createWordList(self, _id, name, desc): createWordListFrom = &#123; "name": name, "description": desc, "wordbook_id": _id, &#125; r = self.sb_session.post("http://www.shanbay.com/api/v1/wordbook/wordlist/", createWordListFrom) return (json.loads(r.text)["data"]["wordlist"]["id"]) passsss = ShanBay() 这个程序还是比较简单的。 博客文章原创声明：本博文章如果没有声明为整理或者转载，均为本人原创。非商业可以任意转载分享。关于本人』(http://twocucao.xyz/about/),点击链接就可以 web 幻灯片的方式看到我对自己的介绍。 我的 Github 地址：https://github.com/twocucao （尽管东西不多，但是欢迎来 Star 和 Fork，就算你们来这里提前 Star Folk 了）简书地址：http://www.jianshu.com/users/9a7e0b9da317/latest_articles （不常更新，而且几乎没有技术文章的讲解）联系方式：twocucao@gmail.com本人才疏学浅，是一个水平比较菜的程序员，如果行文之间发现任何错误，欢迎指正，特别欢迎技术上的指正。]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>小玩具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 小爬虫案例 -- 抓取女神邓紫棋相关照片]]></title>
    <url>%2F2015%2F03%2F09%2F%E4%B8%80%E4%B8%AA%E5%B0%8F%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[0x00 前言在平时抓取部分自己喜欢的资源的时候，我们常常会去下载一些比较有用的资源，比如，我比较喜欢 GEM 的照片，但是，这个东西，总不能总是去找别人要吧，那么，怎么办？ 很简单，我们只需要通过 Python 写一个小小的爬虫就可以解决这些问题。 什么是爬虫？自己可以百度去。 我这里指的爬虫是那些可以模拟浏览器的行为的小程序。 比如，我要抓取 G.E.M 的相片，那么，我就想个办法。把图片的地址解析出来。然后写一个小功能下载不就好了么。 虽然，话是这么说， 但，怎么下手？ 这在写这篇文章，并且写到这里的时候，刚刚决定了抓取几个站点 （刚刚百度了 邓紫棋壁纸 得到这个网站 http://www.6188.com/show/12788_1.html) 0x01 准备工作以及爬取思路Python3,Chrome 浏览器或者 Firefox,Python3 基本依赖库 beautifulsoup4 lxml 任务如下： 第一个简单案例 http://www.6188.com/show/12788_1.html 百度 API 解析 虾米照片爬取 4.instagram 墙外下载 Gem 照片 发烧级别的 GEM 粉丝 - 虾米网 down! down! down! 涉及到的知识点： 爬虫的最最基本思路 几个解析方法 正则解析，bs4 解析，lxml 解析 多线程使用 0x02 6188.com 壁纸抓取 – 关键词爬虫先说一下思路，首先，你要会点击下载按钮.(#-#) 访问 http://www.6188.com/show/12788_1.html 点击下载大图 看大图，手动另存为 这是普通人下载图片的方式。 让我们用程序员的眼光来看。 浏览器呈现的具体的过程可以看我的 PyDjango 中关于计算机 Http 协议的部分。 经过抓包 (http 包）分析 (chrome 的 F12), 知道，要想获取图片原始链接，有这么一个流程 从 http://www.6188.com/show/12788_1.html 解析出下面链接 从 http://www.6188.com/show.php?pic=/flashAll/20140211/1392111065nvjKS7.jpg 解析下面链接 从 http://pic.6188.com/upload_6188s/flashAll/20140211/1392111065nvjKS7.jpg 下载图片。 这样一看，非常简单明了。这就是下载一张图片的链接。 同样道理，把下面的程序写成一个 for 循环，就可以直接下载 35 张图片。 123456http://www.6188.com/show/12788_1.htmlhttp://www.6188.com/show/12788_2.htmlhttp://www.6188.com/show/12788_3.html...http://www.6188.com/show/12788_35.html 写的应该比较容易认出 12345678910111213141516171819202122232425262728293031323334import osimport reimport requests__author__ = 'micheal'r = requests.get("http://www.6188.com/show/12788_1.html")m = re.search("(/show\.php.+jpg)\"", r.text)pic_url = "http://www.6188.com" + m.group(0)print(m.group(0))data = requests.get(pic_url)print(data.text)m = re.search("src='(http://.+\.jpg)", data.text)real_url = m.group(1)try: print("real_url-- 正在下载 --"+real_url) r = requests.get(real_url,stream=True) fileName = "GEM.jpg" fileFullPath = os.path.join('/home/micheal/Pictures/', fileName) print("正在下载" + str(data.status_code)) with open(fileFullPath, 'wb') as f: for chunk in r.iter_content(chunk_size=1024 * 2): if chunk: # filter out keep-alive new chunks f.write(chunk) f.flush() passexcept Exception: print("出错") raiseprint("任务完成") 添加 For 循环，优化一下1234567891011121314151617181920212223242526272829303132333435363738394041424344import osimport reimport requests__author__ = 'micheal's = requests.session() # 仿真 browser 使用一个会话for i in range(1,30): html_url = "http://www.6188.com/show/12788_"+str(i)+".html" r = s.get(html_url) print("downloading" + html_url) m = re.search("(/show\.php.+jpg)\"", r.text) pic_url = "http://www.6188.com" + m.group(0) print(m.group(0)) data = s.get(pic_url) print(data.text) m = re.search("src='(http://.+\.jpg)", data.text) real_url = m.group(1) try: img_store_dir = "/home/micheal/Pictures/GEM/6188" print("real_url-- 正在下载 --"+real_url) r = s.get(real_url,stream=True) fileName = "GEM"+str(i)+".jpg" if not os.path.exists(img_store_dir): os.makedirs(img_store_dir) fileFullPath = os.path.join(img_store_dir, fileName) print("正在下载" + str(data.status_code)) with open(fileFullPath, 'wb') as f: for chunk in r.iter_content(chunk_size=1024 * 2): if chunk: # filter out keep-alive new chunks f.write(chunk) f.flush() pass except Exception: print("出错") continue finally: passprint("任务完成") ###评价 第一个小程序应该是非常容易看懂的。 那么，这个程序有什么缺点呢？ 下载速度太慢，需要使用多线程， 解析方法不具有通用性，这张网页中只有一个地址需要解析，所以正则表达式还是可以胜任。但是，复杂的网页肯定不行 下载的图片太少了。 0x03 百度 API 的解析 – 关键词多线程主要就是增加了一个多线程的任务，原理什么的基本上和上面那个的相似 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import jsonimport osfrom queue import Queueimport reimport threadingimport requests__author__ = 'micheal'q = Queue(maxsize=0)# http://image.baidu.com/i?tn=resultjsonavatarnew&amp;ie=utf-8&amp;word=%E9%82%93%E7%B4%AB%E6%A3%8B&amp;cg=star&amp;pn=0&amp;rn=60s = requests.session()def worker(): while True: try: real_url = q.get() print("正在下载" + real_url) img_store_dir = "/home/micheal/Pictures/GEM/baidu" print("real_url-- 正在下载 --"+real_url) r = s.get(real_url,stream=True) fileName = real_url.split("/")[-1] if not os.path.exists(img_store_dir): os.makedirs(img_store_dir) fileFullPath = os.path.join(img_store_dir, fileName) print("正在下载" + str(r.status_code)) with open(fileFullPath, 'wb') as f: for chunk in r.iter_content(chunk_size=1024 * 2): if chunk: # filter out keep-alive new chunks f.write(chunk) f.flush() pass except Exception as e: print("出错") raise e continue finally: pass q.task_done() passif __name__ == "__main__": for i in range(100): fr = i * 60 to = i * 60 + 60 r = requests.get("http://image.baidu.com/i?tn=resultjsonavatarnew&amp;ie=utf-8&amp;word=%E9%82%93%E7%B4%AB%E6%A3%8B&amp;cg=star&amp;pn="+str(fr)+"&amp;rn="+str(to)+"&amp;itg=1&amp;z=3&amp;fr=&amp;width=0&amp;height=0&amp;lm=-1&amp;ic=0&amp;s=0&amp;st=-1") data = json.loads(r.text) for j in range(60): real_url = data['imgs'][j]['objURL'] print(real_url) q.put(real_url) for j in range(20): t = threading.Thread(target=worker) t.daemon = True t.start()q.join()print("任务完成") 引入了多线程，但是抓取效果并不好，大概有 10% 左右的照片可能是有点问题的，把线程数目从 20 条调整小一些。 先写到这里，明天接着写剩下来的代码。 0x04 抓取虾米的相册 – 反反爬虫好吧，我们将魔手伸向了虾米音乐的图片板块 http://www.xiami.com/artist/pic-55712 我们尝试使用昨天的方法获取页面。 123ss = requests.session()r = ss.get(“http://www.xiami.com/artist/pic-55712?spm=0.0.0.0.IaKt5o&amp;page=3”)print(r.text) 但是出现问题了， 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white”&gt;&lt;script&gt;with(document)with(body)with(insertBefore(createElement(“script”),firstChild))setAttribute(“exparams”,”category=&amp;userid=&amp;aplus&amp;yunid=&amp;&amp;asid=AABI4v5USkJh1pUp01o=”,id=”tb-beacon-aplus”,src=(location&gt;”https”?”//s”:”//a”)+”.tbcdn.cn/s/aplus_v2.js”)&lt;/script&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;p&gt;Your browser sent a request that this server could not understand. Sorry for the inconvenience.&lt;br/&gt;Please report this message and include the following information to us.&lt;br/&gt;Thank you very much!&lt;/p&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;URL:&lt;/td&gt;&lt;td&gt;http://www.xiami.com/artist/pic-55712?spm=0.0.0.0.IaKt5o&amp;amp;page=3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Server:&lt;/td&gt;&lt;td&gt;web-xiami-main-030.cm10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Date:&lt;/td&gt;&lt;td&gt;2015/03/10 20:23:36&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;hr/&gt;Powered by Tengine&lt;/body&gt;&lt;/html&gt;Process finished with exit code 0&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;&lt;/h&gt;&lt;/script&gt;&lt;/title&gt;&lt;/head&gt;&lt;/html&gt; 我们前面使用的代码都是爬取一些没有做太多防止爬虫的网站，但是，我们今天准备爬取的是一个有防护措施的网站。 没办法，修改一下 headers, 然后继续访问即可。 0xEE 更新 ChangeLog: 2017-12-19 重修文字]]></content>
      <categories>
        <category>Python 黑魔法</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用 Windows 之编辑器 Sublime Text]]></title>
    <url>%2F2015%2F02%2F27%2F%E7%BC%96%E8%BE%91%E5%99%A8Sublime%2F</url>
    <content type="text"><![CDATA[于2016 中期 重修文字，声明已转投 Vim. sublime 作为非主力编辑器。于2017 前期 重修文字，声明已转投 Spacemacs.于2017 后期 重修文字，重回 Vim. 这个 Sublime 究竟好在哪里？ 方便的 Vim 模式。 各种语言特性支持。 强大的社区支持。插件教程，balbalbala 长的好看，而且能干。 最佳实践下载安装（建议便携版本）http://www.sublimetext.com/3 安装 Package Control 用于管理插件步骤：view showconsole 输入下面代码 1import urllib.request,os,hashlib; h = 'eb2297e1a458f27d836c04bb0cbaf282' + 'd0e7a3098092775ccb37ca9d6b2e4b7d'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by) 重启，然后你就可以正常使用 Package Control 了 基本使用方法之编辑功能命令面板^+p ctrl+shift+p 打开的是命令面板命令面板主要内容分为四块。 设置 改变语法 来自插件的命令 Go to Anything^p 打开的是切换面板直接输入文件名可以切换文件可以直接预览输入 @ 可以查看按照 Header 查看 (Markdown 语法）, 代码中按照函数来查找输入 # 可以查看变量 同一页面搜索^r 整个项目搜索ctrl + shift + r Toggle Sidebarctrl+k Ctrl+b 切换面板alt + shift + 1 to 4 直达某行ctrl+g 移动行ctrl+shift+ 上下左右。 结论一嘿嘿，这样看上去你基本的编辑任务都是可以比较出色完成的吧？好，我们依然可以看出来，这款编辑器的的确确足够日常编辑使用了，但是，还是并不代表有一定的优越性啊？ 你说，老师，能不能再给力一点啊？ 深入研究其中的编辑功能把上面的一些功能进行系统性梳理。已经有前辈完成了，我就直接贴上他的地址了。 http://feliving.github.io/Sublime-Text-3-Documentation/index.html 结论二，确实强大。但是…你说，老师，能不能再给力一点啊？……………………..……………………………………………..…………………..…………………….……………………. 当然可以！! 插件，让 sublime 长出逆风飞翔的翅膀。sublime 的功能已经是比较强大了。可是还有什么地方可以优化的吗？加上插件，可以增强已经有的功能，可以扩展越来没有的功能。下面请看好！ 用 Vim 强化编辑功能。在编辑强化方面，Sublime 自带了一个非常好用的模式，叫做 Vintage mode这个模式有一点点的小问题，就是不方便，我们不妨使用另一个小插件来替换它。 https://github.com/guillermooo/Vintageous ctrl+shift+p 输入 install 输入{enter} 输入 Vintageous{Enter} 安装完毕，你就可以在 Sublime 上面比较方便的使用 vim 编辑方式了。 能不能好看一点？Of course! 来来来，戳这里戳这里 https://scotch.io/bar-talk/the-complete-visual-guide-to-sublime-text-3-themes-color-schemes-and-cool-features 新建文件可以方便一点吗？可以，AdvancedNewFile你只需要 ctrl+alt+n 就可以使用这个插件。 输入文件名可以直接在当前目录下新建。你也可以使用相对路径比如 ../ 或者 ../_drafts/AndroidShow是不是非常方便？ 侧边栏好像右键菜单好少，能不能再给力一点啊有，SidebarEnhancement 只能补全功能不够用，能不能再给力一点啊好，SublimeCodeIntel 我有强迫症，对齐功能不够强大，能不能再给力一点啊好，ALignment 写注释可以方便一些，就像 Intellij IDEA 那样写注释吗？可以 Doc Blockr 前端工程师要那些插件吗？EmmetHTML-CSS-JS等等 我平时用 markdown 写 BLOG, 有什么比较方便的东西吗？markdown extended preview light toc 结论三，老师真的很好用啊。但是…你说，老师，能不能再给力一点啊？……………………..……………………………………………..…………………..…………………….……………………..……………………………………………..…………………..…………………….……………………..……………………………………………..…………………..…………………….……………………..……………………………………………..…………………..…………………….……………………..……………………………………………..…………………..……………………. 特码的，你是来编程的还是来配置编辑器的啊！等你有需求了再去寻找更好的配置方案 OK? 其他链接这个 BLog 分享了不少关于 Sublime 的干货https://scotch.io/ 这个视频链接讲解了一些关于 Sublime 的一些小知识。http://www.imooc.com/learn/40 sublime 非官方资源http://docs.sublimetext.info/en/latest/index.html ChangeLog: 2016-12-05 重修文字，已转投 Vim. sublime 作为非主力编辑器。]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chorthotkey 发布]]></title>
    <url>%2F2015%2F02%2F22%2FChorthotkey%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[概要介绍经过长时间的电脑的使用，我渐渐的喜欢上了 Autohotkey 这个神器，喜欢 Python 是因为 Python 强大与高效，喜欢 AHK 则是太方便了。 长时间的使用，毕竟也积攒了一些脚本，加上对很多脚本的收集以及修改，勉强算得上是一个入门的 AHK 菜鸟了。 AHK 的优点可以对快捷键进行编程，对一个经常使用电脑自动化处理一些事情的人说，非常之方便，但缺点，太多，效率低，语法乱，数据结构乱。让我写一段文字处理简直就让我非常难受。 但为了取长补短，我仅仅使用其中的对快捷键编程的功能，加上收集来的别人的一些函数。修改集成，然后做一个顺手的 AHK 脚本，名字就叫做 Chorthotkey。 开源，协议选择 Mit 协议。简而言之也就是你改了名字版权就是你的了。 我在编写这篇文章的时候，也在重构并进行 V0.4 版本的完善。 什么时候使用 AHK 脚本呢。 当繁杂的功能可以批量完成的时候。 换而言之，当这个功能不值得用另一个大的专业性比较强的软件代替的时候，或者对快捷键进行编程的时候。 先说第一点：当我想使用一个功能的时候，比如快速打开一个网页，或者进行文字上的简单处理，这个时候没有必要单独下载一个软件进行处理，这个在 AHK 中就是简单的几行代码就可以搞定。比如打开网站直接 Run www.baidu.com AHK 就会直接调用相关浏览器打开 baidu. 这么简单的东西没有必要单独下载一个软件进行管理。 再说第二点：当我想着对快捷键进行编程调用进行自动化处理东西的时候，或者编写一套自己的热键用来打游戏或者其他的一些编辑用途等等，都可以。理论上来说，AHK 几乎是只有想不到没有做不到的。 那么，AHK 不能替代什么东西？ 在文件管理方面，尽管你可以自己编写很多的快捷键，但你没有办法超越 TotalCMD，没有办法超越 Listary 或者 Everything，所以，你编写的东西只需要辅助你使用这些东西就好了。 在文本编辑方面，你始终无法超越 sublime text 3，无法超越 vi，无法超越 Emacs，你只需要辅助你使用这些工具即可。 其他专业软件同理。 既然说了 AHK 那么多的不足和缺憾，但是 AHK 在我的脚本语言中依然傲立第二名，就是因为它擅长的快捷键编程。 好了，废话这么多，总该说点干货了。 我认为 Autohotkey 用好这三个脚本即可： Candy 一个非常强大的第三方弹出菜单 amii 编写。 ChortHotKey 一个我编写的工具 vimd 无所不在的 vim 党编写的软件。 好吧，我无耻的把三个工具放在一起了。虽然 Candy 和 vimdesktop 在使用上面甩 Chorthotkey 几条街，但是，我乐意把他们放在一起，怎么滴？ 设计思路AHK 的操作按照是否聪明分为两种： 第一种叫做非上下文的操作 第二种叫做上下文操作 AHK 操作按照使用场景分为： 直接操作 选中操作 AHK 按照操作目标分为 程序类操作 键盘类操作 文件类操作 文本类操作 命令类操作 其他操作 选取一个角度对 Chorthotkey 描述 — 按照操作目标 PS：浏览器建议 chrome 1. 程序类 – 涉及运行程序，或者一些常用的小功能我的所有程序都是使用配置好的环境变量 D:\Sysconfig 其中的快捷方式搞定的。比如 win+r 输入 qq 然后回车自动打开 QQ。这个并不使用 AHK。因为没有必要增加大量的热键来增加自己的记忆负担。但是使用频率非常高的必须设置快捷键。 程序类快捷键我主要使用的是 Win 按键，AHK 中用 # 来表示 123456789101112131415 #a 到有道官网查找单词翻译，并且保存到桌面上一个文本文档中。 #b 选中某段文字进行解析，如果里面有网址则访问网址，否则使用百度进行搜索 #g 选中某段文字进行解析，如果里面有网址则访问网址，否则使用 Google 进行搜索 #f 打开 everything 进行搜索 #e 替换原有的资源管理器，打开 TotalCMD #q 打开 QQ #v open with vim #s open with sublime text官方的操作 #c Windows8 什么鸟菜单 #x win8 快捷菜单 #r 运行，比较方便 #1-9 数字，建议把几个（四个之内，超过四个你的手可能就跟不上操作了）可能有变化的软件放在 pin 在 taskbar 上面。 2. 键盘鼠标操作123456789101112131415161718192021alt+f4 按住左键再按住右键输出CAPSLOCK 超级导航CAPSLOCK 输出 ESCSHIFT &amp; CAPSLOCK 调用 Candy下面内容属于组合键的另一个按键hjkl 前下上右a 行尾进行编辑o 下一行进行编辑n ctrl+deletem delete, backspace. ctrl+backspace5 打开 coding workspace6 打开未整理文件7 打开 Onedirve8 打开同步文件夹9 打开娱乐文件0 打开 sysconfig 3. 文件类操作选中的文件夹在 TC 中打开，其余操作全部在 TC 中解决由于我使用了 Capslock 的导航功能，这时候的 capslock hjkl 完全可以当作左下上右使用。vim+tc，可以使用 vim desktop 进行超级强化。我一直对 TOTALCMD 的快捷键设计抱有不满和一丝丝的畏惧，但是这个软件把 TC 的快捷键常用快捷键精简到了令人发指的地步。 I love TC plus AHK 4. 文本类操作candy 操作，保存，发送等等，凡是 Ctrl + c 飘落的地方，就一定会有 candy 的存在（火影忍者既视感）。请在我另一篇 Blog 中看看我是怎么使用 Candy 的。 5. 命令类操作这里面存放的是 AHK 的命令。其实就是使用 ahk 调用 python 脚本执行之类的东西。起到一个胶水的作用。 6. 其他操作热字符串输入其实和代码的 Snippet 比较相近。 12345678910111213141516171819202122用的特别频繁的//date 20150223/dd//time 08:52:33/tt//lastupdate 最后修改时间 2015-02-23 08:52:33/ll//mail twocucao@gmail.com/mm//anouncement 声明 lalalalalallalalalallalalalla/aa常用的//motto 我挥舞着纸笔和键盘，发誓要把这个世界写个明白。常用打开 Vim 的文字模板使用/hexo 打开 gvim，粘贴进去对应的模板。比如我输入//hexo那么就会 Copy 我之前定义的文字，然后存放在我的剪切板中。（时间是动态的）接着脚本打开 gvim，你要做的就是把文字粘贴进去就可以进行 HEXO 的编写了。 1234567891011121314151617181920title: 标题date:2015-02-23 10:16:30tags: 感悟category: 『生活，感悟』---正文&lt;!-- more --&gt;其他博客文章原创声明：本博文章如果没有声明为整理或者转载，均为本人原创。非商业可以任意转载分享。但是编写的代码如果没有特别声明，虽然我建议保留原作者出处，但是代码皆为 mit 协议，也就是修改了名字也算是你的版权，开源世界嘛，我就喜欢那些可以拿来直接使用的东西，贯彻最纯粹的免费自由，但是求求你，改掉名字等等信息再说是版权是你的啊。![关于本人](http://twocucao.xyz/about/),点击链接就可以以 web 幻灯片的方式看到我的介绍。我的 Github 地址：https://github.com/twocucao （尽管东西不多，但是欢迎来 Star 和 Fork，就算你们来这里提前 Star Folk 了）简书地址：http://www.jianshu.com/users/9a7e0b9da317/latest_articles （不常更新，而且几乎没有技术文章的讲解）联系方式：twocucao@gmail.com本人才疏学浅，是一个水平比较菜的程序员，如果行文之间发现任何错误，欢迎指正，特别欢迎技术上的指正。 三剑客地址 Chorthotkey https://github.com/twocucao/ChortHotKey Candy https://github.com/aamii/Candy VimDesktop https://github.com/victorwoo/vimdesktop 如果你想了解关于 ahk 的世界，请到这里来看： 善用佳软的 ahk 地址 A 大在知乎的系列专题 我的 AUTOHOTKEY 脚本使用我的脚本来上手速度会快很多） AWESOME AUTOHOTKEY_L 这里仅仅是关于 AHKL 的资源。 AHK 论坛 欢迎加入 AUTOHOTKEY 的官方群 3222783 这里的大神喜欢解答有挑战性的问题，很多 AHK 的脚本都在这里。 ChangeLog: 2016-11-23 已经于 2015-12 月份转投苹果平台，从此不想念 Windows. 除了 Windows 上面的 Autohotkey / Everything / TotalCMD]]></content>
      <categories>
        <category>善用佳软</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>Autohotkey</tag>
        <tag>自动化</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[至尊宝和孙悟空 - 『大话西游』影评]]></title>
    <url>%2F2014%2F10%2F25%2F%E5%AD%99%E6%82%9F%E7%A9%BA%E5%92%8C%E8%87%B3%E5%B0%8A%E5%AE%9D%2F</url>
    <content type="text"><![CDATA[有才的人往往是很有个性的，甚至个性难以驾驭，生活这么枯燥无味，天天做着同样的事情，吃饭，打怪，看着猪队友坑自己，还要听肉眼凡胎唐僧的绵延不绝的滔滔口水。 这样的生活有什么意思呢？我可是当年踏碎凌霄，放肆桀骜的齐天大圣孙悟空啊！ 于是，孙悟空打伤了紫霞仙子，把师傅送给牛魔王，抢走了月光宝盒。 孙悟空是想逃走，想逃避这样的一份普度众生的伟大职业。众生与我何干？我只管红尘潇潇洒洒便好。 那时候的孙悟空，放荡不羁爱自由，哪想着有一天会跌倒在观音和如来的手下。也不会想到，这个平时废话一大篇的唐僧居然用生命给自己换回了一个救赎的机会。 可是他的命运从转生成至尊宝那一天起，就已经刻在了命运之轮上。注定逃不了的。 五百年后，转世悟空至尊宝在五岳山第四边 101 号 B One 做着一份非常光辉的职业——山贼。偏偏蜘蛛精春三十娘来了，偏偏白骨精白晶晶来了，菩提老祖来了，牛魔王来了。甚至，这个时候，至尊宝以为自己爱上了那个爱上了孙猴子的白骨精。 只怪好景不长，该来的总是逃不掉。 冥冥之中，一切早就按照命运之轮运行，为了拯救心上人白晶晶，至尊宝阴差阳错回到了 500 年前，却和紫霞仙子相识。为了回到五百年后，至尊宝不惜欺骗紫霞仙子，说上一段一万年的承诺。 紫霞爱上了至尊宝，却落入了牛魔王的手中，至尊宝回到山洞，却意外的发现自己爱上的人是紫霞。却不是白晶晶。 『我一定是太想念晶晶了！』 『是啊，昏倒的时候叫了晶晶这个名字 98 次！』 『晶晶是我娘子！』 『还有一个名字叫做紫霞的你叫了 784 次，784 次…. 这个紫霞一定欠了你很多钱！』 爱情这东西总是后知后觉的，不是么？ 因为对白晶晶有责任感，至尊宝用月光宝盒想救白晶晶，却意外邂逅真爱紫霞。 为了打败牛魔王，救回紫霞，就要成为孙悟空，但如果成为不了孙悟空，将永远失去紫霞。 白晶晶和蜘蛛精再次闯进洞来，杀了至尊宝。死掉以后的至尊宝大彻大悟——为了化解人世间的仇恨，背负起该有的责任，救回紫霞，去取西经。 带上紧箍圈，获得强大的力量却再也不能有人世间的半点情欲。 唐僧对这孙悟空说：『你终于能够重返正途了，阿弥陀佛.』 而最终，紫霞死去了。 小的时候看《大话西游》的时候，可谓是单纯到只能解读笑点。现在看《大话西游》的时候，总是看着看着，就开始有些伤怀。其实众生依旧皆苦，剧中的至尊宝好歹是受过精神压力后戴上紧箍儿，瞬间开挂一般一夫当关万夫莫开。现实中想要去守护一些东西，还要经过漫长的修炼。 『等你明白了舍生取义的道理，你自然会回来和我唱这首歌的』 唐僧仿佛看穿了一切，又仿佛和之前一样对自己认为的道理令人发指的相信。 紧箍咒，圈住至尊宝昔日的梦想与爱情，圈住棱角分明的个性。至尊宝终究成为了悟空。 天边的你，漂泊在云海。 月溅星河 长路漫漫 风烟残尽 独影阑珊 谁叫我身手不凡 谁让我爱恨两难 到后来 肝肠寸断 女孩问：『那个人样子好怪。』男孩笑道：『我也看到了，他好像一条狗。』 UPDATE: 刘镇伟导演出了大话三，我觉得依旧是一个不错的番外，在我心里并不能算是续集。经典的续集总是难续的。 ChangeLog: 2014-10-25 完成初稿 2016-12-03 重修文字]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>影评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在人生的边上]]></title>
    <url>%2F2014%2F10%2F16%2F%E5%86%99%E5%9C%A8%E4%BA%BA%E7%94%9F%E7%9A%84%E8%BE%B9%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[写在人生的边上钱钟书先生有一本书叫做《写在人生的边上》。 读罢，由于缺乏足够的文学涵养，记性差，并没有对这本书留下非常深刻的印象。 除了这本书的书名。 当然，后来钱先生出了另一本书，叫做『人生边上的边上』, 那又是另一番意味了。 古人总是在书籍的边上写下一些东西，此为批注，便好像是在书上留下了自己的痕迹。 写下到此一游的风范，从古时候那孙猴子在如来的掌中留下一泡尿，到现在某些低素质游客随手乱刻乱画，可谓是一大特色，但细细想来这可能是老祖宗留下的传统。 在茫茫然中度过自己的一生，就好像草草写下一本书籍，还来不及写下什么优质的内容，就已经就已经从一本书的扉页翻到了尾页。 同样的剧情，同样的套路，只是人换了，而已。 可人总是想留下什么东西，总想向自己或者是他人证明，『我是独特的，是唯一的』。不是吗？ 比如在纸墨世界里留下一本书籍，或者是在比特世界里留下自己的博客。用这些文字，在一个已知的世界里，写一些已经知道的或者是不知道的世界，那多有趣。 如果说人这种动物的一生仅仅用一本书就可以包容的话，那么我想，在我的故事的结尾，我可以看到我的人生的那本书，以及写在书本边上的那些批注，甚至写批注上的批注。这样，总归是让自己的一生，多了一些有趣的意义。 写东西，也是为了获得并且保持更加精确的思考。 此为我写这些文字的原因，也是我重新开始写这些文字的原因。 ChangeLog: 2015-02-20 增加图片 2016-11-23 重新润饰文字 2017-03-08 增加几句新感慨]]></content>
      <categories>
        <category>写在人生的边上</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>