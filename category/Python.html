<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Python | 海拉鲁编程客</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/49455a07b6dd33600cdf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/49455a07b6dd33600cdf.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-20d43e08bea62467b090.js" defer=""></script><script src="/_next/static/chunks/framework-0441fae7fd130f37dee1.js" defer=""></script><script src="/_next/static/chunks/main-4777350f2a9ff73ea2b0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3050679c6e5142ffcaf5.js" defer=""></script><script src="/_next/static/chunks/ea88be26-9bcf6ead520f4ac26973.js" defer=""></script><script src="/_next/static/chunks/421-f2f33a86b546237f0325.js" defer=""></script><script src="/_next/static/chunks/pages/category/%5Bslug%5D-4d8847f86983258925d4.js" defer=""></script><script src="/_next/static/oDi_oBCBuu3qj6v7hDnrL/_buildManifest.js" defer=""></script><script src="/_next/static/oDi_oBCBuu3qj6v7hDnrL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="v-page"><nav class="shadow"><div class="flex flex-col container mx-auto h-12 px-40 md:flex-row md:items-center md:justify-between"><div class="flex justify-between items-center"><div><a class="text-gray-800 text-xl md:text-xl leading-5" href="/">海拉鲁编程客</a></div><div><button type="button" class="block text-gray-800 hover:text-gray-600 focus:text-gray-600 focus:outline-none md:hidden"><svg viewBox="0 0 24 24" class="h-6 w-6 fill-current"><path d="M4 5h16a1 1 0 0 1 0 2H4a1 1 0 1 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2z"></path></svg></button></div></div><div class="md:flex flex-col md:flex-row md:-mx-4 hidden"><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/">首页</a><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/archive">归档</a><a class="my-1 text-gray-800 hover:text-blue-500 md:mx-4 md:my-0" href="/about">关于我</a><button style="cursor:pointer;overflow:hidden;width:50px;height:23.5px;appearance:none;-moz-appearance:none;-webkit-appearance:none;border:none;background-color:transparent;padding:0" aria-hidden="true"><div style="display:flex;align-items:center;justify-content:center;margin-top:-28.749999999999996px;margin-left:-16px;width:82.5px;height:82.5px"><div></div></div></button></div></div></nav><div class="v-article">Python<li>Python Profiling/Tracing Tools</li><li>Python ORM</li><li>CPython 源码初步阅读笔记</li><li>PyCon 2018 之 pipenv -- 未来的 Python 依赖管理工具</li><li>NumPy CheatSheet</li><li>Celery 快速入门指北</li><li>Python 中的数据压缩和存档</li><li>记一次小机器的 Python 大数据分析</li><li>Python 图片爬虫</li><li>背单词小助手</li><li>Python 中的作用域准则</li><li>ReThinking In Python</li><li>Pandas CheatSheet</li><li>Thinking In Python Language</li><li>从一个小问题来说 Python 的作用域</li><li>Text Processing In Python</li><li>Awesome-Python</li><li>IPython Notebook 引入 ECharts 做可视化</li><li>如何发布一个 Python 命令行工具</li><li>Python 程序员如何优雅的看斗鱼 TV</li></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"category":{"name":"Python","posts":[{"tags":["Python","性能优化"],"path":"20201201_PythonProfiling.md","title":"Python Profiling/Tracing Tools","slug":"Python Profiling/Tracing Tools","date":"2020-11-30","category":"Python","lastMod":"2020-12-01","description":"未描述","thumbnail":"","content":"\n- Profiling 定位与优化耗时、内存使用、CPU 使用\n- Tracing 用于追踪内存布局\n\n## 0x00 前言\n\n本篇讨论的是优化\n\n当我们在谈优化的的时候，首先要背诵下面三个口诀\n\n    优化口诀 1: 先做对，布监控，再做好。\n    优化口诀 2: 过早优化是万恶之源。\n    优化口诀 3: 去优化那些需要优化的地方。\n\n可以参考之前的文章 https://zhuanlan.zhihu.com/p/58754459\n\n本文讨论的是基于现有代码的诊断。也顺带讨论了无侵入线上 trace 的原理和技巧\n\n优化分为两种：\n\n1. 侵入性诊断\n2. 侵入性诊断\n\n## 0x01 侵入性诊断\n\n### 基础工具\n\n- print\n- logging\n- timeit\n\n### Profile vs cProfile\n\ncProfile overhead 较高，\n\n```python\nimport cProfile\nimport re\ncProfile.run('re.compile(\"foo|bar\")')\n\n   197 function calls (192 primitive calls) in 0.002 seconds\n\nOrdered by: standard name\n\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\n     1    0.000    0.000    0.001    0.001 \u003cstring\u003e:1(\u003cmodule\u003e)\n     1    0.000    0.000    0.001    0.001 re.py:212(compile)\n     1    0.000    0.000    0.001    0.001 re.py:268(_compile)\n     1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)\n     1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)\n     4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)\n   3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)\n```\n\n### SpeedScope\n\n- speedscope\n- pyspeedscope\n\n### PyInstrument\n\n- https://github.com/joerick/pyinstrument\n- https://github.com/joerick/pyinstrument_cext\n\n### Line Profiler\n\nhttps://github.com/pyutils/line_profiler\n\n```bash\nPystone(1.1) time for 50000 passes = 2.48\nThis machine benchmarks at 20161.3 pystones/second\nWrote profile results to pystone.py.lprof\nTimer unit: 1e-06 s\n\nFile: pystone.py\nFunction: Proc2 at line 149\nTotal time: 0.606656 s\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n   149                                           @profile\n   150                                           def Proc2(IntParIO):\n   151     50000        82003      1.6     13.5      IntLoc = IntParIO + 10\n   152     50000        63162      1.3     10.4      while 1:\n   153     50000        69065      1.4     11.4          if Char1Glob == 'A':\n   154     50000        66354      1.3     10.9              IntLoc = IntLoc - 1\n   155     50000        67263      1.3     11.1              IntParIO = IntLoc - IntGlob\n   156     50000        65494      1.3     10.8              EnumLoc = Ident1\n   157     50000        68001      1.4     11.2          if EnumLoc == Ident1:\n   158     50000        63739      1.3     10.5              break\n   159     50000        61575      1.2     10.1      return IntParIO\n```\n\n### 其他侵入性 Profiling 方案\n\n- https://github.com/vmprof/vmprof-python\n- https://github.com/bdarnell/plop\n\n### Overhead 基数\n\nDjango template render × 4000\n\n- Base 0.33s\n- pyinstrument 0.43s 30%\n- cProfile 0.61s 84%\n- profile 6.79s 2057%\n\n### 内存布局\n\n- memory profiler 检查内存消耗\n- pympler 快照未 GC 的对象\n\n\u003e TODO: python 有无侵入检查内存布局的工具么？\n\n## 0x02 无侵入诊断\n\n以上的代码都是侵入代码，Java 生态中存在着一些黑科技。可以在线打断点。\n\nhttps://github.com/qunarcorp/bistoury/blob/master/docs/cn/debug.md\n\n从而实现无侵入在线 tracing 代码，可以理解为一个无需 reload 代码即可实现的热插拔 logging\n\nPython 世界里存在 2 个这样的工具\n\n### pyflame\n\n- https://github.com/uber-archive/pyflame\n\n原理\n\n- https://man7.org/linux/man-pages/man2/ptrace.2.html\n\n### py-spy\n\n- https://github.com/benfred/py-spy\n\n直接读取 python 程序的内存信息\n\n- Linux https://man7.org/linux/man-pages/man2/process_vm_readv.2.html\n- macOS https://developer.apple.com/documentation/kernel/1585350-vm_read?language=objc\n- Windows https://msdn.microsoft.com/en-us/library/windows/desktop/ms680553(v=vs.85).aspx\n\n## 0x03 其他利器\n\n### Django Debug Toolbar\n"},{"tags":["Python","ORM","SQLAlchemy"],"path":"20190412_PythonORM.md","title":"Python ORM","slug":"Python ORM","date":"2019-04-12","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\nPython 圈内三大 ORM SQLAlchemy VS Django ORM VS Peewee\n\n1. SQLAlchemy 复杂程度最高，同时，这也意味着 SQLAlchemy 可以做更多的事情。使用 DataMapper 方式实现\n2. Django ORM 个人最喜欢，使用 ActiveRecord 实现 如果不是因为现在 Flask 项目已经是用了 SQLAlchemy , 否则的话我甚至会考虑将 Django ORM 配置到 Flask 项目中。当然，也有蛋疼的 SqlAlchemy 使用者已经移植给 django 配置了 SQLAlchemy 的库。\n3. Peewee 没用过，不好评论。以后有机会试试。\n\n## 0x01 如何访问数据库\n\n那，既然已经可以访问数据库，本着『如无必要，勿增实体』的原则，为什么要不辞劳苦的用个库呢？\n\n## 0x02 数据库抽象的两种理论\n\n### 理论一：Active Record\n\n### 理论二：Data Mapper\n\n## 0x03 数据库抽象的两种实现\n\n### 实现一：Django ORM\n\n### 实现二：Sqlalchemy\n\n## 0x04 工具的强弱\n\nhttps://www.thoughtfulcode.com/orm-active-record-vs-data-mapper/\n\n### 2.0 SQLAlchemy VS DjangoORM\n\nORM 通常有 DataMapper 实现和 ActiveRecord 实现两种。\n\n依照我的经验，ActiveRecord 使用起来的更接近对象 (Object) 的操作，DataMapper 使用起来更接近 (Table) 的操作。\n\n\u003e SQLAlchemy 是 DataMapper 模式的实现，在该模式下，session 会暴露出来，即 Model 与 session 并不耦合。\n\n\u003e DjangoORM 是 ActivityRecord 模式的一种实现，在该模式下，session 并不暴露出来，即 Model 与 session 耦合。\n\n使用 Django ORM 的时候，往往是\n\n```python\nb = Blog(**data)\nb.save()\n```\n\n使用 SQLAlchemy 的时候，往往是\n\n```python\nb = Blog(**data)\nsession.add(b)\nsession.session(b)\n```\n\n由于 Django 帮你屏蔽了 session 的操作。\n\n在通常情况下，\n\n1. DjangoORM 使用起来更加接近 Object 的操作。\n2. SQLAlchemy 使用起来更加接近 Table 的操作。\n\n举个例子，\n\n一对多，Father 添加两个小孩（其中一个小孩是已经存在的）\n\n在 DjangoORM 里面， 这里更像是一个 Set 的 add 操作。\n\n```python\nfather.children.add(new_child,exsit_child)\n```\n\n在 SQLAlchemy 里面，这里更像是一个 table 的 insert 操作。（麻蛋，你要说是一个 list 的 append 操作也行）\n\n```python\nfor child in (new_child,exsit_child):\n    if child in father.children:\n        father.children.append(child)\n```\n\n\u003e 写 SQLAlchemy 更接近操作放在数据库里面的数据记录，而 DjangoORM 更接近操作一批放在数据库里面的对象。\n\n由于 session 的使用姿势不同，所以往往会有很多使用上面的区别。\n\n至于孰优孰劣，难以评判。\n\n- 技术老大 (Flask 和 React 大神）倾向于使用 SQLAlchemy, 他认为\n\n  - 对于一个技术『知其然，知其所以然』\n  - 对于 ORM\n    - 操作数据库，操作最好要落实在成 SQL\n    - 如果有可能的话，每一个 SQL 语句都要经过推敲，而且写这个 SQL 和 ORM 过程要反复练习\n  - 对于 Migration 机制\n    - Alembic 这个迁移工具是为了省事用的，甚至在某些情况下没必要用。完全可以写 SQL 代替\n\n- 我 (Django 和 Vue 弱鸡）倾向于使用 DjangoORM, 我认为\n  - 对于一个技术『先知其大致然，需要深入的时候知其所以然』\n  - 对于 ORM\n    - 操作数据，最好抽象为对对象的操作。\n    - 测试到位的情况下，快糙狠先出东西。到需要优化的时候该怎么 Profile 怎么 Profile\n  - 对于 Migration 机制\n    - 用起来啊，能操作对象为什么还要强行到数据库操作？\n\n```python\nActive Record, properly defined, is a design pattern where an object is represented as a record on a table in a relational database.\n```\n\n### 2.1 模型定义\n\n先看一组模型\n\n```python\nfrom sqlalchemy.ext.declarative import declarative_base\nBase = declarative_base() # 模型基类\nfrom sqlalchemy import Column, Integer, String\nclass User(Base):\n    __tablename__ = 'users'\n\n    id = Column(Integer, primary_key=True) # 主键\n    name = Column(String)\n    fullname = Column(String)\n    password = Column(String)\n\n    def __repr__(self):\n       return \"\u003cUser(name='%s', fullname='%s', password='%s')\u003e\" % (\n                            self.name, self.fullname, self.password)\nBase.metadata.create_all(engine)\n```\n\n可以看出，包含如下的部分：\n\n1. Model 与 Model 内部的 Meta\n2. Field 与 Field 内部的 Options\n3. Model 与 Model 之间的关系\n4. 其他，比如索引\n\n#### Models 与 Meta\n\nhttps://github.com/zzzeek/sqlalchemy/blob/master/lib/sqlalchemy/sql/schema.py#L3685\n\n#### 关系\n\n##### One To Many\n\n母亲有若干个孩子，外键在孩子上。\n\n```python\nclass Parent(Base):\n    #...\n    children = relationship(\"Child\", backref=\"parent\")\n\nclass Child(Base):\n    #...\n    parent_id = Column(Integer, ForeignKey('parent.id'))\n```\n\n##### Many To One\n\n多个母亲共享一个孩子，外键在母亲上。\n\n```python\nclass Parent(Base):\n    child_id = Column(Integer, ForeignKey('child.id'))\n    child = relationship(\"Child\")\n\nclass Child(Base):\n    # ...\n```\n\n##### One To One\n\nOne to One 是 One to Many 或者是 Many to One 的简化版本\n\n```python\n# Many To One\nclass Parent(Base):\n    # ...\n    child_id = Column(Integer, ForeignKey('child.id'))\n    child = relationship(\"Child\", backref=backref(\"parent\", uselist=False))\n\nclass Child(Base):\n    # ...\n\n# One To Many 改 One To One\nclass Parent(Base):\n    # ...\n\nclass Child(Base):\n    # ...\n    parent_id = Column(Integer, ForeignKey('parent.id'))\n    parent = relationship(\"Parent\", backref=backref(\"child\", uselist=False))\n```\n\n##### Many To Many\n\n```python\nassociation_table = Table('association', Base.metadata,\n    Column('left_id', Integer, ForeignKey('left.id')),\n    Column('right_id', Integer, ForeignKey('right.id'))\n)\n\nclass Parent(Base):\n    # ...\n    children = relationship(\"Child\",\n                    secondary=association_table,\n                    backref=\"parents\")\n\nclass Child(Base):\n    # ...\n```\n\n注意事项\n\n执行删除 mapping 表的时候尽量这样。\n\n```bash\nmyparent.children.remove(somechild)\n```\n\n当你想干掉 somechild 的时候，会执行\n\n```\nsession.delete(somechild)\n```\n\n1. 假如 Child 没有 ref Parent 的话，Secondary Table 无删除，则无法删除。\n2. 假如 ref 了的话，则删除 secondary 里面的记录。\n3. TODO\n\n##### 邻接列表关系\n\n```python\nclass Node(Base):\n    __tablename__ = 'node'\n    id = Column(Integer, primary_key=True)\n    parent_id = Column(Integer, ForeignKey('node.id'))\n    data = Column(String(50))\n    children = relationship(\"Node\",\n                backref=backref('parent', remote_side=[id])\n            )\n```\n\n##### relationship 详解\n\n### 2.1 Query\n\n#### Create\n\n```python\nc1 = Child(name=\"苏轼\")\nsession.add(c1)\nsession.flush()\np = Parent(name=\"苏辙\")\np.best_child = c1\nfor c in [c1,c2,c3,c4]:\n    p.children.append(c)\nsession.add(c1)\nsession.commit()\n```\n\n#### Retrieve\n\n过滤\n\n```python\nfilter(**kwargs)\nfilter(Singer.name == \"周杰伦\")\nfilter(Singer.name =! \"周杰棍\")\n```\n\n##### 跨关系（跨表）查询\n\n```\nsession.query(Entry).join(Blog,Blog.entry_id == Entry.id).filter(Blog.name = \"SqlAlchemy CheatSheet\")\n```\n\n##### Limit / Offset / 分页\n\n- limit()\n- offset()\n\n##### 链式调用\n\n```python\nquery = session.query(Order) # query = session.query(Order)\nquery = query.filter(Order.name.like(f\"%name%\"))\n```\n\n##### 二进制表达式\n\n我们先 type 一下表达式，找到 eq 的类型\n\n```python\ntype(model.column_name == 'asdf') → sqlalchemy.sql.elements.BinaryExpression\n```\n\n是一个二进制表达式。\n\n```python\n# 等于\nquery.filter(User.name == 'ed')\n# 不等于\nquery.filter(User.name != 'ed')\n# Like（有的数据库不区分大小写）\nquery.filter(User.name.like('%ed%'))\n# ILIKE (case-insensitive LIKE)\nquery.filter(User.name.ilike('%ed%'))\n# IN\nquery.filter(User.name.in_(['ed', 'wendy', 'jack']))\n# Not in\nquery.filter(~User.name.in_(['ed', 'wendy', 'jack']))\n# IS NULL\nquery.filter(User.name == None)\n## 如果你用了 pep8/linter 的话\nquery.filter(User.name.is_(None))\n# IS NOT NULL:\nquery.filter(User.name != None)\n## 如果你用了 pep8/linter 的话\nquery.filter(User.name.isnot(None))\n# AND\n## use and_()\nquery.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))\n## or send multiple expressions to .filter()\nquery.filter(User.name == 'ed', User.fullname == 'Ed Jones')\n## or chain multiple filter()/filter_by() calls\nquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones')\n# OR\nquery.filter(or_(User.name == 'ed', User.name == 'wendy'))\n# MATCH\nquery.filter(User.name.match('wendy'))\n```\n\n##### 执行查询\n\n```python\nall()\nfirst()\none()\none_or_none()\nscalar()\n```\n\nYourModel.query.get((pk1, pk2))\n\n##### 比较\n\n\u003e 同一个 Session 下面，取到的某一条数据对应的 objects 应该是一样的？\n\n##### 复制 实例\n\n##### 其他\n\n```python\n# 查询的是 SomeModel 里面所有的字段 即 select *\nquery = session.query(SomeModel)\n# 查询的是 SomeModel 里面部分的字段 即 select acol, bcol\nquery = session.query(SomeModel.acol,SomeModel.bcol)\n# 即 select acol , bcol\n# alias\nuser_alias = aliased(User, name='user_alias')\nfor row in session.query(user_alias, user_alias.name).all():\n    # 即相当于 select name as name_label\n    print(row.user_alias)\n\n# limit 和 offset\nfor u in session.query(User).order_by(User.id)[1:3]:\n    print(u)\n\n# distinct\nsession.query(model.Name).distinct(model.Name.value).order_by(model.Name.value)\n# order_by\nUser.query.order_by(User.popularity.desc(),User.date_created.desc()).limit(10).all()\n```\n\n#### Update\n\n单个 object 更新\n\n```python\nblog.title = \"大宝天天见\"\nsession.add(blog)\nsession.commit()\n```\n\n批量更新\n\n```python\nsession.query.filter(Blog.content.like(\"% 敏感词 %\")).update({\n    Blog.content: \"依照相关 XX 无法查看\"\n})\n```\n\n一对多的更新\n\n```\nappend\n```\n\n#### Delete\n\nquery.delete()\n\n#### JOIN\n\nhttps://stackoverflow.com/questions/6044309/sqlalchemy-how-to-join-several-tables-by-one-query\n\n##### 两表 InnerJoin\n\n```python\nfor u, a in session.query(User, Address).\\\n                    filter(User.id==Address.user_id).\\\n                    filter(Address.email_address=='jack@google.com').\\\n                    all():\n    print(u)\n    print(a)\n# \u003cUser(name='jack', fullname='Jack Bean', password='gjffdd')\u003e\n# \u003cAddress(email_address='jack@google.com')\u003e\n\n```\n\n##### 多表 InnerJoin + LeftJoin\n\n```python\nquery.outerjoin(User.addresses)   # LEFT OUTER JOIN\n```\n\n#### 聚集查询\n\n```python\nsession.query(User).filter(User.name.like('%ed')).count()\n```\n\n```python\nfrom sqlalchemy import func\nsession.query(Table.column, func.count(Table.column)).group_by(Table.column).all()\n\nself.session.query(func.count(Table.column1),Table.column1, Table.column2).group_by(Table.column1, Table.column2).all()\n\nfrom sqlalchemy.sql import func\nsession.query(func.avg(Rating.field2).label('average')).filter(Rating.url==url_string.netloc)\n```\n\n#### 缓存机制\n\nQuery 对象，下文中，我会聊到这个 Query 对象。这里先跳过。\n\n### 2.2 原生查询\n\n```python\nfrom sqlalchemy import text\n\nsql = text('select name from penguins')\nresult = db.engine.execute(sql)\nnames = []\nfor row in result:\n    names.append(row[0])\n\nprint names\n\nfrom collections import namedtuple\n\nRecord = namedtuple('Record', result.keys())\nrecords = [Record(*r) for r in result.fetchall()]\nfor r in records:\n    print(r)\n\nfrom sqlalchemy.sql import text\n\nconnection = engine.connect()\n\n# recommended\ncmd = 'select * from Employees where EmployeeGroup == :group'\nemployeeGroup = 'Staff'\nemployees = connection.execute(text(cmd), group = employeeGroup)\n\n```\n\nget_or_create\n\n```python\ndef get_or_create(session, model, defaults=None, **kwargs):\n    instance = session.query(model).filter_by(**kwargs).first()\n    if instance:\n        return instance, False\n    else:\n        params = dict((k, v) for k, v in kwargs.iteritems() if not isinstance(v, ClauseElement))\n        params.update(defaults or {})\n        instance = model(**params)\n        session.add(instance)\n        return instance, True\n```\n\n### 2.3 更新查询\n\n```python\nsession.query(Stuff).update({Stuff.foo: Stuff.foo + 1})\n```\n\n```python\n1) for c in session.query(Stuff).all():\n       c.foo += 1\n   session.commit()\n\n2) session.query().\\\n       update({\"foo\": (Stuff.foo + 1)})\n   session.commit()\n\n3) conn = engine.connect()\n   stmt = Stuff.update().\\\n       values(Stuff.foo = (Stuff.foo + 1))\n   conn.execute(stmt)\n```\n\n```python\n1) user.no_of_logins += 1\n   session.commit()\n\n2) session.query().\\\n       filter(User.username == form.username.data).\\\n       update({\"no_of_logins\": (User.no_of_logins +1)})\n   session.commit()\n\n3) conn = engine.connect()\n   stmt = User.update().\\\n       values(no_of_logins=(User.no_of_logins + 1)).\\\n       where(User.username == form.username.data)\n   conn.execute(stmt)\n\n4) setattr(user, 'no_of_logins', user.no_of_logins+1)\n   session.commit()\n```\n\n### 2.4 删除\n\nhttps://stackoverflow.com/questions/5033547/sqlalchemy-cascade-delete\n\n#### OnDelete\n\nondelete='CASCADE'))\n\n#### 批量操作\n\nmodels.User.query.delete()\n\n### 如何从 Object 到一个 ORM\n\n如何追踪 Object 的变化？\n\n## 0x03 SQLAlchemy 的高级特性\n\n### 表继承\n\nhttps://stackoverflow.com/questions/1337095/sqlalchemy-inheritance\n\n### 啥玩意\n\nFlush 和 commit\n\nhttps://stackoverflow.com/questions/4201455/sqlalchemy-whats-the-difference-between-flush-and-commit\n\n```\nx = Foo(bar=1)\nprint x.id\n# None\nsession.add(x)\nsession.flush()\n# BEGIN\n# INSERT INTO foo (bar) VALUES(1)\n# COMMIT\nprint x.id\n```\n\n```\nqry = DBSession.query(User).filter(\n        and_(User.birthday \u003c= '1988-01-17', User.birthday \u003e= '1985-01-17'))\n```\n\n## 0x04 SQLAlchemy 的基础特性 Under The Hood\n\n### Loading 策略\n\n#### Lazy Loading\n\n#### Eager Loading\n\n```\n\u003e\u003e\u003e from sqlalchemy.dialects import postgresql\n\u003e\u003e\u003e print str(q.statement.compile(dialect=postgresql.dialect()))\nWhere q is defined as:\n\n```\n\n## 0x05 SQLAlchemy 的高级特性 Under The Hood\n\n### 多线程\n\nhttps://stackoverflow.com/questions/6297404/multi-threaded-use-of-sqlalchemy\nhttps://stackoverflow.com/questions/9619789/sqlalchemy-proper-session-handling-in-multi-thread-applications\n\n```\n\nhttps://stackoverflow.com/questions/34322471/sqlalchemy-engine-connection-and-session-difference\nhttps://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly\nhttps://stackoverflow.com/questions/12223335/sqlalchemy-creating-vs-reusing-a-session\nsession 是个容器\n\nhttps://stackoverflow.com/questions/18199053/example-of-what-sqlalchemy-can-do-and-django-orm-cannot\nhttps://stackoverflow.com/questions/7389759/memory-efficient-built-in-sqlalchemy-iterator-generator\n\n# 日志\nimport logging\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n```\n\n## 0x06 DEBUG 和 Profile 技巧\n\n```\nSQLALCHEMY_TRACK_MODIFICATIONS = False\n```\n\n### 6.1 查看技巧\n\ndict(u)\nu.**dict**\n\nhttps://stackoverflow.com/questions/1171166/how-can-i-profile-a-sqlalchemy-powered-application\n\n如果用上 Flask+SQLAlchemy 一般也要带上，Flask-Migration 与 Flask-SQLAlchemy, 这两个库也是对 Alembic 和 SQLAlchemy 的浅封装。\n\n那么，对于这个 ORM 库还有那些通用性的知识需要了解？\n\n嗯，是时候了解本质了。\n\nhttp://derrickgilland.com/posts/demystifying-flask-sqlalchemy/\n\n## 0x07 ORM 的本质\n\nORM 的本质是 Data Access Layer 上的一层封装。如果你写原生 SQL, 即手写 DAL 的话，开发效率可能会大打折扣。\n\n### ORM 的两种类型 Active Record 与 Data Mappers\n\n```\n# ActiveRecord 风格写起来类似于 Django ORM, 大致是这样的\n\n## AR 的模型定义\n\nclass User(db.models):\n    name = db.StringField(verbose=\"xyz\")\n\n## AR 的新增\nuser = User()\nuser.name = \"123456\"\nuser.save() ## 正好对应数据库中的一行\n\n## AR 的查询\n\nusers = User.objects.filter(Q(name=\"黄老板的小姨子\")).all()\n\n# Data Mappers 风格写起来类似于 SQLAlchemy ORM, 大致是这样的\n\n## SA 的定义\n\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nfrom sqlalchemy import Column, Integer, String\nclass User(Base):\n    __tablename__ = 'users'\n\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n\nBase.metadata.create_all(engine)\n\n## SA 的新增\n\nuser = User()\nuser.name = \"123456\"\nsession.add(user)\nsessoon.commit() ## 嗯？其实也是对应数据库中的一行。\n\n## SA 的查询\n\nsession.query(User).filter(User.name)\n\n```\n\n问题来了，这两者到底是什么，看起来似乎相差不大。\n\n```\nclass Person:\n\n    lastname\n    firstname\n    children\n\n    # 数据操作\n    def findone(self):\n        pass\n\n    def insert(self):\n        pass\n\n    def update(self):\n        pass\n\n    def delete(self):\n        pass\n\n    # 业务逻辑\n    def getChildrenTax(self):\n        pass\n\n```\n\nlastName firstName numberOfDependents\n\ninsert update delete\n\ngetExemption isFlaggedForAudit getTaxableEarnings\n\nAn object that wraps a row in a database table or view, encapsulates the database access, and adds domain logic on that data.\n\nThe essence of an Active Record is a Domain Model (116) in which the classes match very closely the record structure of an underlying database. Each Active Record is responsible for saving and loading to the database and also for any domain logic that acts on the data. This may be all the domain logic in the application, or you may ﬁnd that some domain logic is held in Transaction Scripts (110) with common and data-oriented code in the Active Record.\n\nThe data structure of the Active Record should exactly match that of the database: one ﬁeld in the class for each column in the table. Type the ﬁelds the way the SQL interface gives you the data—don’t do any conversion at this stage. You may consider Foreign Key Mapping (236), but you may also leave the foreign keys as they are. You can use views or tables with Active Record, although updates through views are obviously harder. Views are particularly useful for reporting purposes.\n\nobjects correspond directly to the database tables: an isomorphic schema. If your business logic is complex, you’ll soon want to use your object’s direct relationships, collections, inheritance, and so forth. These don’t map easily onto Active Record, and adding them piecemeal gets very messy. That’s what will lead you to use Data Mapper (165) instead.\n\nAnother argument against Active Record is the fact that it couples the object design to the database design. This makes it more difﬁcult to refactor either design as a project goes forward.\n\nActive Record is a good pattern to consider if you’re using Transaction Script (110) and are beginning to feel the pain of code duplication and the difﬁculty in updating scripts and tables that Transaction Script (110) often brings. In this case you can gradually start creating Active Records and then slowly refactor behavior into them. It often helps to wrap the tables as a Gateway (466) ﬁrst, and then start moving behavior so that the tables evolve to a Active Record.\n\n其实为什么不选择设计成 ActiveRecord , 而是选择设计成 Data Mapper, 其实就可以回答这个问题：\n\n\u003e 虽然要设计成 ORM, 考虑到数量和性能因素，SQL 数据库（多个表）并不应该是表现像 Object 集合那样（换言之，也就是 AR 表现的像 Object 的集合一样）。\n\u003e 同时，出于更好的抽象，object 集合也应该表现的像表以及行\n\n于是我们可以得出结论，可以在 SQLAlchemy 上面进行一定的封装，使得最后用起来非常的 Django ORM like，其实 SQLAlchemy 稍加定制还是可以很 Django ORM-like 的。\n\n:TODO: 有机会看看那本书再修改一下本小节\n\n这不，果然有人就这么搞了 https://github.com/absent1706/sqlalchemy-mixins\n\n## 0x09 踩坑集\n\n### 关系持久化坑\n\n1. Rows that point to themselves : 比如一个 insert 一个推荐自己的用户，则需要保存 id / ref_id , 但是在这个 user 插入之前，并不存在 id. 所以，一般情况下是先 insert, 然后保存 ref_id\n2. Mutually Dependent Rows\n\n### SQL 注入\n\nsession.query(MyClass).filter(\"foo={}\".format(getArgs['val']))\n\n## 0xEE 参考链接\n\n- https://www.eversql.com/django-vs-sqlalchemy-which-python-orm-is-better/\n- https://stackoverflow.com/questions/2546207/does-sqlalchemy-have-an-equivalent-of-djangos-get-or-create\n- 除了文档本身，作者在 Stack Overflow 上的回答都是非常值得阅读的。https://stackoverflow.com/users/34549/zzzeek\n- Patterns of Enterprise Application Architecture - Martin Fowler\n- http://aosabook.org/en/sqlalchemy.html\n\n  http://techspot.zzzeek.org/\n\n---\n\nChangeLog:\n\n- **2018-03-09** 重修文字\n"},{"tags":["CPython","源码解读"],"path":"20180606_CPython.md","title":"CPython 源码初步阅读笔记","slug":"CPython 源码初步阅读笔记","date":"2018-06-06","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n先挖坑，以后有机会填\n\n├── Grammar # 语法\n├── Include # C 语言头文件，如果需要自定义模块扩展 Python, 也需要这块。\n├── Modules # C 语言编写的模块，对速度要求高，比如 random\n├── Objects # 内建对象 包含整数，list,dict 等。\n├── Parser # Scanner 和 parser\n├── Python # 各种 Python 共享库\n├── Lib # Python 自带的所有标准库\n├── Doc # 文档\n├── Tools # 一些 Python 程序，方便扩展 Python\n├── Misc # 不清楚放哪，就放这里好了\n├── PC # Windows 编译姿势\n├── PCbuild # Windows 编译姿势\n├── Mac # Mac 上编译姿势\n├── Programs\n├── README.rst\n├── aclocal.m4\n├── config.guess\n├── config.sub\n├── configure\n├── configure.ac\n├── install-sh\n├── m4\n├── pyconfig.h.in\n├── setup.py\n├── LICENSE\n├── Makefile.pre.in\n\n## Ch01 Python 对象初探\n\n一切都是对象\n\n类型对象\n\n- 内置对象：int / string / dict\n- 自定义对象：class A\n\n实例对象\n\n### 1.1 Python 内的对象\n\nPython 里的对象就是 C 中结构体在堆上申请的一块内存。\n"},{"tags":["PipEnv"],"path":"20180523_PipEnv.md","title":"PyCon 2018 之 pipenv -- 未来的 Python 依赖管理工具","slug":"PyCon 2018 之 pipenv -- 未来的 Python 依赖管理工具","date":"2018-05-23","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\nPyCon 2018 有很多精彩的演讲，今天的文章里，介绍一下 K 神的演讲 『Python 未来的包管理工具 pipenv』\n\nKenneth Reitz 出品，必属精品。\n\n### Python 打包历史\n\n刚开始的时候，我们是这样安装包的。\n\n```\ncurl http://pypi.python.org/packages/alsdasdl/requests.tar.gz | tar zxf\ncd requests/\npython setup.py install\n```\n\n这个问题初看起来不是问题，但是随着你安装程序的增多就知道有多么痛苦了。\n\n1. 有的依赖库依赖别的库你怎么解决？比如 pandas 需要安装 numpy\n2. 有的依赖库依赖 c 库怎么办？比如 LXML\n3. 在 python2.6.5 下，如果我需要安装两个不同版本的 Django 开发不同的软件怎么办？难道只能动态复制文件到 site-packages 里面？\n\n后来，我们是这样安装包的。\n\n```\neasy_install requests\n```\n\n我们可以直接从 pypi 进行安装了。但尼玛，为什么 easy_install 安装很 easy, 但是没有 easy_uninstall?\n\n好，2010 年后，我们继续前进：\n\n- 可以通过 pip 替代 easy_install 了。\n- 可以通过 virtualenv 管理项目的依赖库了。虽然说，还是不能像 ruby gem 一样同时把多个版本的的软件装在同一个系统里。\n- 可以通过 requirements 锁依赖了。\n\n但，同期的其他编程语言社区分别出现了如下的包管理工具：\n\n- node -\u003e yarn \u0026\u0026 npm , 有 lockfile\n- php -\u003e composer , 有 lockfile\n- rust -\u003e cargo , 有 lockfile\n- ruby -\u003e bundler , 有 lockfile\n\n而我大 Python 居然没跟上潮流\n\n- python -\u003e pip \u0026\u0026 virtualenv/venv , 无 lockfile\n\n\u003e PS: Python3.3 之后，默认可以直接使用 venv 模块，不需要再安装 virtualenv 了。但还是需要手动，并且用起来比较反直觉。\n\n关于 requirements.txt\n\n- 如果你使用 pip freeze 来形成这个文件，则不直观，完全看不出来哪个依赖库依赖哪个依赖。\n- 如果你直接手动指定你所需要的库，比如 flask 的话，似乎又有些太直观了。\n\n如果能有一个东西，既可以表示 freeze 的结果 (what you want)，又可以表示你需要的库 (what you need). 就好了。\n\n\u003e 这当然可以考虑用两份 requirements 来解决。先安装 what you need 用来开发，然后 freeze 为 what you want 去部署。\n\n当然，铺垫了这么多 K 神肯定是来介绍他的 pipenv 的。\n\n比如说，我想查看，本项目的依赖库，直接 pipenv graph\n\n```\ncoverage==4.5.1\nfabric==2.0.1\n  - cryptography [required: \u003e=1.1, installed: 2.2.2]\n    - asn1crypto [required: \u003e=0.21.0, installed: 0.24.0]\n    - cffi [required: \u003e=1.7, installed: 1.11.5]\n      - pycparser [required: Any, installed: 2.18]\n    - idna [required: \u003e=2.1, installed: 2.6]\n    - six [required: \u003e=1.4.1, installed: 1.11.0]\n  - invoke [required: \u003c2.0,\u003e=1.0, installed: 1.0.0]\n  - paramiko [required: \u003e=2.4, installed: 2.4.1]\n    - bcrypt [required: \u003e=3.1.3, installed: 3.1.4]\n      - cffi [required: \u003e=1.1, installed: 1.11.5]\n        - pycparser [required: Any, installed: 2.18]\n      - six [required: \u003e=1.4.1, installed: 1.11.0]\n    - cryptography [required: \u003e=1.5, installed: 2.2.2]\n      - asn1crypto [required: \u003e=0.21.0, installed: 0.24.0]\n      - cffi [required: \u003e=1.7, installed: 1.11.5]\n        - pycparser [required: Any, installed: 2.18]\n      - idna [required: \u003e=2.1, installed: 2.6]\n      - six [required: \u003e=1.4.1, installed: 1.11.0]\n    - pyasn1 [required: \u003e=0.1.7, installed: 0.4.2]\n    - pynacl [required: \u003e=1.0.1, installed: 1.2.1]\n      - cffi [required: \u003e=1.4.1, installed: 1.11.5]\n        - pycparser [required: Any, installed: 2.18]\n      - six [required: Any, installed: 1.11.0]\nflake8==3.5.0\n  - mccabe [required: \u003e=0.6.0,\u003c0.7.0, installed: 0.6.1]\n  - pycodestyle [required: \u003c2.4.0,\u003e=2.0.0, installed: 2.3.1]\n  - pyflakes [required: \u003e=1.5.0,\u003c1.7.0, installed: 1.6.0]\n# 其他省略\n```\n\n如何尝鲜？我最近更新到了之前写的一个库（代码写的惨不忍赌，最近准备重构，勿喷）\n\n```\ngit clone git@github.com:twocucao/YaPyLib.git\ncd YaPyLib/\nbrew install pipenv\npipenv --three\npipenv install --dev\npipenv shell\n```\n\n记住几个命令\n\n```\npipenv --venv # 查看 venv 位置\npipenv --python 3.6.5\nexit 退出 pipenv shell\n```\n\n至于其他的功能，参考官网自己摸索吧。\n\n### FAQ 环节\n\nFAQ 环节有一个问题非常有趣，应该把 lockfile 放在 git 仓库里面吗？\n\nk 神是这么回答的 yes。 这个问题很久之前就在 issue 上回答过了\n\nhttps://github.com/pypa/pipenv/issues/598\n\n我刚开始觉得不提交会好一些，后来觉得 track 一下也无妨。\n\n## 写在最后\n\n\u003e 在用 npm 和 yarn 的时候，我有这么一个想法，希望 python 圈子里面能出一个类似于包管理工具。今年 2 月份的时候把自己的项目迁移过来，发现 pipenv 用起来很挺舒服的。\n\n\u003e pipenv 是未来。火速用上吧。\n\n\u003e 觉得有趣就点个赞或者关注下呗。\n"},{"tags":["CheatSheet"],"path":"20180203_NumpyCheatSheet.md","title":"NumPy CheatSheet","slug":"NumPy CheatSheet","date":"2018-02-03","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# Numpy 库\n\n## 0x00 前言\n\n本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Numpy 相关语句。\n\n对于数据分析应用而言，最应该关注：\n\n- 用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。\n- 常用的数组算法，如排序、唯一化、集合运算等。\n- 高效的描述统计和数据聚合 / 摘要运算。\n- 用于异构数据集的合并 / 连接运算的数据对齐和关系型数据运算。\n- 将条件逻辑表述为数组表达式（而不是带有 if-else-if 分支的循环）\n- 数据的分组运算（聚合、转换、函数应用等）。\n\n\u003e 学习 Numpy 本质上是为了更好的使用 Pandas\n\n## 0x01 ndarray\n\n### 1.1 数据类型\n\n### 1.2 创建 ndarray\n\n### 1.3 数组和标量之间的运算\n\n当我们把数组当做矢量的时候。\n\n1. 两个大小相同的矢量将运算到元素级\n2. 矢量和标量将作用与每一个元素\n3. 不同大小的矢量之间的运算叫做广播\n\n### 1.4 索引和切片\n\n### 1.4.1 一般索引和一般切片\n\n对于一维数组的话，如果没有显式 copy 则会修改原来的值。\n\n切片语法与 Python 相近\n\n### 1.4.2 切片型索引\n\n```python\na[:2,1:]\na[2,1:]\n```\n\n### 1.4.3 布尔型索引\n\n参考 pandas 语法\n\n## 0xEE 参考链接\n\n---\n\nChangeLog:\n\n- **2017-06-03** 初始化本文\n- **2018-02-03** 重修文字\n"},{"tags":["Celery","消息队列"],"path":"20180220_CeleryCheatSheet.md","title":"Celery 快速入门指北","slug":"Celery 快速入门指北","date":"2018-02-02","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n本文编写于 2018 年初，于 2019 四月进行修订，也是笔者对 Celery 的系统梳理。\n\n在我的文章如何保证 Django 项目的数据一致性中，提到了这么一个解决超卖的方案。\n\n1. 在 Redis 里面直接生成 200 个订单号\n2. 然后用户来一个取走一个订单号码\n3. 通过 Celery 削峰 排队走异步任务\n4. 最后通过数据表的 uniq 约束来防止下单超过 200 个。\n\nhttps://zhuanlan.zhihu.com/p/57668068\n\n有朋友和我讲，你这个方法是有问题的，走异步任务容易并发量太大，容易把数据库打爆。\n\n其实是可以的，Celery 可以对 Worker 的 Task 限流 (ratelimit)。\n\n## 0x01 Celery\n\n### 为什么需要 Celery\n\n在日常开发的时候，常常有一些『任务』需要处理。\n\n1. 为了提升系统的响应速度，比如发送短信 / 发送邮箱，这类的『任务』可以走异步。\n2. 为了在某个时间执行耗时操作，比如统计用户的文章 / 点赞 / 活跃度。\n3. 为了削减峰值，比如秒杀系统的削峰走异步\n4. 为了业务代码解耦，比如当我在知乎上更新文章，可能就会触发『推荐系统』,『文章管理系统』,『用户通知系统』\n\n不用 Celery 的话，其实上面的业务也是能做的。 比如 1 中，可以直接启一个线程来做。比如 2 完全可以 Crontab 做一个定时任务。\n\n那为什么要用 Celery 呢？\n\n1. 把目光聚焦在 Task 的分发上面。而非线程，Deamon 之类细节的处理。\n2. 方便，简单，易维护，高可用。\n3. 便于监控。\n4. 扩展性好。\n\n基本上满足了你九成的需求。\n\n## 0x02 Celery 快速开始\n\n本文的讨论基于 Broker 为 RabbitMQ, Result Backend 为 Redis, Django 的 Web 应用，叫做 djoo\n\n```\nsudo rabbitmqctl add_user djoo djoo\nsudo rabbitmqctl add_vhost djoo\nsudo rabbitmqctl set_user_tags djoo djoo\nsudo rabbitmqctl set_permissions -p djoo djoo \".*\" \".*\" \".*\"\n```\n\n```\nCELERY_BROKER_URL = 'amqp://djoo:djoo@localhost:5672/djoo'\n\nCELERY_RESULT_BACKEND = \"redis://{host}:{port}/1\".format(\n    host=os.getenv(\"REDIS_HOST\", \"localhost\"), port=os.getenv(\"REDIS_PORT\", \"6379\")\n)\n\n```\n\n泛读文档之后，需要搞清楚几个概念。\n\n- Broker: 携带 Task 的消息中间件，是发送消息和接收消息的解决方案，比如 RabbitMQ\n- Result Backend: Task 执行结果。\n- Application: Celery 的实例\n- Worker: 执行任务者\n- Beat: 或叫做 Schedule, 一般用于执行定时任务。\n- Task: 任务\n\n## 0x03 Celery Guide\n\n### Application\n\nApplication 可以针对整个 Celery 实例进行配置，比如配置时区，重写 Application 里的基类\n\n### Tasks\n\nTask 是一个 Class, 并且可以从任意 Callable 的对象创建。\n\nTask Message 除非被 Acked, 否则不会从队列中移除。\n\n\u003e NOTE: 那什么时候算是 Acked?\n\n```\n@app.task(name=\"xsum\")\ndef xsum(numbers):\n    return sum(numbers)\n```\n\n- Tasks\n- Calling Tasks\n- Canvas: Designing Work-flows\n- Workers Guide\n- Daemonization\n- Periodic Tasks\n- Routing Tasks\n- Monitoring and Management Guide\n- Security\n- Optimizing\n- Debugging\n- Concurrency\n- Signals\n- Testing with Celery\n- Extensions and Bootsteps\n- Configuration and defaults\n\n### Application\n\n### Tasks\n\n### Calling Tasks\n\n### Canvas: Designing Work-flows\n\n### Workers Guide\n\n### Daemonization\n\n### Periodic Tasks\n\n### Routing Tasks\n\n### Monitoring and Management Guide\n\n### Security\n\n### Optimizing\n\n### Debugging\n\n### Concurrency\n\n### Signals\n\n### Testing with Celery\n\n### Extensions and Bootsteps\n\n### Configuration and defaults\n\n## 0x03 RabbitMQ\n\n发布者的消息经过交换机，分发到不同的队列，最后由接收方进行处理。\n\n那么问题来了，交换机都是用来干嘛的\n\n- Direct 单播路由：扔一条消息到一个队列中，依照 routingkey 投递\n- Topic 多播路由：发给某几类队列（通知）.\n- Fanout 广播路由：发给全部绑定在该路由上面的队列。\n- Headers\n\n1. 应用解耦。（平台无关，语言无关）\n\n比如说，但项目足够大的时候，更新一个活动，可能需要更新用户的一些状态，可能要更新一波统计数据，可能要记录一批日志。这个时候原来的代码可能这么写：\n\n```bash\nupdate_activity()\nupdate_user()\nupdate_user_cache()\nupdate_stats()\nrecord_user_log()\n```\n\n现在代码就可能这么写：\n\n```\nsend_task_update_activity()\nsend_task_update_user()\nsend_task_update_user_cache()\nsend_task_update_stats()\nsend_task_record_user_log()\n```\n\n2. 异步通信。（减轻请求峰值）\n\n原本一个 webapp 不做异步的话，也能搞定，但做了异步之后，可以大幅度提升吞吐量和响应时间。\n\n3. 数据持久化。（不丢失消息）\n4. 送达保证。(ack late)\n\n### 简单步骤\n\n1. 定义 app, 指定 broker 和 backend\n2. 定义 tasks\n3. 指定 worker\n4. 调用 Task , 调用后返回 AsyncResult 实例，\n\n```python\nadd.delay(2, 2)\nadd.apply_async((2, 2))\nadd.apply_async((2, 2), queue='lopri', countdown=10)\nadd.signature((2, 2), countdown=10)\n\nres = add.delay(2, 2)\nres.get(timeout=1)\n\n```\n\n#### Groups\n\n```\n# 并行\ngroup(add.s(i, i) for i in xrange(10))().get()\n# [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n# partial group\ng = group(add.s(i) for i in xrange(10))\ng(10).get()\n```\n\n#### Chains\n\n```\nchain(add.s(4, 4) | mul.s(8))().get()\n(add.s(4, 4) | mul.s(8))().get()\n# partial chain\ng = chain(add.s(4) | mul.s(8))\ng(4).get()\n```\n\n#### Chords\n\n```python\nchord((add.s(i, i) for i in xrange(10)), xsum.s())().get()\n(group(add.s(i, i) for i in xrange(10)) | xsum.s())().get()\n# eg : upload_document.s(file) | group(apply_filter.s() for filter in filters)\n```\n\n## 0x07 踩坑集\n\n- 序列问题\n\n## 0xEE 参考链接\n\n---\n\nChangeLog:\n\n- **2018-02-20** 初始化\n- **2019-04-04** 重修文字\n"},{"tags":["Python"],"path":"20180123_PythonCompression.md","title":"Python 中的数据压缩和存档","slug":"Python 中的数据压缩和存档","date":"2018-01-23","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n在一次数据分析过程中，对方扔过来 40GB 的数据 -- data.tar.gz .\n\n我想着能不能直接用 pandas 直接读取这个文件呢？查找了一些资料，于是有了本文。\n\nPython 中支持如下：\n\n- 数据压缩算法：zlib, gzip, bzip2 and lzma\n- 存档格式：zip 以及 tar\n\n## 0x01 压缩是怎么回事？\n\n## 0x02 zlib 与 gzip\n\ngzip 依赖于 zlib\n\n```\n# 读取压缩文件\nimport gzip\nwith gzip.open('/home/joe/file.txt.gz', 'rb') as f:\n    file_content = f.read()\n\n# 写入压缩文件\nimport gzip\ncontent = b\"Lots of content here\"\nwith gzip.open('/home/joe/file.txt.gz', 'wb') as f:\n    f.write(content)\n\n# 拷贝压缩文件\nimport gzip\nimport shutil\nwith open('/home/joe/file.txt', 'rb') as f_in:\n    with gzip.open('/home/joe/file.txt.gz', 'wb') as f_out:\n        shutil.copyfileobj(f_in, f_out)\n\n# 压缩二进制字符串\nimport gzip\ns_in = b\"Lots of content here\"\ns_out = gzip.compress(s_in)\n```\n\n---\n\nChangeLog:\n\n- **2017-12-20** 初始化本文\n"},{"tags":["数据分析"],"path":"20171207_ANoteWithSmallMachineAndBigData.md","title":"记一次小机器的 Python 大数据分析","slug":"记一次小机器的 Python 大数据分析","date":"2017-12-07","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n机缘巧合，最近公司突然要搞一波大量数据的分析。属于客流类的分析。\n\n数据量级也还算不错，经过 gzip 压缩，接近 400 个 点位的 SQL 文件 (MySQL innoDB)，大小接近 100GB 左右，原始记录数据估测在 180 亿左右。\n\n解压后...... 差不多一个 T 吧。\n\n如果是人民币玩家，自然是直接购置几十台高配置机器，做个 mysql shard 或者直接上大数据全家桶比如 hadoop 和 hive 之类，让程序员去往死里折腾吧。\n\n\u003e 嗯，然而对于我这种非人民币玩家，就要用单机硬扛。\n\n那就硬扛呗。\n\n我手上的机器配置如下：\n\n- 局域网服务器 （ Ubuntu 16.04 LTS ）\n\n  - Xeon(R) CPU E3-1225 v5 @ 3.30GHz\n  - 16G 内存\n  - 1T 硬盘\n\n- 苹果电脑 2016 年 15 寸 最高配\n  - 1T 硬盘\n  - i7 四核\n\n## 0x01 准备数据阶段\n\n用低配机器分析大数据的**首要原则**，就是**不要分析大数据**。\n\n何也？\n\n\u003e 就是**尽可能的抽取所得结论所需分析数据的最小超集**\n\n小机器是无法完成海量计算的，但通过一定的过滤和筛选可以将数据筛选出到一台机器能扛得住的计算量。从而达到可以可以分析海量数据的目的。\n\n### 1.1 将数据导入 MySQL 中\n\n我们先不管三七二十一，既然给了 SQL 文件，肯定要入库的，那么问题来了：\n\n\u003e ~~将大象关进冰箱要几个步骤~~\n\n将数据导入数据库中需要几个步骤\n\n或者说，如何更快的导入 400 张不同表的数据。\n\n大致步骤如下：\n\n- 新增硬盘，并初始化\n- 配置 MySQL 的 datadir 到新增硬盘上\n- 导入数据 (PV \u0026 MySQL)\n\n#### 新增硬盘，并初始化\n\n首先，**购买并插入硬盘**\n\n使用 lshw 查看硬盘信息\n\n```bash\nroot@ubuntu:~# lshw -C disk\n  *-disk\n       description: SCSI Disk\n       product: My Passport 25E2\n       vendor: WD\n       physical id: 0.0.0\n       bus info: scsi@7:0.0.0\n       logical name: /dev/sdb\n       version: 4004\n       serial: WX888888HALK\n       size: 3725GiB (4TB)\n       capabilities: gpt-1.00 partitioned partitioned:gpt\n       configuration: ansiversion=6 guid=88e88888-422d-49f0-9ba9-221db75fe4b4 logicalsectorsize=512 sectorsize=4096\n  *-disk\n       description: ATA Disk\n       product: WDC WD10EZEX-08W\n       vendor: Western Digital\n       physical id: 0.0.0\n       bus info: scsi@0:0.0.0\n       logical name: /dev/sda\n       version: 1A01\n       serial: WD-WC888888888U\n       size: 931GiB (1TB)\n       capabilities: partitioned partitioned:dos\n       configuration: ansiversion=5 logicalsectorsize=512 sectorsize=4096 signature=f1b42036\n  *-cdrom\n       description: DVD reader\n       product: DVDROM DH1XXX8SH\n       vendor: PLDS\n       physical id: 0.0.0\n       bus info: scsi@5:0.0.0\n       logical name: /dev/cdrom\n       logical name: /dev/dvd\n       logical name: /dev/sr0\n       version: ML31\n       capabilities: removable audio dvd\n       configuration: ansiversion=5 status=nodisc\n```\n\n使用 fdisk 格式化硬盘，并且分区\n\n```bash\nfdisk /dev/sdb\n#输入 n\n#输入 p\n#输入 1\n#输入 w\nsudo mkfs -t ext4 /dev/sdb1\nmkdir -p /media/mynewdrive\nvim /etc/fstab\n# /dev/sdb1    /media/mynewdrive   ext4    defaults     0        2\n# 直接挂载所有，或者 reboot\nmount -a\n```\n\n至此为止，硬盘就格式化完成了。\n\n\u003e 关于安装硬盘，可以参考 https://help.ubuntu.com/community/InstallingANewHardDrive\n\n#### 配置 MySQL\n\n篇幅有限，只简介具体在 Ubuntu 16.04 上面 配置 MySQL 的 DataDIR ，省去安装和基本登录认证的配置。\n\nmysql 在 ubuntu 下面默认的路径如下：\n\n```bash\n/var/lib/mysql/\n```\n\n我们开始配置 DataDIR\n\n```bash\nsystemctl stop mysql\nrsync -av /var/lib/mysql /mnt/volume-nyc1-01\nmv /var/lib/mysql /var/lib/mysql.bak\nvim /etc/mysql/mysql.conf.d/mysqld.cnf\n# 修改至 datadir=/mnt/volume-nyc1-01/mysql\nvim /etc/apparmor.d/tunables/alias\n# alias /var/lib/mysql/ -\u003e /mnt/volume-nyc1-01/mysql/\nsudo systemctl restart apparmor\nvim /usr/share/mysql/mysql-systemd-start\n# 修改成\nif [ ! -d /var/lib/mysql ] \u0026\u0026 [ ! -L /var/lib/mysql ]; then\n echo \"MySQL data dir not found at /var/lib/mysql. Please create one.\"\n exit 1\nfi\n\nif [ ! -d /var/lib/mysql/mysql ] \u0026\u0026 [ ! -L /var/lib/mysql/mysql ]; then\n echo \"MySQL system database not found. Please run mysql_install_db tool.\"\n exit 1\nfi\n\n# 接下来\nsudo mkdir /var/lib/mysql/mysql -p\nsudo systemctl restart mysql\n\n# 最后 my.conf 修改相关文件路径\n```\n\n\u003e 详细请参考这篇文章 https://www.digitalocean.com/community/tutorials/how-to-move-a-mysql-data-directory-to-a-new-location-on-ubuntu-16-04\n\n将 DataDIR 配置完成之后，就可以导入数据了。嗯，经过这么麻烦的事情之后，我决定下次遇到这种情况首选 Docker 而不是在 Ubuntu Server 上面搞这个。\n\n\u003e 站在现在看，如果重来的话，我肯定会用 Docker 然后把数据盘挂载到新硬盘到。\n\n比如直接 Docker 命令执行\n\n```bash\ndocker run --name some-mysql -v /my/own/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag\n```\n\n#### 导入数据 之 MySQL + PV\n\n我们使用 mysql 导入脚本的时候，有几种导入方式\n\n- source 命令，然而这个命令容易在数据量很大的时候直接卡掉。（印象中是直接把 sql 文件加载到内存中，然后执行，然而，只要涉及到大量文本打印出来并且执行，速度一定会变慢很多）\n- mysql 命令\n\n```bash\n# mysql 命令的典型导入场景就是这样\nmysql -uadmin -p123456 some_db \u003c tb.sql\n```\n\n加上 PV 命令的话，比较神奇了。有进度条了！!\n\n```bash\n# 附加进度条的导入场景\npv -i 1 -p -t -e ./xxxx_probe.sql | mysql -uadmin -p123456 some_db\n```\n\n然后，可以查看一下磁盘 CPU 内存的占用情况。如果负载（着重注意 IO，内存）还不够满，使用 tmux 多开几个进程导入数据。\n\n因为每个 SQL 文件对应的表不一样，所以多开几个进程批量 insert 的话并不会锁表，这样可以显著提升导入速度。\n\n### 1.2 导出数据\n\n既然已经导入了数据，为什么需要导出数据呢？\n\n因为数据量比较大，需要进行初步清洗。而我们最后肯定使用 Pandas 进行分析，从局域网数据库中读取大量的数据的时候，pandas 速度会非常的慢（具体是因为网络传输速度？)。所以，为了后面分析省事，我批量导出了数据，然后按照我的习惯进行了归类。\n\n在这个过程中，我还进行了一小部分的数据过滤，比如：\n\n- 只选取对自己有用的行与列。\n- 化整为零，拆分数据为最小单元的 CSV 文件\n\n#### 只选取对自己有用的行与列\n\n```sql\nselect col_a , col_b from some_table where Acondition and bcondition and col_c in ('xx','yy','zz');\n```\n\n这里面有一些值得注意的地方\n\n- 尽量把简单的判断写在左边。\n- 如果不是反复查询，则没有必要建立索引。直接走全表，筛选出必要的数据存 CSV 即可。\n\n#### 尽量拆分数据为最小单元的 CSV 文件\n\n如果按照某类，某段时间进行拆分可以在分析的时候随时取随时分析那就进行拆分。\n\n比如，某个大的 CSV 包含琼瑶里面各种人物情节地点的位置就可以拆分为：\n\n```bash\n201712_大明湖畔_夏雨荷_还珠格格_你还记得吗.csv\n201711_老街_可云_情深深雨蒙蒙_谁来救我.csv\n201710_屋子里_云帆_又见一帘幽梦_你的腿不及紫菱的爱情.csv\n```\n\n当我们需要取这坨数据的时候，可以直接 glob 一下，然后 sort, 接着二分查找。就可以快速读取这块数据了。\n\n### 1.3 校验数据完备性\n\n第三方给的数据多多少少会有这些或者那些的问题，一般情况下，可以通过检查数据完备性来尽可能的减少数据的不靠谱性。\n\n我习惯性在这样的表里面详细记录数据完备性的各种参数与进度。\n\n比如：\n\n- 数据的提供情况和实际情况\n- 阶段性的记录条数和点位的统计值\n- max，min，mean，median 用来避免异常值\n- 如果是分年份，则必须要统计每一天的情况，否则也不知道数据的缺失程度。\n\n## 0x02 分析阶段\n\n经过上一步处理，数据的文件总大小大约从 1000GB (uncompressed) -\u003e 30GB 左右 （拆分成若干个文件 compressed) 。每个文件大约是几百兆。\n\n### 2.1 性能要点 1：文件系统\n\n如果统计逻辑很简单，但是数量多，首选使用读取文件。读取文件进行统计速度是非常快的。（人民币玩家走开）\n\n像 linux 里面的 wc,grep,sort,uniq 在这种场景有时候也能用到。\n\n\u003e 注意，如果文件特别大，一定要迭代器一个一个读取。\n\n对于超大文件，比如说，上百 G 文件，可以先分成小片的文件，然后多进程批量读取并且处理。\n\n### 2.2 性能要点 2：化整为零，map reduce filter\n\n化整为零这个已经在上面的 1.2 节讲过了。\n\nmap/reduce/filter 可以极大的减少代码。\n\n\u003e collection 中有个 Counter , 在进行简单代码统计的时候用起来可以极大的减少代码。\n\n### 2.3 性能要点 3：进程池的两种作用\n\n我们都知道，当 用 Python 执行计算密集的任务时，可以考虑使用多进程来加速：\n\n即**为了加速计算**，此为作用一。如下：\n\n```python\ndef per_item_calc(item):\n    df = pd.read.....\n    # complex calc\n    return result\n\nwith ProcessPoolExecutor(3) as pool:\n    result_items = pool.map(per_item_calc,all_tobe_calc_items)\n\nreduce_results = ....\n```\n\n其实进程的销毁本身就可以给我带来第二个作用**管理内存**。\n\n具体会在 2.6 中的 DataFrame 里面解释。\n\n### 2.4 性能要点 4：List 和 Set , itertools\n\n有 400 组 UUID 集合，每个列表数量在 1000000 左右，列表和列表之间重复部分并不是很大。我想拿到去重之后的所有 UUID，应该怎么处理\n\n在去重的时候，自然而然想到了使用集合来处理。\n\n最初的做法是\n\n```python\nlist_of_uuid_set = [ set1 , set2 ... set400 ]\nall_uuid_set = reduce(lambda x: x | y, list_of_uuid_set)\n```\n\n1 小时过去了。 突然之间，四下里万籁无声。公司内外聚集数百之众，竟不约而同的谁都没有出声，便有人想说话的，也为这寂静的气氛所慑，话到嘴边都缩了回去。似乎硬盘的指示灯也熄灭了，发出轻柔异常的声音。我心中忽想：\n\n\u003e ~~小师妹这时候不知在干甚么？~~ 卧槽，程序是不是又卡死了？\n\nSSH 上去 htop 一下机器。发现实存和内存都满了。直觉告诉我，CPython 的集合运算应该是挺耗内存的。\n\n嗯，这怎么行，试试用列表吧。列表占用内存应该是比较小的。\n\n```python\ndef merge(list1,list2):\n    list1.append(list2)\n    return list1\n\nlist_of_uuid_list = [ list1 , list2 ... list400 ]\nall_uuid_set = set(reduce(merge, list_of_uuid_list))\n```\n\n1 小时过去了。 我一拍大腿，道：\n\n\u003e ~~小师妹这时候不知在干甚么？~~ 卧槽，程序是不是又卡死了？\n\n最后在 StackOverFlow 上找到了更好的解决方案。\n\n```python\nlist_of_uuid_list = [ list1 , list2 ... list400 ]\nall_uuid_set = set(list(itertools.chain(*list_of_uuid_list)))\n```\n\n运行一下，5s 不到出了结果（注意，包含了 Set 去重）。\n\nitertools 里还有很多有趣的函数可以使用。\n\nhttps://docs.python.org/3/library/itertools.html\n\n### 2.5 性能要点 5：IPython 给性能带来的影响\n\n当我们在分析数据的时候，往往使用的是 IPython, 或者 Jupyter Notebook\n\n但是，方便的同时，如果不加以注意的话，就会带来一点点小问题。\n\n比如下划线和双下划线分别存储上一个 CELL 的返回值，和上上个 CELL 的返回值。\n\n### 2.6 性能要点 6：DataFrame 带来的 GC 问题\n\nDataFrame 是我用 Pandas 的原因，在这次使用 DataFrame 的过程中，还是出现一些头疼的问题的。比如莫名的内存泄露。\n\n```python\ndef per_item_calc(item):\n    df = pd.read.....\n    # complex calc\n    return result\n\nresult_items = []\nfor item in all_tobe_calc_items:\n    result_items.append(per_item_calc(item))\n\nreduce_results = ....\n```\n\n我在 For 循环中读取 DataFrame 赋值给 df, 然后统计出一个结果。按理来说，每次只要一个简单的 result, 每次读取的文件大小一致，同样的会占用接近 2G 内存，而，当我赋值 df 的时候，**按理来说，应该是把原先 df 的引用数应该为 0, 会被 gc 掉，又释放了 2G 内存**，所以，是不太可能出现内存不够用的。\n\n运行程序，内存 biubiubiubiu 的增长，当进行到约第 1000 次的循坏的时候，直到 16G 内存占满。\n\n那么显式的 del 一下会不会好一点呢？代码如下：\n\n```python\ndef per_item_calc(item):\n    df = pd.read.....\n    # complex calc\n    del df\n    return result\n```\n\n似乎好了一点点，但是其实并没有好到哪里去。\n\n然而，和前一次一样，内存 biubiubiubiu 的增长，当进行到约第 1000 次的循坏的时候，直到 16G 内存占满。\n\n只是在读取文件的时候，预先减少了上次循环没有 del 掉的 df. 和上一个想法没有太大区别。除了比上一个方法每次读取文件的提前减少了一个多 G 的内存。\n\n查找相关资料，涉及到 Python 里面的 Pandas GC 的资料并不多，稍微整理一下，如下：\n\n\u003e Python 程序 在 Linux 或者 Mac 中，哪怕是 del 这个对象，Python 依旧 ~~站着茅坑不拉屎~~ 就是不把内存还给系统，自己先占着，~~有本事你打死我啊~~ 直到进程销毁。\n\n嗯？这个和我要的东西不一样嘛？具体怎么管理 pandas 里面的 object 的，到底是哪里 GC 不到位呢？还是没有说呀。\n\n参考：\n\n- https://stackoverflow.com/questions/23183958/python-memory-management-dictionary\n- http://effbot.org/pyfaq/why-doesnt-python-release-the-memory-when-i-delete-a-large-object.htm\n\n不过有一点启示了我。\n\n\u003e 直到进程销毁。\n\nPython 里面不是有个 ProcessPoolExecutor 模块么。\n\n那么问题来了，ProcessPoolExecutor 是动态创建进程并且分配任务的呢，为每一个 item 分配一个进程来运算？还是创建完三个进程之后把 item 分配给空闲进程的进行运算呢？\n\n- 如果是前者，则是正经的进程池。似乎 map 过去，除非任务执行完毕或者异常退出，否则进程不销毁。并不能给我们解决 内存泄露 的问题。\n- 如果是后者，则是并不是线程池。\n\n你说，进程池肯定是前者咯。可是你在验证之前，这是进程池只是你的从其他语言带来的想法，这是不是一个线程池，是一个什么样子的进程池，如果进程执行过程中挂掉了，这个时候就少了一个线程，会不会再补充一个进程呢？？\n\n怎么看验证呢？\n\n1. 运行程序，进入 Htop 看进程 PID\n2. 看源码\n\n```python\n# https://github.com/python/cpython/blob/3.6/Lib/concurrent/futures/process.py#L440\ndef _adjust_process_count(self):\n    for _ in range(len(self._processes), self._max_workers):\n        p = multiprocessing.Process(\n                target=_process_worker,\n                args=(self._call_queue,\n                        self._result_queue))\n        p.start()\n        self._processes[p.pid] = p\n```\n\n从源码得出在主线程创建了管理进程的线程，管理进程的线程创建了 max_workers 个进程（在我的例子里面就只有 3 个 worker).\n\n\u003e 是个进程池。\n\n好，如果是进程池，似乎 map 过去，除非任务执行完毕或者异常退出，否则进程不销毁。并不能给我们解决 内存泄露 的问题。\n\n\u003e 等等，如果用多进程池不就好咯？\n\n```python\ndef per_item_calc(item):\n    df = pd.read.....\n    # complex calc\n    return result\n\nresult_items = []\nstep = 300\nfor idx in range(0,len(all_tobe_calc_items),step):\n    pieces_tobe_calc_items = all_tobe_calc_items[idx:idx+step]\n    with ProcessPoolExecutor(3) as pool:\n        pieces_result_items = pool.map(per_item_calc,pieces_tobe_calc_items)\n        result_items.append(pieces_result_items)\n\nreduce_results = list(itertools.chain(*result_items))\n```\n\n\u003e 当然，这是一种让操作系统帮我 GC 的方法。**即 Python 不能帮我 GC 的，操作系统帮我 GC**\n\n\u003e PS: 其实用 multiprocessing 模块也行，只是线程池可以稍微控制一下进程创建的数量。\n\n总结一下，对于大量的 DataFrame 处理：\n\n1. 多个进程池是一种处理的方式。\n2. 尽量减少 DataFrame 的数量\n3. 尽量减少赋值导致的 COPY, 修改时带上 inplace=True\n4. 读取 CSV 的时候指定相关列的类型 {‘col_a’: np.float64, ‘col_b’: np.int32}，否则 pandas 会产生大量的 object\n\n## 0xDD 番外篇\n\n在分析这次的数据过程中，自己的 Mac 主板也坏掉了，幸好还在保修期，送到苹果店维修了一下。给苹果的售后点个赞。\n\n## 0xEE 更新\n\n- **2017-12-07** 初始化本文\n- **2017-12-16** 增加分析阶段的文字\n- **2017-12-26** 去掉一些 TODO, 发布到我的小站\n- **2017-12-31** 正式发布\n"},{"tags":["Python"],"path":"20150309_图片爬虫.md","title":"Python 图片爬虫","slug":"Python 图片爬虫","date":"2017-12-01","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# Python 图片爬虫\n\n## 0x00 前言\n\n在平时抓取部分自己喜欢的资源的时候，我们常常会去下载一些比较有用的资源，比如，我比较喜欢 GEM 的照片，但是，这个东西，总不能总是去找别人要吧，那么，怎么办？\n\n很简单，我们只需要通过 Python 写一个小小的爬虫就可以解决这些问题。\n\n什么是爬虫？自己可以百度去。\n\n我这里指的爬虫是那些可以模拟浏览器的行为的小程序。\n\n比如，我要抓取 G.E.M 的相片，那么，我就想个办法。把图片的地址解析出来。然后写一个小功能下载不就好了么。\n\n\u003c!--more--\u003e\n\n虽然，话是这么说，\n\n但，怎么下手？\n\n这在写这篇文章，并且写到这里的时候，刚刚决定了抓取几个站点\n\n（刚刚百度了 邓紫棋壁纸 得到这个网站 http://www.6188.com/show/12788_1.html)\n\n## 0x01 准备工作以及爬取思路\n\nPython3,Chrome 浏览器或者 Firefox,\nPython3 基本依赖库 beautifulsoup4 lxml\n\n任务如下：\n\n1. 第一个简单案例 http://www.6188.com/show/12788_1.html\n\n2. 百度 API 解析\n\n3. 虾米照片爬取\n\n4.instagram 墙外下载 Gem 照片\n\n5. 发烧级别的 GEM 粉丝 - 虾米网 down! down! down!\n\n涉及到的知识点：\n\n1. 爬虫的最最基本思路\n2. 几个解析方法 正则解析，bs4 解析，lxml 解析\n3. 多线程使用\n\n## 0x02 6188.com 壁纸抓取 -- 关键词爬虫\n\n先说一下思路，首先，你要会点击下载按钮.(#-#)\n\n1. 访问 http://www.6188.com/show/12788_1.html\n\n2. 点击下载大图\n\n3. 看大图，手动另存为\n\n这是普通人下载图片的方式。\n\n让我们用程序员的眼光来看。\n\n浏览器呈现的具体的过程可以看我的 PyDjango 中关于计算机 Http 协议的部分。\n\n经过抓包 (http 包）分析 (chrome 的 F12), 知道，要想获取图片原始链接，有这么一个流程\n\n从 http://www.6188.com/show/12788_1.html 解析出下面链接\n\n从 http://www.6188.com/show.php?pic=/flashAll/20140211/1392111065nvjKS7.jpg 解析下面链接\n\n从 http://pic.6188.com/upload_6188s/flashAll/20140211/1392111065nvjKS7.jpg 下载图片。\n\n这样一看，非常简单明了。这就是下载一张图片的链接。\n\n同样道理，把下面的程序写成一个 for 循环，就可以直接下载 35 张图片。\n\n```html\nhttp://www.6188.com/show/12788_1.html http://www.6188.com/show/12788_2.html\nhttp://www.6188.com/show/12788_3.html ... http://www.6188.com/show/12788_35.html\n```\n\n写的应该比较容易认出\n\n```python\nimport os\nimport re\nimport requests\n\n__author__ = 'micheal'\n\nr = requests.get(\"http://www.6188.com/show/12788_1.html\")\nm = re.search(\"(/show\\.php.+jpg)\\\"\", r.text)\n\npic_url = \"http://www.6188.com\" + m.group(0)\nprint(m.group(0))\ndata = requests.get(pic_url)\nprint(data.text)\n\nm = re.search(\"src='(http://.+\\.jpg)\", data.text)\nreal_url = m.group(1)\n\ntry:\n    print(\"real_url-- 正在下载 --\"+real_url)\n    r = requests.get(real_url,stream=True)\n    fileName = \"GEM.jpg\"\n    fileFullPath = os.path.join('/home/micheal/Pictures/', fileName)\n    print(\"正在下载\" + str(data.status_code))\n    with open(fileFullPath, 'wb') as f:\n        for chunk in r.iter_content(chunk_size=1024 * 2):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n                f.flush()\n    pass\nexcept Exception:\n    print(\"出错\")\n    raise\n\nprint(\"任务完成\")\n\n```\n\n添加 For 循环，优化一下\n\n```python\nimport os\nimport re\nimport requests\n\n__author__ = 'micheal'\n\ns = requests.session() # 仿真 browser 使用一个会话\n\nfor i in range(1,30):\n    html_url = \"http://www.6188.com/show/12788_\"+str(i)+\".html\"\n    r = s.get(html_url)\n    print(\"downloading\" + html_url)\n    m = re.search(\"(/show\\.php.+jpg)\\\"\", r.text)\n\n    pic_url = \"http://www.6188.com\" + m.group(0)\n    print(m.group(0))\n    data = s.get(pic_url)\n    print(data.text)\n\n    m = re.search(\"src='(http://.+\\.jpg)\", data.text)\n    real_url = m.group(1)\n\n    try:\n        img_store_dir = \"/home/micheal/Pictures/GEM/6188\"\n        print(\"real_url-- 正在下载 --\"+real_url)\n        r = s.get(real_url,stream=True)\n        fileName = \"GEM\"+str(i)+\".jpg\"\n        if not os.path.exists(img_store_dir):\n            os.makedirs(img_store_dir)\n        fileFullPath = os.path.join(img_store_dir, fileName)\n        print(\"正在下载\" + str(data.status_code))\n        with open(fileFullPath, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=1024 * 2):\n                if chunk: # filter out keep-alive new chunks\n                    f.write(chunk)\n                    f.flush()\n        pass\n    except Exception:\n        print(\"出错\")\n        continue\n    finally:\n        pass\n\nprint(\"任务完成\")\n\n```\n\n###评价\n\n第一个小程序应该是非常容易看懂的。\n\n那么，这个程序有什么缺点呢？\n\n- 下载速度太慢，需要使用多线程，\n- 解析方法不具有通用性，这张网页中只有一个地址需要解析，所以正则表达式还是可以胜任。但是，复杂的网页肯定不行\n- 下载的图片太少了。\n\n## 0x03 百度 API 的解析 -- 关键词多线程\n\n主要就是增加了一个多线程的任务，原理什么的基本上和上面那个的相似\n\n```python\nimport json\nimport os\nfrom queue import Queue\nimport re\nimport threading\nimport requests\n\n__author__ = 'micheal'\n\nq = Queue(maxsize=0)\n# http://image.baidu.com/i?tn=resultjsonavatarnew\u0026ie=utf-8\u0026word=%E9%82%93%E7%B4%AB%E6%A3%8B\u0026cg=star\u0026pn=0\u0026rn=60\n\ns = requests.session()\n\ndef worker():\n    while True:\n        try:\n            real_url = q.get()\n            print(\"正在下载\" + real_url)\n\n            img_store_dir = \"/home/micheal/Pictures/GEM/baidu\"\n            print(\"real_url-- 正在下载 --\"+real_url)\n            r = s.get(real_url,stream=True)\n            fileName = real_url.split(\"/\")[-1]\n            if not os.path.exists(img_store_dir):\n                os.makedirs(img_store_dir)\n            fileFullPath = os.path.join(img_store_dir, fileName)\n            print(\"正在下载\" + str(r.status_code))\n            with open(fileFullPath, 'wb') as f:\n                for chunk in r.iter_content(chunk_size=1024 * 2):\n                    if chunk: # filter out keep-alive new chunks\n                        f.write(chunk)\n                        f.flush()\n            pass\n        except Exception as e:\n            print(\"出错\")\n            raise e\n            continue\n\n        finally:\n            pass\n\n        q.task_done()\n\n    pass\n\nif __name__ == \"__main__\":\n\n    for i in range(100):\n        fr = i * 60\n        to = i * 60 + 60\n        r = requests.get(\"http://image.baidu.com/i?tn=resultjsonavatarnew\u0026ie=utf-8\u0026word=%E9%82%93%E7%B4%AB%E6%A3%8B\u0026cg=star\u0026pn=\"+str(fr)+\"\u0026rn=\"+str(to)+\"\u0026itg=1\u0026z=3\u0026fr=\u0026width=0\u0026height=0\u0026lm=-1\u0026ic=0\u0026s=0\u0026st=-1\")\n        data = json.loads(r.text)\n\n        for j in range(60):\n            real_url = data['imgs'][j]['objURL']\n            print(real_url)\n            q.put(real_url)\n\n        for j in range(20):\n            t = threading.Thread(target=worker)\n            t.daemon = True\n            t.start()\n\nq.join()\n\nprint(\"任务完成\")\n\n```\n\n引入了多线程，但是抓取效果并不好，大概有 10% 左右的照片可能是有点问题的，把线程数目从 20 条调整小一些。\n\n先写到这里，明天接着写剩下来的代码。\n\n## 0x04 抓取虾米的相册 -- 反反爬虫\n\n好吧，我们将魔手伸向了虾米音乐的图片板块\n\nhttp://www.xiami.com/artist/pic-55712\n\n我们尝试使用昨天的方法获取页面。\n\n```python\nss = requests.session()\nr = ss.get(“http://www.xiami.com/artist/pic-55712?spm=0.0.0.0.IaKt5o\u0026page=3”)\nprint(r.text)\n\n```\n\n但是出现问题了，\n\n```html\n\u003c!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”\u003e\n\u003chtml\u003e\n\u003chead\u003e\u003ctitle\u003e400 Bad Request\u003c/title\u003e\u003c/head\u003e\n\u003cbody bgcolor=”white”\u003e\u003cscript\u003e\nwith(document)with(body)with(insertBefore(createElement(“script”),firstChild))setAttribute(“exparams”,”category=\u0026userid=\u0026aplus\u0026yunid=\u0026\u0026asid=AABI4v5USkJh1pUp01o=”,id=”tb-beacon-aplus”,src=(location\u003e”https”?”//s”:”//a”)+”.tbcdn.cn/s/aplus_v2.js”)\n\u003c/script\u003e\n\n\u003ch1\u003e400 Bad Request\u003c/h1\u003e\n\u003cp\u003eYour browser sent a request that this server could not understand. Sorry for the inconvenience.\u003cbr/\u003e\nPlease report this message and include the following information to us.\u003cbr/\u003e\nThank you very much!\u003c/p\u003e\n\u003ctable\u003e\n\u003ctr\u003e\n\u003ctd\u003eURL:\u003c/td\u003e\n\u003ctd\u003ehttp://www.xiami.com/artist/pic-55712?spm=0.0.0.0.IaKt5o\u0026amp;page=3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eServer:\u003c/td\u003e\n\u003ctd\u003eweb-xiami-main-030.cm10\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDate:\u003c/td\u003e\n\u003ctd\u003e2015/03/10 20:23:36\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n\u003chr/\u003ePowered by Tengine\u003c/body\u003e\n\u003c/html\u003e\n\nProcess finished with exit code 0\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\u003c/p\u003e\u003c/h\u003e\n\u003c/script\u003e\u003c/title\u003e\u003c/head\u003e\n\u003c/html\u003e\n```\n\n我们前面使用的代码都是爬取一些没有做太多防止爬虫的网站，但是，我们今天准备爬取的是一个有防护措施的网站。\n\n没办法，修改一下 headers, 然后继续访问即可。\n\n## 0xEE 更新\n\n---\n\nChangeLog:\n\n- **2017-12-19** 重修文字\n"},{"tags":["Python"],"path":"20150317_扇贝背单词小助手.md","title":"背单词小助手","slug":"背单词小助手","date":"2017-12-01","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# 背单词小助手\n\n## 0x01 本文内容\n\n### 思路\n\n- 英文单词的处理\n- shanbay 单词本的提交\n\n### 英文单词的处理\n\n正则表达式进行提取，然后通过 Python 的自然语言处理工具 ntlk 进行单词原型的转换\n\n### shanbay 单词的处理\n\n由于使用了传说中的 requests，使得代码简洁程度大大提升。\n\n\u003c!--more--\u003e\n\n### 代码如下\n\n英文单词处理模块\n\nshanbay 登录以及单词的提交\n\n这是 v0.1 版本，有不少细节需要调整。有时间我会继续更新\n代码 9 逻辑比较简单，自己阅读代码吧\n\n[请来 github 这里](https://github.com/twocucao/PyTools)\n\n```python\nimport os\nimport re\n\n__author__ = 'micheal'\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\n## 常量设置\n\nBOOKS_FOLDER = \"Books/\"\n\nOUTPUTS_FOLDER = \"OutPuts/\"\n\nCOVER_FILE = \"cover.jpg\"\n\nEXCLUDED_LIB_FILE = \"excluded_libs.txt\"\n\nSUMMARY_FILE = \"SUMMARY.json\"\n\nALL_LIB_FILE = \"all.txt\"\n\n### 初始化数据，\n# 创建 ALLFile\ndef createMergeFile():\n    fo = open(ALL_LIB_FILE, 'w')\n    for name in os.listdir(BOOKS_FOLDER):\n        fi = open(BOOKS_FOLDER + name, \"r\")\n        while True:\n            s = fi.read(16 * 1024)\n            if not s:\n                break\n            fo.write(s)\n        fi.close()\n    fo.close()\n\n    pass\n\ndef get_sorted_words_list_from(txt_path):\n    with open(txt_path, \"r\") as f:\n        strs = f.read()\n        s = re.findall(\"\\w+\", str.lower(strs), flags=re.ASCII)\n\n    ss = []\n    for item in s:\n        ss.append(lemmatizer.lemmatize(item))\n\n    l = sorted(list(set(ss)))\n    ll = []\n\n    for i in l:\n        m = re.search(\"\\d+\", i)\n        n = re.search(\"\\W+\", i, flags=re.ASCII)\n        if not m and not n and len(i) \u003e 4:\n            ll.append(i)\n            # 不属于数字也不属于非（英文 + 数字）并且字母长度大于 4 的集合\n\n    return ll\n\ndef WordCountInit():\n    createMergeFile()\n\n    excluded_words = get_sorted_words_list_from(\"excluded_libs.txt\")\n\n    file = {}\n\n    folder_list = os.listdir(BOOKS_FOLDER)\n\n    for item in folder_list:\n        file[item] = get_sorted_words_list_from(BOOKS_FOLDER + item)\n\n        words = file[item]\n\n        real_words = []\n\n        for word in words:\n            if word not in excluded_words:\n                real_words.append(word)\n\n        # print(\"excluded_words\\n\"+str(excluded_words))\n\n        print(\"real_words\\n\" + str(real_words))\n\n        excluded_words.extend(file[item])\n        with open(OUTPUTS_FOLDER + item, \"w\") as f:\n            f.write(str(sorted(list(real_words))))\n\n    return True\n\n    # print(file)\n\n```\n\n```python\nfrom datetime import datetime\nimport json\nimport os\nimport requests\nfrom WordsCount import get_sorted_words_list_from, WordCountInit\n\n__author__ = 'micheal'\n\nword_book_url = \"http://www.shanbay.com/wordbook/99004/\"\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\nclass ShanBay:\n    # 初始化 shanbay 的基本信息\n    # 1. 登录，\n\n    # 2，创建 wordbook\n    # 3，创建 wordlist，\n    # 4，用集合填充 wordlist\n    # 5，填充策略\n    #\n\n    def __init__(self):\n        print(\"基本数据正在初始化\")\n        WordCountInit()\n        print(\"初始化完毕\")\n\n        self.headers = {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\",\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n            \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n            \"Accept-Language\": \"en-US,en;q=0.5\",\n            \"Accept-Encoding\": \"gzip, deflate\",\n            \"Connection\": \"keep-alive\",\n            \"Cache-Control\": \"max-age=0\",\n        }\n\n        self.index_url = \"http://www.shanbay.com/\"\n\n        self.login_url = \"http://www.shanbay.com/accounts/login/\"\n\n        self.sb_session = requests.Session()\n        self.sb_session.headers.update(self.headers)\n        self.sb_session.get(self.login_url)\n        # 开始登录\n        # 初始化登录\n\n        print(\"正在登录中\")\n        self.doLogin(\"test\", \"test\")\n\n        print(\"单词书  情况如下 \\n\")\n        with open(\"SUMMARY.json\", \"r\") as f:\n            decodejson = json.loads(f.read())\n            self.book_info_title = decodejson[\"title\"]\n            self.book_info_category = decodejson[\"category\"]\n            self.book_info_description = decodejson[\"description\"]\n            self.book_info_price = decodejson[\"price\"]\n            print(\n                \"标题：\" + self.book_info_title + \"\\n 类型：\" + self.book_info_category + \"\\n 描述：\" + self.book_info_description + \"\\n 价格：\" + self.book_info_price)\n\n        self.createWordBook()\n\n        ## 判断有多少个路进然后接着进行一系列的操作\n        word_list_list = os.listdir(\"Books/\")\n        for word_list in word_list_list:\n            print(\"正在创建\" + word_list)\n\n            dt = datetime.now()\n\n            list_id = self.createWordList(self.word_book_id, \"List\" + dt.strftime('%Y%m%d%H%M%S'),\n                                          \"这仅仅是一个比较简单的描述\" + dt.strftime('%Y%m%d%H%M%S'))\n\n            self.fillWordListById(list_id, get_sorted_words_list_from(\"OutPuts/\" + word_list))\n\n            # print(self.sb_session.get(self.index_url).text)\n\n    def doLogin(self, username, password):\n        self.login_form = {\n            \"csrfmiddlewaretoken\": self.sb_session.cookies[\"csrftoken\"],\n            \"username\": username,\n            \"password\": password,\n        }\n\n        self.sb_session.post(self.login_url, self.login_form)\n\n        return True\n\n    def fillWordListById(self, _id, words):\n        # \"172981\"\n        for word in words:\n            post_data = {\n                \"id\": _id,\n                \"word\": word,\n            }\n            self.sb_session.post(\"http://www.shanbay.com/api/v1/wordlist/vocabulary/\", post_data)\n\n        return 0\n\n    def createWordBook(self):\n        # http://www.shanbay.com/wordbook/create/basicinfo/\n\n        createWordBookForm = {\n            \"csrfmiddlewaretoken\": self.sb_session.cookies[\"csrftoken\"],\n            \"title\": self.book_info_title,\n            \"category\": self.book_info_category,\n            \"description\": self.book_info_description,\n            \"price\": self.book_info_price,\n        }\n\n        t = self.sb_session.post(\"http://www.shanbay.com/wordbook/create/basicinfo/\", createWordBookForm)\n        self.word_book_id = str(t.url).split(\"/\")[-3]\n\n        # 封面没有办法提交...... 以后再说\n        coverFiles = {\n            \"csrfmiddlewaretoken\": self.sb_session.cookies[\"csrftoken\"],\n            \"cover\": ('cover.jpg', open('cover.jpg', 'rb'), 'image/jpeg', {'Expires': '0'}),\n            \"wordbook_id\": self.word_book_id,\n            \"description\": self.book_info_description,\n        }\n        # files = {'file': ('report.xls', open('report.xls', 'rb'), 'application/vnd.ms-excel', {'Expires': '0'})}\n\n        self.sb_session.post(\"http://www.shanbay.com/wordbook/create/\" + self.word_book_id + \"/uploadcover/\",\n                             files=coverFiles)\n\n        return True\n\n    def doMenu(self):\n        # while True:\n        #\n        # print(\"\"\"\\\n        #\n        # 请输入相关操作：\n        # 1.createWordBook\n        # 2.createWordList\n        #\n        #\n        #     \"\"\")\n        #     self.word_book_id = input(\"word_book_id\")\n        #\n        #\n        #\n\n        pass\n\n    def createWordList(self, _id, name, desc):\n        createWordListFrom = {\n            \"name\": name,\n            \"description\": desc,\n            \"wordbook_id\": _id,\n\n        }\n        r = self.sb_session.post(\"http://www.shanbay.com/api/v1/wordbook/wordlist/\", createWordListFrom)\n        return (json.loads(r.text)[\"data\"][\"wordlist\"][\"id\"])\n\n        pass\n\nsss = ShanBay()\n\n```\n\n这个程序还是比较简单的。\n\n---\n\nChangeLog:\n\n- **2020-11-30** 重修文字\n"},{"tags":["Python"],"path":"20171120_PythonClosureAndScopes.md","title":"Python 中的作用域准则","slug":"Python 中的作用域准则","date":"2017-11-20","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n因为最早用的是 Java 和 C#，写 Python 的时候自然也把 Python 作用域的想的和原有的一致。\n\nPython 的作用域变量遵循在大部分情况下是一致的，但也有例外的情况。\n\n本文着通过遇到的一个作用域的小问题来说说 Python 的作用域\n\n\u003c!-- more --\u003e\n\n## 0x01 作用域的几个实例\n\nPython 的作用域变量遵循在大部分情况下与其他语言一致，但也有例外的情况。比如：\n\n### 1.1 第一个例子\n\n作用域第一版代码如下\n\n```python\na = 1\nprint(a, id(a)) # 打印 1 4465620064\ndef func1():\n    print(a, id(a))\nfunc1()  # 打印 1 4465620064\n```\n\n作用域第一版对应字节码如下\n\n```\n  4           0 LOAD_GLOBAL              0 (print)\n              3 LOAD_GLOBAL              1 (a)\n              6 LOAD_GLOBAL              2 (id)\n              9 LOAD_GLOBAL              1 (a)\n             12 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             15 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\n             18 POP_TOP\n             19 LOAD_CONST               0 (None)\n             22 RETURN_VALUE\n```\n\n\u003e PS: 行 4 表示 代码行数 0 / 3 / 9 ... 不知道是啥，我就先管他叫做**条**吧 是 load global\n\u003e PPS: 注意条 3/6 LOAD_GLOBAL 为从全局变量中加载\n\n顺手附上本文需要着重理解的几个指令\n\n    LOAD_GLOBA          : Loads the global named co_names[namei] onto the stack.\n    LOAD_FAST(var_num)  : Pushes a reference to the local co_varnames[var_num] onto the stack.\n    STORE_FAST(var_num) : Stores TOS into the local co_varnames[var_num].\n\n这点似乎挺符合我们认知的，那么，再深一点呢？既然这个变量是可以 Load 进来的就可以修改咯？\n\n### 1.2 第二个例子\n\n然而并不是，我们看作用域第二版对应代码如下\n\n```python\na = 1\nprint(a, id(a)) # 打印 1 4465620064\ndef func2():\n    a = 2\n    print(a, id(a))\nfunc2() # 打印 2 4465620096\n```\n\n一看，WTF, 两个 a 内存值不一样。证明这两个变量是完全两个变量。\n\n作用域第二版对应字节码如下\n\n```\n  4           0 LOAD_CONST               1 (2)\n              3 STORE_FAST               0 (a)\n\n  5           6 LOAD_GLOBAL              0 (print)\n              9 LOAD_FAST                0 (a)\n             12 LOAD_GLOBAL              1 (id)\n             15 LOAD_FAST                0 (a)\n             18 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             21 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\n             24 POP_TOP\n             25 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n```\n\n\u003e 注意行 4 条 3 (STORE_FAST) 以及行 5 条 9/15 (LOAD_FAST)\n\n这说明了这里的 a 并不是 LOAD_GLOBAL 而来，而是从该函数的作用域 LOAD_FAST 而来。\n\n### 1.3 第三个例子\n\n那我们在函数体重修改一下 a 值看看。\n\n```python\na = 1\ndef func3():\n    print(a, id(a)) # 注释掉此行不影响结论\n    a += 1\n    print(a, id(a))\nfunc3() # 当调用到这里的时候 local variable 'a' referenced before assignment\n# 即 a += 1 =\u003e a = a + 1 这里的第二个 a 报错鸟\n```\n\n```\n  3           0 LOAD_GLOBAL              0 (print)\n              3 LOAD_FAST                0 (a)\n              6 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n              9 POP_TOP\n\n  4          10 LOAD_FAST                0 (a)\n             13 LOAD_CONST               1 (1)\n             16 BINARY_ADD\n             17 STORE_FAST               0 (a)\n\n  5          20 LOAD_GLOBAL              0 (print)\n             23 LOAD_FAST                0 (a)\n             26 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             29 POP_TOP\n             30 LOAD_CONST               0 (None)\n             33 RETURN_VALUE\n```\n\n那么，func3 也就自然而言由于没有无法 LOAD_FAST 对应的 a 变量，则报了引用错误。\n\n然后问题来了，a 为基本类型的时候是这样的。如果引用类型呢？我们直接仿照 func3 的实例把 a 改成 list 类型。如下\n\n### 1.4 第四个例子\n\n```python\na = [1]\ndef func4():\n    print(a, id(a)) # 这条注不注释掉都一样\n    a += 1 # 这里我故意写错 按理来说应该是 a.append(1)\n    print(a, id(a))\nfunc4()\n\n# 当调用到这里的时候 local variable 'a' referenced before assignment\n```\n\n╮(╯▽╰)╭ 看来事情那么简单，结果变量 a 依旧是无法修改。\n\n可按理来说跟应该报下面的错误呀\n\n```\n'int' object is not iterable\n```\n\n### 1.5 第五个例子\n\n```python\na = [1]\ndef func5():\n    print(a, id(a))\n    a.append(1)\n    print(a, id(a))\nfunc5()\n# [1] 4500243208\n# [1, 1] 4500243208\n```\n\n这下可以修改了。看一下字节码。\n\n```\n  3           0 LOAD_GLOBAL              0 (print)\n              3 LOAD_GLOBAL              1 (a)\n              6 LOAD_GLOBAL              2 (id)\n              9 LOAD_GLOBAL              1 (a)\n             12 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             15 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\n             18 POP_TOP\n\n  4          19 LOAD_GLOBAL              1 (a)\n             22 LOAD_ATTR                3 (append)\n             25 LOAD_CONST               1 (1)\n             28 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             31 POP_TOP\n\n  5          32 LOAD_GLOBAL              0 (print)\n             35 LOAD_GLOBAL              1 (a)\n             38 LOAD_GLOBAL              2 (id)\n             41 LOAD_GLOBAL              1 (a)\n             44 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             47 CALL_FUNCTION            2 (2 positional, 0 keyword pair)\n             50 POP_TOP\n             51 LOAD_CONST               0 (None)\n             54 RETURN_VALUE\n```\n\n从全局拿来 a 变量，执行 append 方法。\n\n## 0x02 作用域准则以及本地赋值准则\n\n### 2.1 作用域准则\n\n看来这是解释器遵循了某种变量查找的法则，似乎就只能从原理上而不是在 CPython 的实现上解释这个问题了。\n\n查找了一些资料，发现 Python 解释器在依据 基于 LEGB 准则 （顺手吐槽一下不是 LGBT）\n\nLEGB 指的变量查找遵循\n\n- Local\n- Enclosing-function locals\n- Global\n- Built-In\n\nStackOverFlow 上 martineau 提供了一个不错的例子用来说明\n\n```python\nx = 100\nprint(\"1. Global x:\", x)\nclass Test(object):\n    y = x\n    print(\"2. Enclosed y:\", y)\n    x = x + 1\n    print(\"3. Enclosed x:\", x)\n\n    def method(self):\n        print(\"4. Enclosed self.x\", self.x)\n        print(\"5. Global x\", x)\n        try:\n            print(y)\n        except NameError as e:\n            print(\"6.\", e)\n\n    def method_local_ref(self):\n        try:\n            print(x)\n        except UnboundLocalError as e:\n            print(\"7.\", e)\n        x = 200 # causing 7 because has same name\n        print(\"8. Local x\", x)\n\ninst = Test()\ninst.method()\ninst.method_local_ref()\n```\n\n我们试着用变量查找准则去解释 **第一个例子** 的时候，是解释的通的。\n\n第二个例子，发现函数体内的 a 变量已经不是那个 a 变量了。要是按照这个查找原则的话，似乎有点说不通了。\n\n但当解释第三个例子的时候，就完全说不通了。\n\n```python\na = 1\ndef func3():\n    print(a, id(a)) # 注释掉此行不影响结论\n    a += 1\n    print(a, id(a))\nfunc3() # 当调用到这里的时候 local variable 'a' referenced before assignment\n# 即 a += 1 =\u003e a = a + 1 这里的第二个 a 报错鸟\n```\n\n按照我的猜想，这里的代码执行可能有两种情况：\n\n- 当代码执行到第三行的时候可能是向从 local 找 a, 发现没有，再找 Enclosing-function 发现没有，最后应该在 Global 里面找到才是。注释掉第三行的时候也是同理。\n- 当代码执行到第三行的时候可能是向下从 local 找 a, 发现有，然后代码执行，结束。\n\n但如果真的和我的想法接近的话，这两种情况都可以执行，除了变量作用域之外还是有一些其他的考量。我把这个叫做**本地赋值准则** （拍脑袋起的名称）\n\n一般我们管这种考量叫做 ~~Python 作者就是觉得这种编码方式好你爱写不写~~ Python 作者对于变量作用域的权衡。\n\n事实上，当解释器编译函数体为字节码的时候，如果是一个赋值操作 (list.append 之流不是赋值操作），则会被限定这个变量认为是一个 local 变量。如果在 local 中找不到，并不向上查找，就报引用错误。\n\n    这不是 BUG\n    这不是 BUG\n    这不是 BUG\n\n这是一种设计权衡 Python 认为 虽然不强求强制声明类型，但假定被赋值的变量是一个 Local 变量。这样减少避免动态语言比如 JavaScript 动不动就修改掉了全局变量的坑。\n\n这也就解释了第四个例子中赋值操作报错，以及第五个例子 append 为什么可以正常执行。\n\n如果我偏要勉强呢？ 可以通过 global 和 nonlocal 来 引入模块级变量 or 上一级变量。\n\n\u003e PS: JS 也开始使用 let 进行声明，小箭头函数内部赋值查找变量也是向上查找。\n\n## 0xEE 参考链接\n\n- [Martineau 的例子](https://stackoverflow.com/questions/291978/short-description-of-the-scoping-rules)\n\n---\n\nChangeLog:\n\n- **2017-11-20** 从原有笔记中抽取本文整理而成\n"},{"tags":["Python"],"path":"20170804_RethinkingInPython.md","title":"ReThinking In Python","slug":"ReThinking In Python","date":"2017-08-04","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n本文诞生于利用 Topic Reading 方法读 Python 和 JavaScript 若干本技术书籍这个过程中结合自己的开发常见场景记录下来的一些笔记。\n\n## 0x01 Python 胡论\n\n### Why Python\n\n是要用一门编程语言无非是两种原因：\n\n- 这门技术很火，能挣钱\n- 写起来很舒服，开发效率高\n\n这也是我在涉猎了很多编程语言为什么选择了 Python 和 TypeScript 作为自己的主要技能树。\n\nPython 具备这两点，TS （更加准确的说是 JavaScript）具备前一点。\n\nPython 写起来真的特别舒服，语法简洁，第三方库丰富，而且也比较火。\n\n有什么东西比，写代码效率高、生态圈好还重要了。\n\n生态圈好，比如\n\n- Web 开发用 Django/Flask\n- 数据抓取用 Requests\n- 数据分析清洗用 Pandas\n- 机器学习 Tensorflow SCIPY\n\n\u003c!-- more --\u003e\n\n### 工具链\n\n[Pythonista 的工具集](./ch04/s03_Pythonista_的工具集.md)\n\n### 文档\n\n### 社区\n\n### 书籍\n\n## 0x02 基础概念\n\n### 2.1 数据类型\n\n#### 常量\n\n```\nFalse\nTrue\nNone\nNotImplemented\nElilipsis ...\n```\n\n##### 布尔\n\n布尔常量\n\n```\nNone\nFalse\n0 0.0 0j\n'' () []\n{}\n一个对象 __bool__() = False , 如果上一个为 True 则__len__()\n```\n\n布尔运算符\n\n```\nx or y\nx and y\nnot x\n```\n\n布尔比较值\n\n```\n# 可以定制\n\u003c \u003c= \u003e= \u003e == !=\n# 无法定制\nis / is not\n```\n\n##### 字符串\n\n五种 format 方式\n\n1. 古代 %\n2. 近代 format\n3. 现代 f 字符串\n4. 内置的 template\n5. jinja2 的模板\n\n#### 数字类型\n\n- int\n- float\n- complex\n\n##### 操作符\n\n```\n+ - * / // % -n +n abs() int() float()\ncomplex(re,im)\nc.conjugate()\ndivmod(x,y)\npow(x,y) x ** y\nmath.trunc(x)\nmath.round(x[,n])\nmath.floor(x) \u003c=x\nmath.ceil(x)  \u003e=x\n| ^ \u0026 \u003c\u003c \u003e\u003e ~x\n```\n\n注意\n\n```\n(-1) / 2 # -1\n1 / (-2) # -1\n```\n\n##### 数值哈希\n\n// TODO : 麻蛋居然没看懂 4.4.4. Hashing of numeric types\n\n#### 迭代器类型\n\n迭代器类型\n\n#### 序列类型\n\nC 实现的按照 item 是否为同一类型分为：\n\n- **Container sequences**: list, tuple, and collections.deque can hold items of different types.\n- **Flat sequences**: str, bytes, bytearray, memoryview, and array.array hold items of one type.\n\nC 实现按照 item 是否可修改分为：\n\n- **Mutable sequences**: list, bytearray, array.array, collections.deque, and memoryview\n- **Immutable sequences**: tuple, str, and bytes\n\n##### 通用序列操作\n\n```bash\nx in s\nx not in s\ns + t\ns * n 或者 n * s\ns[i]\ns[i:j]\ns[i:j:s]\nlen(s)\nmin(s)\nmax(s)\ns.index(x,i,j)\ns.count(x)\n// TODO 封装 deepEqual\n```\n\n切片\n\n为何 Slice 和 Range 会排除 最后一个 Item?\n\n书中讲的太复杂，其实这个和尺子是一个作用，尺子从 0 刻度开始，这样方便丈量。\n\n比如说：\n\n- items[0:10] 为 10 厘米\n- items[10] 为 10 刻度后一个单位，即 items[10:11]\n- items[2:] 为 2 刻度后面若干个单位\n- items[::3] 以三为单位，从 0 刻度开始，最后为结尾，每三个\n\n```python\na[i, j] # 调用 a.__getitem__((i, j))\n```\n\n##### 不可变序列\n\n- 解包赋值\n- 不要手贱加逗号\n- 下划线可以用作临时变量 （但是 django 中下划线用于中英文）\n\n```python\na, b, *rest = range(5) # (0, 1, [2, 3, 4])\na, b, *rest = range(3) # (0, 1, [2])\na, b, *rest = range(2) # (0, 1, [])\n\na, *body, c, d = range(5) # (0, [1, 2], 3, 4)\n*head, b, c, d = range(5) # ([0, 1], 2, 3, 4)\n```\n\n- namedtuple\n\n```python\nCity = namedtuple('City', 'name country population coordinates')\ntokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))\ntokyo.population\ntokyo.coordinates\ntokyo[1]\nCity._fields # tuple\n```\n\n##### 可变序列\n\n```\ns[i] = x\ns[i:j] = t\ndel s[i:j]\ns[i:j:k] = t\ndel s[i:j:k]\ns.append(x)\ns.clear()\ns.copy()\ns.extend(t) 或者 s += t\n\n```\n\n##### List Comprehensions and Generator Expressions\n\n```python\nnew_items = [func(a) for item in items]\nnew_items = [ str(x) for x in range(100) if x % 2 == 0]\nnew_items = list(map(str,list(filter(lambda x: x % 2 == 0 , list(range(100))))))\n# 可写成\nnew_items = list(map(str,filter(lambda x: x % 2 == 0 , range(100))))\n```\n\nlist 往往和 map filter 以及 listcomp 用于创建简单的序列\n\n##### 序列赋值\n\n```python\n对于不可变类型 赋值 l *= 2 在内存中则是创建了新的两个长度的元祖，然后赋值\n而由于字符串则需要注意，str_a += \"str b\" , 虽然为不可变变量，但并不需要拷贝整个字符串（特殊情况）, 但字符串的拼接建议还是\"\".join()\n\nt = (1, 2, [30, 40])\nt[2] += [50, 60]\n# 结果为既赋值成功，又报错\n# 但 t[2].extend([50, 60]) 可以赋值成功\nimport dis\ndis.dis('s[a] += b') # 可以查看字节码\n```\n\n1. 尽量不要在不可变变量内保存可变变量\n2. t[2] += [50,60] 并不是原子操作，因为，当做了一半的时候，抛出的错误。\n\n##### objs.sort 与 sorted()\n\n对于 sort 和 sorted 来说，reverse 代表 desc,key 为单参数用于计算每一个值的结果的函数。\nlist.sort 直接针对列表排序，并且返回 None（出于编程习惯的问题，直接返回 None 的函数大多是对程序有一定的修改）\n\n##### 二分搜索\n\n```python\nimport bisect\nbisect -\u003e bisect_right\nbisect_left\ninsort -\u003e insort_left\ninsort_right\n# 搜索可以用来划分档次\ndef grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):\n    i = bisect.bisect(breakpoints, score)\n    return grades[i]\n\n[grade(score) for score in [33, 99, 77, 70, 89, 90, 100]] # ['F', 'A', 'C', 'C', 'B', 'A', 'A']\n```\n\n##### 列表\n\nlist 是一种 mix-typed 的数据结构，即可以存放不同种类型的数据结构，由此带来的问题自然是性能问题：\n\n- list 第一是 mix-typed 的数据结构\n- 动态数组，并非数组\n\n当考虑性能的时候，则需要考虑是不是要换一个更好的数据结构：\n\n- 适用于类型单一的 array\n- 增删比较多，或者需要使用 FIFO,LIFO, 则使用 deque (double-ended queue)\n\n```python\n# Arrays\nfloats = array('d', (random() for i in range(10**7)))\n# NumPy and SciPy\n\n# Deques and Other Queue\n```\n\n##### Queue 与 Deque\n\n- Deque\n- queue 线程安全 Queue, LifoQueue, and PriorityQueue\n- multiprocessing Queue 和 JoinableQueue\n- asyncio Queue, LifoQueue, PriorityQueue, and JoinableQueue\n\n### 2.2 语句\n\n语句\n\n### 2.3 函数\n\n#### 参数\n\n#### 闭包与作用域\n\n本部分具备一定文字量，故单独抽取出来到文章，请参考 Python 中的闭包和作用域。\n\n#### 高阶函数\n\n- map\n- reduce\n- filter\n\n#### 特殊方法\n\n```python\nobj.__len__()\nlen()\n\nobj.__\n```\n\n对于内置类型 (list, str , bytearray) 解释器在调用特殊方法的时候调用 C 库，比如 CPython 实现的 len 方法一般直接会调用 PyVarObject C Struct ob_size\n\n特殊方法往往并不是显示调用，而是被隐式调用。比如 init 在 new 中的作用，比如 for item in items 世界上会调用 iter(items), 这也会隐式调用 items.**iter**() .\n\n一般当大量使用特殊方法的时候，都是在进行元编程。\n\n```python\nbool(x) 先调用 x.__bool__() , 如果 x.__bool__() 没有实现，则调用 x.__len__(), 如果为 0 则返回 False\nsorted(arr) 可以直接返回 arr，arr.sort() 是排序内部。\n```\n\n特殊方法名 （有操作符）\n\n| 种类                            | 方法名                                             |\n| ------------------------------- | -------------------------------------------------- |\n| String/Bytes                    | repr , str , format , bytes                        |\n| Conversion to number            | abs , bool , complex , init , float , hash , index |\n| Emulating collections           | len , getitem , setitem , delitem , contains       |\n| Iteration                       | iter, reversed , next                              |\n| Emulating callables             | call                                               |\n| Context management              | enter, exit                                        |\n| Instance creation \u0026 destruction | new , init , del                                   |\n| Attribute management            | getattr , getattribute , setattr , delattr, dir    |\n| Attribute descriptors           | get , set ,delete                                  |\n| Class service                   | prepare , instancecheck , subclasscheck            |\n\n特殊方法名 （无操作符）\n\n| 种类                           | 方法名                                                              |\n| ------------------------------ | ------------------------------------------------------------------- |\n| Unary numeric operators        | neg , pos , abs                                                     |\n| Rich comparison operators      | lt , le , eq , ne , gt , ge                                         |\n| Arithmetic operators           | add ,sub , mul ,truediv ,floordiv ,mod , divmod , pow , round round |\n| Reversed arithmetic operators  | radd , rsub , rmul , rtruediv, rfloordiv , rmod , rdivmod, rpow     |\n| Augmented assignment mathmatic | iadd , isub , imul , itruediv, ifloordiv                            |\n| Bitwise operators              | invert , lshift , rshift , and , or                                 |\n| Reversed bitwise operators     | rlshift , rrshift , rand , rxor , ror                               |\n| Augmented assignment bitwise   | ilshift , irshift , iand , ixor , ior                               |\n\nWhy len Is Not a Method\n\n```python\n因为对 不同类型并不是一定调用 __len__ , 对于基本类型查看 c struct 中长度，对于其他类型直接调用 __len__ , 这种区分对待\n```\n\n### 2.4 生成器\n\n```python\ndef gen():\n    yield 1\n    yield 2\n    yield 3\n    # 这里为了省事，标记 123, 但是一般会有个循环，或者多个循环\n\ngen # \u003cfunction __main__.gen\u003e\n# 显式调用，返回方法对象\ng = gen() # \u003cgenerator object gen at 0x10ec23dc0\u003e\nnext(g)\nnext(g)\nnext(g)\nnext(g) # 执行到结尾部分或者其他报错 StopIteration\n\nfor i in gen():\n    print(i)\n```\n\n生成器的作用就在于将遍历 lazy 化。嗯？其实编写代码的时候完全不中写生成器也可以 lazy 化很多操作。\n\n需要注意的是，generator 后面支持了一个方法叫做 send(), 是 next() 的升级版本。将原来的数据的单向流通变成了双向流通。\n\n见 [协程](#423-协程)\n\n## 0x03 中级概念\n\n### 类和对象\n\n包含元编程\n\n### 模块与包\n\n#### 单下划线与双下划线\n\n```\n前缀单下划线 _var # 在类中被认为是私有变量，在模块中可以通过 amodule._func() 来使用，但是没有办法 from xx.amodule import * 然后调用。\n后缀单下划线 var_ # 一般用于表示被占用的关键字 比如 default_ int_ class_ object_\n前缀双下划线 __var # 放在类中的话，实例化的时候会被转成'_A__size', 这个解释器进行的操作叫做 name mangling\n\nIn [13]: class A:\n    ...:     def __init__(self):\n    ...:         self.__eq__ = 2\n    ...:         self.__size = 34\n    ...:         self.__size__ = 44\n\n前后双下划线 __var__\n单下划线 _\n```\n\n### 错误 / 调试测试\n\n### IO 编程\n\n### 正则表达式\n\n```python\n. ^ $ * + ? { } [ ] \\ | ( )\n\nRegular String\n\n\"ab*\"\n\"\\\\\\\\section\"\n\"\\\\w+\\\\s+\\\\1\"\n\nRaw string\n\nr\"ab*\"\nr\"\\\\section\"\nr\"\\w+\\s+\\1\"\n```\n\n## 0x04 高级概念\n\n### 元编程\n\n#### 装饰器\n\n```\nenforcing access control and authentication\ninstrumentation and timing functions\nrate-limiting\ncaching, and more”\n```\n\n#### Dynamic Attributes and Properties\n\n```python\nobj.attr\n\n重写__getattr__\n\n// TODO: 什么时候完成 python 的 DICT 以及 JSON 的相等？\n\naccessor?\n__new__ 是一个 class method, 但是并没有 xxx\n\nx = Foo('a')\n\ndef object_maker(the_class, some_arg):\n    new_object = the_class.__new__(some_arg)\n    if isinstance(new_object, the_class):\n        the_class.__init__(new_object, some_arg)\n    return new_object\n\nx = object_maker(Foo,'a')\n```\n\n#### Attributes Descriptors\n\n```python\n@property\n\n__class__ # 接近 type()\n__dict__\n__slot__\n\ndir(obj) # 与__dict__接近\ngetattr\nsetattr\nhasattr\n\n```\n\n#### Class MetaProgramming\n\n### 并发编程\n\n#### GIL - Global Interpreter Lock\n\n并不是所有的解释器语言都有 GIL （尽管 Python 和 Ruby 里面都有）, 也并不是没有尝试过去除 GIL, 但是每次去除都会导致单线程性能的下降。所以暂时保留。\n\nGIL 对程序中的影响：\n\n\u003e 一个线程运行 Python , 而其他 N 个睡眠或者等待 I/O - **同一时刻只有一个线程对共享资源进行存取** , Python 线程也可以等待 threading.Lock 或者线程模块中的其他同步对象；\n\n##### 协同式多任务处理\n\n如果有两个线程，同时进行 IO 请求，当其中一个线程连接之后，立即会**主动让出 GIL**, 其他线程就可以运行。\n\n\u003e 当 N 个线程在网络 I/O 堵塞，或等待重新获取 GIL，而一个线程运行 Python。\n\n让出之后还要执行代码呀，所以要有个收回 GIL 的动作。\n\n##### 抢占式多任务处理\n\nPython 2 GIL , 尝试收回 GIL 为 执行 1000 字节码。\nPython 3 GIL , 尝试收回 GIL 检测间隔为 15ms\n\n##### 线程安全\n\n原子操作：sort 之类不需要\n非原子操作：n=n+2 的字节码分为 加载 n , 加载 2 , 相加，存储 n, 四个步骤，由于不是原子性，很可能被由于 15 ms 而被打断。\n\n当然，懒人一向是 : **优先级不决加括号，线程不决加 lock**\n\n对于 Java, 程序员努力在尽可能短的时间内加锁存取共享数据，减轻线程的争夺，实现最大并行。但 Python 中，线程无法并行运行，细粒度的锁就没有了优势。\n\n#### 多线程\n\n\u003e Python 多线程约等于并发。\n\n#### 多进程\n\n#### 协程\n\nPython 中，协程在语法上接近于生成器（函数内包含 yield 关键字）.\n\n```python\n# 生成器\ndef g():\n    yield a\n    pass\n```\n\n```python\n# 协程\ndef c():\n    # b = yield a\n    b = yield\n    pass\n```\n\n协程在\n\n## 0x05 标准库与第三方库\n\n### 数据结构与算法\n\n### 字符串与文本\n\n### 数字日期与时间\n\n### 迭代器与生成器\n\n1. Introduction\n2. Built-in Functions\n3. Built-in Constants\n4. Built-in Types\n5. Built-in Exceptions\n6. Text Processing Services\n7. Binary Data Services\n8. Data Types\n9. Numeric and Mathematical Modules\n10. Functional Programming Modules\n11. File and Directory Access\n12. Data Persistence\n13. Data Compression and Archiving\n14. File Formats\n15. Cryptographic Services\n16. Generic Operating System Services\n17. Concurrent Execution\n18. Interprocess Communication and Networking\n19. Internet Data Handling\n20. Structured Markup Processing Tools\n21. Internet Protocols and Support\n22. Multimedia Services\n23. Internationalization\n24. Program Frameworks\n25. Graphical User Interfaces with Tk\n26. Development Tools\n27. Debugging and Profiling\n28. Software Packaging and Distribution\n29. Python Runtime Services\n30. Custom Python Interpreters\n31. Importing Modules\n32. Python Language Services\n33. Miscellaneous Services\n34. MS Windows Specific Services\n35. Unix Specific Services\n36. Superseded Modules\n37. Undocumented Modules\n\n## 0xAA 测试\n\n### 单元测试\n\n单元测试我只用 pytest\n\n1. 给对象打补丁\n2. 测试异常情况\n3. 测试输出到日志文件\n\n```\npytest --pdb\npytest --tb=long    # exhaustive, informative traceback formatting\n```\n\n## 0xBB 调试技巧\n\n### IPython\n\n### IPdb\n\n## 0xCC 优化技巧\n\n```\ncProfile\n```\n\n### 统计型优化\n\nhttps://github.com/what-studio/profiling\n\n## 0xDD 代码质量\n\n### 社区推崇的代码风格 Pythonic\n\n```\n    The Zen of Python, by Tim Peters\n\n    Beautiful is better than ugly.\n    Explicit is better than implicit.\n    Simple is better than complex.\n    Complex is better than complicated.\n    Flat is better than nested.\n    Sparse is better than dense.\n    Readability counts.\n    Special cases aren't special enough to break the rules.\n    Although practicality beats purity.\n    Errors should never pass silently.\n    Unless explicitly silenced.\n    In the face of ambiguity, refuse the temptation to guess.\n    There should be one-- and preferably only one --obvious way to do it.\n    Although that way may not be obvious at first unless you're Dutch.\n    Now is better than never.\n    Although never is often better than *right* now.\n    If the implementation is hard to explain, it's a bad idea.\n    If the implementation is easy to explain, it may be a good idea.\n    Namespaces are one honking great idea -- let's do more of those!\n```\n\n### Python 代码质量\n\n```\nhttps://github.com/ambv/black\n```\n\n#### 正确性\n\n- 外部**不该**引用 protected member （单下划线）\n- lambda 为一次使用，最好不要赋值。\n- 不要给 buildin 函数赋值\n- py3 直接 super()\n- for in else 如果不内置 break 则出会在最后 for in 为 empty 的时候再执行 else 中的语句\n- context exit 如果不 catch 掉异常让其自然向上一级抛出错误的话，必须为 (self, exception_type, exception_value, traceback):\n- 不要在 init 里面 return 数据\n- 不要混用 tab 和 space\n- 4 个 space 缩进\n- staticmethod 直接是 参数，classmethod 第一个参数为 cls\n- 可变的 default value 是不能作为 参数的。（可能是解释器在确定函数的定义的时候完成赋值？)\n- 遵循 exception hierachy https://docs.python.org/3/library/exceptions.html#exception-hierarchy\n- defaultdict defaultdict(lambda : 6) , 必须 callable\n- 尽量 unpack 赋值\n- 字典用获取用 get(\"myk\",None) , 赋值用 dictionary.setdefault(\"list\", []).append(\"list_item\")\n\n#### 可维护性\n\n- 避免使用 import \\* , 我觉得这点值得商榷 , 如果是某个模块下，完全可以先把模块拆分成多个，最后 import 进来，接着使用 all.\n- getxxx 获取实际值，如果不为实际值，返回 None 显然不如 try catch 来的实在。\n- 避免使用 global\n- 命名要注意\n- 动态创建方法 , 我觉得这点值得商榷。\n\n#### 可读性\n\n- 不要检查，如果可能有异常，尽量抛出异常来 trycatch 解决。\n- a is None , if flag\n- isinstance , not type(r) is types.ListType\n- \"{name}{city}\".format(\\*\\*info_dict)\n- for k , v in infodict.items()\n- 使用 poiinfo = namedtuple(\"poiinfo\",[\"name\",\"lng\",\"lat\"]) 返回 poiinfo['上海',121.00,23] 最后返回值打印 poi.name , poi.lng , poi lat\n- for numbers_value, letters_value in zip(numbers, letters):\n- enumerate\n- 如果能用 listcomp 则不使用 map 和 filter\n\n#### 性能\n\n- 用 set\n- d.iteritems() 比 items() 省内存\n\n## 0xEE 文章更新\n\n- **2017-05-11 19:43:00** : 增加代码质量模块\n- **2017-08-04 19:43:00** : 增加部分 Fluent Python 的笔记\n"},{"tags":["数据分析"],"path":"20170603_PandasCheatSheet.md","title":"Pandas CheatSheet","slug":"Pandas CheatSheet","date":"2017-06-03","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x00 前言\n\n本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Pandas 相关语句。\n\n主要包含：\n\n- Pandas 中 Series 的一些常见操作和技巧\n- Pandas 中 Dateframe 的一些常见操作和技巧\n- Python 里的可视化技巧\n- Pandas 使用过程中的一些细节\n\n不定期更新。\n\n\u003c!-- more --\u003e\n\n\u003e SQL 是一种面向集合的处理工具 / 语言\n\u003e Pandas 是一种面向数组的处理工具\n\n\u003e **而一般处理 pandas 的数据往往以二维表的形式存在。所以，可以类比为更加强大的 SQL 语言。**\n\n而依据 Pandas 的作者之言，牛逼的 Pandas 使用者必须要精通 numpy; 当然，关于 Numpy, 留待之后开一篇文章做笔记好了。\n\n## 0x01 Series 相关\n\nSeries 接近于 ndarray 的用法，区别仅仅在于会带上 label 而已\n\n\u003e 关于 ndarray, 请参考 我的另一篇文章 Numpy Cheatsheet\n\n## 0x02 DataFrame 相关\n\n### 2.1 对象创建\n\n```python\n\n# 1. 内存变量转 Dataframe\n## 1.1. 通过二位矩阵 , index , columns\ndates = pd.date_range('20130101', periods=6)\npd = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n## 1.2. 通过字典 Key 为 Column , Value 为 list,timestamp,np.array,value\ndf2 = pd.DataFrame({ 'A' : 1.,\n                     'B' : pd.Timestamp('20130102'),\n                     'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n                     'D' : np.array([3] * 4,dtype='int32'),\n                     'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n                     'F' : 'foo' })\n# 长度无需统一，会自动填充\n\n# 2. 从文件中读取\npd.read_excel(\"./data_set.xlsx\",index_col=False) # 关掉 Index\n\n# 3. 合并多个同样的 DataFrame\ndf_items = [df_item1,df_item2,...]\ndf = pd.concat(df_items).drop_duplicates()\ndf.merge(data_set_df, left_on=\"lno\", right_on=\"rno\", how=\"outer\")\n\n# 4.series to dataframe\ndf = s.to_frame()\n\n```\n\n选择数据\nGetting\nSelection by Label\nSelection by Position\nBoolean Indexing\nSetting\n缺失数据\n数据操作\nOperations\nStats\nApply\nHistogramming\nString Methods\n数据合并\nConcat\nJoin\nAppend\nGrouping\nReshaping\nStack\nPivot Tables\nTime Series\nCategoricals\nPlotting\n\n### 2.2 浏览数据\n\n```python\n# 1. 查看表结构\n\ndf.head()\ndf.tail(3)\ndf.index\n# df.index = ['日期','小时']\ndf.columns\ndf.columns = map(str.lower, df.columns)\n\ndf.values\n\ndf['col'] = df['col'].astype(str).convert_objects(convert_numeric=True)\n\n# 2. 删除 col_name\n\ndf.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')\n\ndel df['cola']\n\n# 3. 修改元数据\ndf.rename(columns=lambda x: x.split('.')[-1], inplace=True)\ndf.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\ndf.rename(columns = {0: 'cola', 1: 'colb', 2: 'colc'}, inplace=True)\n\n# 2.\n## 2. 遍历\nfor index, row in df.iterrows():\n    print row[\"c1\"], row[\"c2\"]\nfor row in df.itertuples(index=True, name='Pandas'):\n    print getattr(row, \"c1\"), getattr(row, \"c2\")\n= IF([@price] \u003c 1, \"未知\",IF([@price] \u003c 30000, \"三万以下\", IF([@price] \u003c= 50000, \"三万到五万\", IF([@price] \u003c= 100000, \"五万到十万\", IF([@price] \u003c= 10000000, \"十万以上\", \"其他\")))))\n```\n\n### 2.3 修改表内容\n\n```python\ndf.drop_duplicates(['col_a','col_b'])\n```\n\n### 2.4 查看表内容\n\n```python\n# 选择\ndf['A'] # 列选\ndf[0:30] # 行选\ndf['20130102':'20130104'] # 行选\ndf.loc['20130102':'20130104',['A','B']] # by label\ndf.loc[condition,['cola','colb']]\ndf.loc[['ri01','ri02'] , [\"cola\",\"colb\",\"colc\"]]\n\ndf.iloc[1:5, 2:4] # by position\ndf.iloc[: , 0:7] # 全部列，0-7 索引\n\ndf.ix[['ri02', 'ri09']] # 选取行\n\ntotal_rows=len(df.axes[0])\ntotal_cols=len(df.axes[1])\n\ndf.sample(3000) # 随机抽取 3000 行，可以用于快速验证算法\n\ncriterion = df2['a'].map(lambda x: x.startswith('t'))\ndf2[criterion]\n\ndf2[[x.startswith('t') for x in df2['a']]]\n# select * from df limit 5\ndf.head()\n# select a,b,c from df\ndf[['a','b','c']].head()\n# select a,b,c from df where a = 11 and b = 'xx'\ndf[ ( df['a'] == 11) \u0026 ( df['b'] == 'xx') ][['a','b','c']]\ndf['a'].value_counts()\n\n# SELECT * FROM df ORDER BY a DESC LIMIT 10 OFFSET 5;\ndf.nlargest(10+5, columns='a').tail(10)\n\ndf.column.str[0:2]\ndf.column_name.str.len()\ntwo_groups = '(?P\u003cletter\u003e[a-z])(?P\u003cdigit\u003e[0-9])'\ns.str.extract(two_groups, expand=True)\n\n# 排序\n\ndf.sort_index(axis=1, ascending=False)\ndf.sort_values(by='B')\ndf = df.sort(['col1','col2','col3'],ascending=[1,1,0])\n#\n\n# window function\n# SELECT a, b, c, rank() OVER (PARTITION BY a ORDER BY b DESC) as rn FROM df;\n# 如果没有这个 window function 的话，可以 groupby 一下，然后生成表和原有表进行 JOIN\ntips.assign(rn=tips.sort_values(['b'], ascending=False).groupby(['a']).cumcount() + 1)\n\n# Top N rows per group\n# rank 代表等级 如果两人并列第一名，则不存在第二名，直接是第三名 , row_number 代表排名，即即便两个人分数一样，也无法并列第一名\n\n# PostGRESQL's ROW_NUMBER() analytic function\nSELECT * FROM (\n  SELECT\n    t.*,\n    ROW_NUMBER() OVER(PARTITION BY day ORDER BY total_bill DESC) AS rn\n  FROM tips t\n) tt\nWHERE rn \u003c 3\nORDER BY day, rn;\n\n(tips.assign(rn=tips.sort_values(['total_bill'], ascending=False)\n                    .groupby(['day'])\n                    .cumcount() + 1)\n     .query('rn \u003c 3')\n     .sort_values(['day','rn'])\n)\n\n(tips.assign(rnk=tips.groupby(['day'])['total_bill']\n                     .rank(method='first', ascending=False))\n     .query('rnk \u003c 3')\n     .sort_values(['day','rnk'])\n)\n\n# PostGRESQL's RANK() analytic function\nSELECT * FROM (\n  SELECT\n    t.*,\n    RANK() OVER(PARTITION BY sex ORDER BY tip) AS rnk\n  FROM tips t\n  WHERE tip \u003c 2\n)\nWHERE rnk \u003c 3\nORDER BY sex, rnk;\n\n(tips[tips['tip'] \u003c 2]\n     .assign(rnk_min=tips.groupby(['sex'])['tip']\n                         .rank(method='min'))\n     .query('rnk_min \u003c 3')\n     .sort_values(['sex','rnk_min'])\n)\n\n# where 语句\ndf['a'].isnull()\ndf['a'].isin(arr)\n\n# groupby\ndf.groupby('a').size() # 计算 a\ndf.groupby('a')['b'].count() # 同上计算 a\ndf.groupby('a').count() # 计算所有 cols\nagg_fun_dict = {'tip': np.mean, 'day': np.size}\nagg_fun_dict_new = {'tip': [np.mean, np.size]}\ndf.groupby('a')[['b','c']].agg(agg_fun_dict)\ndf.groupby('a')['b'].describe()\ndf.age.agg(['min', 'max'])\ndf.applymap(multiply_10_for_every_int) #\n\ncalc_groups = df.groupby([date])\ncalc_groups['id_aa'].nunique().reset_index().to_excel(\"123.xlsx\")\n\n# pivot\npd.pivot_table(data=df,values='value_col', index='A_FROM', columns='B_TO', aggfunc=lambda x: len(x.unique()),margins=True)\n\n# CONCAT\nappend\n# JOIN\npd.merge(df1, df2, on='key', how='outer')\n\n# UPDATE tips SET tip = tip*2 WHERE tip \u003c 2;\ntips.loc[tips['tip'] \u003c 2, 'tip'] *= 2\n\n# TODO:\n```\n\n### 2.5 表变换\n\n```python\n# apply , apply map\nDataFrame.apply operates on entire rows or columns at a time.\nDataFrame.applymap, Series.apply, and Series.map operate on one element at time.\n```\n\n### 2.6 表遍历\n\n```python\ndf.iterrows()\ndf.itertuples()\n```\n\n## 数据导入导出\n\n### SQL\n\n```python\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine.url import URL\nDATABASE = {\n    'drivername': 'postgres',\n    'host': 'localhost',\n    'port': '5432',\n    'username': 'yourusername',\n    'password': 'yourpass',\n    'database': 'yourdb'\n}\n# 这里并不建议直接写数据库连接字符串，而是使用 URL 函数，这样可以避免转义字符带来的坑，比如 @ 在数据库连接字符串是 %40\nengine = create_engine(URL(**DATABASE))\n\n# 读一整张表\nwith engine.connect() as conn, conn.begin():\n    data = pd.read_sql_table('yourtablehere', conn)\n    processyourdata(data)\n\n# 按照 SQL 语句来读\nwith engine.connect() as conn, conn.begin():\n    data = pd.read_sql(\"\"\"\n    yoursqlquery\n    \"\"\", conn)\n    processyourdata(data)\n```\n\n### CSV\n\n日常数据处理用 CSV 的比较多，因为这种格式语法简洁，类二维表，读写速度快，而且配合 gzip 压缩解压。\n\npandas 在 windows 上好像不能读取中文路径？\n\n而且，pandas 读取的时候要注意指定编码。因为在日常导出 CSV 的时往往使用的是 utf-8, 而 windows 默认打开文本文件时候使用的是 gbk\n\nread_csv 有几十个参数，挑几个说一下：\n\n- sep 可以指定分隔符，默认为',', 但有的人导出的数据以 tab 为空格。\n- dtype 可以指定某些列的值类型为 int,float 的类型从而减少 object 的创建 , 但是对 str/object 没有什么暖用\n- parse_dates 可以指定 date 列\n- header 如果 CSV 没有 Header, 可以指定为 None\n- usecols 可以指定几列，相当于数据库中的 SELECT a_col,b_col\n\n其中还有一些比较有趣的东西，比如说，iterator=True\n值得注意的是，通过\n\n### Excel\n\nGotchas\n\n## 0x02 可视化技术\n\n```python\n# 绘制\ndf.plot(kind='bar')\n\nplt.xlabel('xlable')\nplt.ylabel('ylable')\nplt.title('title name')\n\nplt.show()\n\ndf['数量'].plot(kind='bar')\n\n# 批量创建图\ng = sns.FacetGrid(customers, col=\"cola\")\ng.map(plt.scatter, \"数量\", \"单位\", alpha=1)\ng.add_legend();\n\nttbill = sns.distplot(tips[\"总价格\"]);\nttbill.set(xlabel = '价值', ylabel = '频率', title = \"标题名\")\nsns.despine()\n\nsns.jointplot(x =\"total_bill\", y =\"tip\", data = tips)\n# https://github.com/guipsamora/pandas_exercises/blob/master/07_Visualization/Tips/Exercises_with_code_and_solutions.ipynb\n\nplt.pie(\n    [100,300],\n    labels = ['男', '女'],\n    shadow = False,\n    colors = ['blue','red'],\n    explode = (0.15 , 0),\n    startangle = 90,\n    autopct = '%1.1f%%'\n    )\nplt.axis('equal')\nplt.title(\"男女比例\")\nplt.tight_layout()\nplt.show()\n```\n\n## 0x03 asd1\n\n## 0x07 Performance Tips\n\n最近遇到了数据量比较大的数据处理，数据条数差不多在 3 千万条。加载到内存中大约 1GB.\n\n### 7.1 精简行列\n\n1. 读入 dataframe 的时候就排除多余的行列。\n2. Merge 时候需要精简行列。\n\n```python\ndf1.merge(df2[list('xab')])\npandas.merge(dataframe1, dataframe2.iloc[:, [0:5]], how='left', on='key')\n```\n\n### 7.2 大文件的处理\n\n\u003e 参考我的文章 记一次小机器的 Python 大数据分析\n\n## 0x 踩坑集合\n\n## 0x08 踩坑集合\n\n### 8.1 IO 类\n\n####\n\n### 8.2 IO 类\n\n## 0xEE 参考链接\n\n---\n\nChangeLog:\n\n- **2017-06-03** 初始化本文\n- **2018-02-03** 重修文字\n"},{"tags":["Python"],"path":"20170408_ThinkingInPython.md","title":"Thinking In Python Language","slug":"Thinking In Python Language","date":"2017-04-08","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n## 0x01 前言\n\n\u003e Python 简略笔记\n\n本文诞生于利用 Topic Reading 方法读 Python 和 JavaScript 若干本技术书籍这个过程中结合自己的开发常见场景记录下来的一些笔记。\n\n\u003c!-- more --\u003e\n\n## 0x00 简介\n\n### 1. 为什么是 Python\n\n选 Python, 很大程度上是因为 Python 的快速开发。\n\n当然，快速开发（这里的开发包含部署）这个词也往往会被误解。什么叫做快速？我用一个 CMS 框架快速搭建出一个网站这是否叫做快速？\n\n- 每一次部署的时候，如果使用 Java 或者是 Go, 部署的时候直接 maven 编译打包，接着把 War 包直接上传到 Tomcat 就结束了。而用 Python 则需要各种虚拟环境，各种稀里哗啦的配置。这种情况下是哪一种快速呢？\n\nPython 有什么好处呢？\n\n- 写代码效率高\n- 生态圈好\n\n写代码效率高，这指的是写 Python 代码，而不是运行时。\n\n生态圈好，Web 开发用 Django/Flask , 数据抓取用 Requests , 数据分析清洗用 Pandas, 机器学习。\n\n### 2. 工具链\n\n### 4. 文档\n\n### 5. 社区\n\n### 6. 书籍\n\n## 0x01 基本概念\n\n\u003e 程序 = 算法 + 数据结构\n\n这句话当然是不全面的，但并不影响这句话在计算机世界里面的地位。\n\n依我看来，对我的启发大致是：\n\n\u003e 我会把 API 的调用和数据结构以及算法想清楚，然后才动手把代码分解成伪代码。\n\n### 1. 数据类型\n\n数据类型按照不同的划分标准可以进行不同的划分：\n\n按照复杂性可以这么划分：\n\n- 简单类型\n- 复杂类型\n\n按照复杂性可以这么划分：\n\n- 基本类型\n- 引用类型\n\n按照数据结构可以这么划分：\n\n- 集合结构 : 串\n- 线性结构 : 线性表 （单链表，静态链表，循环链表，双向链表，**栈，队列**)\n- 树形结构 : 树（二叉树，B+ 树，红黑树）\n- 图形结构 : 图\n\n### 2. 操作\n\n#### 操作\n\n对于一些基本的数据类型，操作为 加减乘除取余数位运算等等\n\n对于复杂的一些数据类型，则需要对数据结构多一些了解。\n\n比如，对队列而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？\n比如，对 hash 而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？\n比如，对字典而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？\n比如，对字符串而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？\n\n那字符串来说，Java 推荐使用 StringBuilder 来合并多个字符串，Python 推荐 join 多个字符串等等。\n\n#### 操作\n\n### 3. 语句\n\n## 0x02 中级概念\n\n### 函数\n\n#### 作用域\n\n### 模块\n\n模块，这个概念，可大可小，大的时候，把一个程序说成是模块，小的时候，可以把一个文件，甚至你说这一个函数是一个模块，也行。\n\n这里的模块指的是一个包下的函数。\n\n### 面向对象\n\n面向对象有三大概念：\n\n- 封装\n- 继承\n- 多态\n\n### 错误 / 调试测试\n\n异常处理实际上可以考验一个程序员编写代码的健壮性。\n\n事实上来说，代码写的健壮是一个程序员必备的素养。但其实在开发过程中，出于对项目进行赶工上线，需要对程序的健壮性做出一定的取舍。并且，在编写客户端，服务端，网页前端的时候基本上都会遇到这个问题。什么时候选择健壮的程序，什么时候选择是还可以的程序。需要自己的经验。\n\n### IO 编程\n\n### 进程和线程\n\n#### 多线程\n\n\u003e Python 多线程约等于并发。\n\n#### 多进程\n\n#### GIL\n\nGlobal Interpreter Lock\n\n并不是所有的解释器语言都有 GIL （尽管 Python 和 Ruby 里面都有）, 也并不是没有尝试过去除 GIL, 但是每次去除都会导致单线程性能的下降。所以暂时保留。\n\nGIL 对程序中的影响：\n\n\u003e 一个线程运行 Python , 而其他 N 个睡眠或者等待 I/O - **同一时刻只有一个线程对共享资源进行存取** , Python 线程也可以等待 threading.Lock 或者线程模块中的其他同步对象；\n\n##### 协同式多任务处理\n\n如果有两个线程，同时进行 IO 请求，当其中一个线程连接之后，立即会**主动让出 GIL**, 其他线程就可以运行。\n\n\u003e 当 N 个线程在网络 I/O 堵塞，或等待重新获取 GIL，而一个线程运行 Python。\n\n让出之后还要执行代码呀，所以要有个收回 GIL 的动作。\n\n##### 抢占式多任务处理\n\nPython 2 GIL , 尝试收回 GIL 为 执行 1000 字节码。\nPython 3 GIL , 尝试收回 GIL 检测间隔为 15ms\n\n##### 线程安全\n\n原子操作：sort 之类不需要\n非原子操作：n=n+2 的字节码分为 加载 n , 加载 2 , 相加，存储 n, 四个步骤，由于不是原子性，很可能被由于 15 ms 而被打断。\n\n当然，懒人一向是 : **优先级不决加括号，线程不决加 lock**\n\n对于 Java, 程序员努力在尽可能短的时间内加锁存取共享数据，减轻线程的争夺，实现最大并行。但 Python 中，线程无法并行运行，细粒度的锁就没有了优势。\n\n### 正则表达式\n\n## 0x03 高级技巧\n\n## 0x04 标准库\n\n### 常用内建模块\n\n### 系统化模块\n\n1. Introduction\n2. Built-in Functions\n3. Built-in Constants\n4. Built-in Types\n5. Built-in Exceptions\n6. Text Processing Services\n7. Binary Data Services\n8. Data Types\n9. Numeric and Mathematical Modules\n10. Functional Programming Modules\n11. File and Directory Access\n12. Data Persistence\n13. Data Compression and Archiving\n14. File Formats\n15. Cryptographic Services\n16. Generic Operating System Services\n17. Concurrent Execution\n18. Interprocess Communication and Networking\n19. Internet Data Handling\n20. Structured Markup Processing Tools\n21. Internet Protocols and Support\n22. Multimedia Services\n23. Internationalization\n24. Program Frameworks\n25. Graphical User Interfaces with Tk\n26. Development Tools\n27. Debugging and Profiling\n28. Software Packaging and Distribution\n29. Python Runtime Services\n30. Custom Python Interpreters\n31. Importing Modules\n32. Python Language Services\n33. Miscellaneous Services\n34. MS Windows Specific Services\n35. Unix Specific Services\n36. Superseded Modules\n37. Undocumented Modules\n\n## 0x05 第三方库\n\n- Requests : API 人性化\n\n## 0x06 代码质量\n\n### 正确性\n\n- 外部**不该**引用 protected member （单下划线）\n- lambda 为一次使用，最好不要赋值。\n- 不要给 buildin 函数赋值\n- py3 直接 super()\n- for in else 如果不内置 break 则出会在最后 for in 为 empty 的时候再执行 else 中的语句\n- context exit 如果不 catch 掉异常让其自然向上一级抛出错误的话，必须为 (self, exception_type, exception_value, traceback):\n- 不要在 init 里面 return 数据\n- 不要混用 tab 和 space\n- 4 个 space 缩进\n- staticmethod 直接是 参数，classmethod 第一个参数为 cls\n- 可变的 default value 是不能作为 参数的。（可能是解释器在确定函数的定义的时候完成赋值？)\n- 遵循 exception hierachy https://docs.python.org/3/library/exceptions.html#exception-hierarchy\n- defaultdict defaultdict(lambda : 6) , 必须 callable\n- 尽量 unpack 赋值\n- 字典用获取用 get(\"myk\",None) , 赋值用 dictionary.setdefault(\"list\", []).append(\"list_item\")\n\n### 可维护性\n\n- 避免使用 import \\* , 我觉得这点值得商榷 , 如果是某个模块下，完全可以先把模块拆分成多个，最后 import 进来，接着使用 all.\n- getxxx 获取实际值，如果不为实际值，返回 None 显然不如 try catch 来的实在。\n- 避免使用 global\n- 命名要注意\n- 动态创建方法 , 我觉得这点值得商榷。\n\n### 可读性\n\n- 不要检查，如果可能有异常，尽量抛出异常来 trycatch 解决。\n- a is None , if flag\n- isinstance , not type(r) is types.ListType\n- \"{name}{city}\".format(\\*\\*info_dict)\n- for k , v in infodict.items()\n- 使用 poiinfo = namedtuple(\"poiinfo\",[\"name\",\"lng\",\"lat\"]) 返回 poiinfo['上海',121.00,23] 最后返回值打印 poi.name , poi.lng , poi lat\n- for numbers_value, letters_value in zip(numbers, letters):\n- enumerate\n- 如果能用 listcomp 则不使用 map 和 filter\n\n### 安全性\n\n### 性能\n\n- 用 set\n- d.iteritems() 比 items() 省内存\n\n## 0xEE 文章更新\n\n- **2017-05-11 19:43:00** : 增加代码质量模块\n"},{"tags":["Python"],"path":"20170114_PythonScope.md","title":"从一个小问题来说 Python 的作用域","slug":"从一个小问题来说 Python 的作用域","date":"2017-01-14","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n\u003e 备注，这种动态设置 module 里的方法不推荐\n\n## 前言\n\n整理工具字符类的时候，想借助正则表达式来实现一部分的文字判断抽取等操作。\n\n比如实现：\n\n- 判断文字是否为 UUID\n- 判断文字是否包含 UUID\n- 抽取文字是中第一个 UUID\n- 抽取文字是中所有 UUID\n\n\u003c!-- more --\u003e\n\n### 一个暴力的实现方法\n\n如果正则表达式比较少，就只一个 UUID，我们就不需要思考什么，我们分别编写四个函数：\n\n- is_uuid(\\_str)\n- has_uuid(\\_str)\n- extract_first_uuid(\\_str)\n- extract_all_uuid(\\_str)\n\n\u003e 没错，过早优化是万恶之源\n\n但很显然，手动方法显得很弱智，当我需要编写判断 QQ 号的时候，我又必须编写四个函数：\n\n- is_qq_num(\\_str)\n- has_qq_num(\\_str)\n- extract_first_qq_num(\\_str)\n- extract_all_qq_num(\\_str)\n\n然而：\n\n- 如果，我还需要判断手机号、日期、时间等等，这手动复制粘贴的过程就比较痛苦了。\n- 如果，我去要添加一个方法，给 QQ 号码，uuid 等打码 那就必须要给所有的 uuid, 手机，邮箱都添加一个 dama_xxx(\\_str) 方法\n\n有没有好一点的解决方法呢？\n\n\u003c!-- more --\u003e\n\n### 两个方法\n\n第一种，比如把函数修改为：\n\n- is(\\_str,QQ_NUM_PATTEN)\n- has(\\_str,QQ_NUM_PATTEN)\n- extract_first(\\_str,QQ_NUM_PATTEN)\n- extract_all(\\_str,QQ_NUM_PATTEN)\n\n第二种，Python 中动态添加工具方法，我个人比较喜欢这种：\n\n```python\n# 一个优雅的错误实现方式\nfor regex, regex_pattern in REGEXES.items():\n    def has_regex_func(_str):\n        return has_pattern(_str, regex_pattern)\n\n    def is_regex_func(_str):\n        return match_pattern(_str, regex_pattern)\n\n    def extract_first_regex_func(_str):\n        return find_first_matched_pattern(_str, regex_pattern)\n\n    def extract_all_regex_func(_str):\n        return find_all_matched_pattern(_str, regex_pattern)\n\n    setattr(sys.modules[__name__], 'has_{regex_suffix}'.format(regex_suffix=regex), has_regex_func)\n    setattr(sys.modules[__name__], 'is_{regex_suffix}'.format(regex_suffix=regex), is_regex_func)\n    setattr(sys.modules[__name__], 'extract_first_{regex_suffix}'.format(regex_suffix=regex), extract_first_regex_func)\n    setattr(sys.modules[__name__], 'extract_all_{regex_suffix}'.format(regex_suffix=regex), extract_all_regex_func)\n```\n\n于是我添加了测试方法：\n\n\u003e 一个不对稍微有些复杂的逻辑的程序进行测试的程序员不是一个称职的老司机。\n\n```python\n@pytest.mark.parametrize('test_input,expected', [\n    (\"321323199509234453\", False),\n    (\"000528-332222\", False),\n    (\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\", True),\n])\ndef test_is_uuid(test_input, expected):\n    assert is_uuid(test_input) == expected\n\n@pytest.mark.parametrize('test_input,expected', [\n    (\"321323199509234453\", False),\n    (\"000528-332222\", False),\n    (\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\", True),\n])\ndef test_has_uuid(test_input, expected):\n    assert has_uuid(test_input) == expected\n\n@pytest.mark.parametrize('test_input,expected', [\n    (\"321323199509234453\", None),\n    (\"000528-332222\", None),\n    (\"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\", \"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\"),\n])\ndef test_extract_first_uuid(test_input, expected):\n    assert extract_first_uuid(test_input) == expected\n\n@pytest.mark.parametrize('test_input,expected', [\n    (\"321323199509234453\", None),\n    (\"000528-332222\", None),\n    (\n            \"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\",\n            ['521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4', '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4',\n             '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4', '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4']),\n    (\n            \"521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4   aslakdj 521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4\",\n            ['521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4', '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4',\n             '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4', '521e7bb0-d8d5-4f49-a5c2-fee1aaf9e8c4']),\n])\ndef test_extract_all_uuid(test_input, expected):\n    assert extract_all_uuid(test_input) == expected\n```\n\n测试未通过：\n\n怎么查看代码本身都没有什么逻辑问题，那么问题出在哪里？\n\n对程序植入一些 print 代码来 Debug 一下：\n\n```python\nfor regex, regex_pattern in REGEXES.items():\n    def has_regex_func(_str, regex_pattern=regex_pattern):\n        # 当函数被调用之后，打印 regex_pattern 查看对应的字符串\n        print(regex_pattern)\n        return has_pattern(_str, regex_pattern)\n\n    def is_regex_func(_str, regex_pattern=regex_pattern):\n        return match_pattern(_str, regex_pattern)\n\n    def extract_first_regex_func(_str, regex_pattern=regex_pattern):\n        return find_first_matched_pattern(_str, regex_pattern)\n\n    def extract_all_regex_func(_str, regex_pattern=regex_pattern):\n        return find_all_matched_pattern(_str, regex_pattern)\n\n    # 查看是否为同一个函数\n    print(id(has_regex_func))\n\n    setattr(sys.modules[__name__], 'has_{regex_suffix}'.format(regex_suffix=regex), has_regex_func)\n    setattr(sys.modules[__name__], 'is_{regex_suffix}'.format(regex_suffix=regex), is_regex_func)\n    setattr(sys.modules[__name__], 'extract_first_{regex_suffix}'.format(regex_suffix=regex), extract_first_regex_func)\n    setattr(sys.modules[__name__], 'extract_all_{regex_suffix}'.format(regex_suffix=regex), extract_all_regex_func)\n```\n\n于是发现问题，所有打印出来的 regex_pattern 都是一致的。也就是，不管是 has_uuid 还是 has_qq_num 还是其他，最后 regex_pattern 都是我在字典中实现的\n"},{"tags":["Python"],"path":"20161203_Python文本处理.md","title":"Text Processing In Python","slug":"Text Processing In Python","date":"2016-12-03","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# Text Processing In Python\n\n## 0x00 前言\n\n本文为 Cheatsheet 类型文章，用于记录我在日常编程中的文本处理相关思路。\n\n本文的目录为：\n\n- 正则处理相关\n- HTML/XML 处理相关\n- Python 中的文本处理\n\n## 0x01 正则处理相关\n\n### 1.1. 正则表达式\n\n正则是个很奇葩的名字，为什么叫做正则表达式呢，首先是个表达式，其次，这是一种叫做正则 (regular expression, rational expression) 的表达式。\n名称为什么叫做 regular 呢，因为它基于 regular language. 而 regular language 是一种 formal language. 得，现在又开始是编译原理相关概念了。为了逃避概念，通过用途来简单定义正则表达式。\n\n简而言之，就是一种用于字符串搜索的模式。或者就是一种领域专用编程语言。\n\nhttps://en.wikipedia.org/wiki/Regular_expression\n\n### 1.2. Python 中正则表达式语法\n\n```python\n# 元字符\n. ^ $ * + ? { } [ ] \\ | ( )\n\n* # 速记，天上一个星星都没有，0 到多个。\n+ # 一加手机..... 1 到多个。\n? # 有还是没有 即 0 or 1\n*? # 没有疑问就是贪婪，有疑问就是非贪婪\n+?\n??\n\n{m} # m 份\n{m,n} # 优先匹配 a{2,}b 优先匹配 aaaab 中 aaaab\n{m,n}? # 优先匹配 a{2,}b 优先匹配 aaaab 中 aab\n\n[] # [a\\-z] == [az-]\n# 1. [\\w] [\\S]\n# 2. [^5]\n# 3. [akm$]  在 [] 中 $ 并不具备元字符特点\n\nPattenA | PattenB\n(...) # 捕获 , 引用可以使用、1 , 但是还有一种扩展语法\n\n(?...) # 扩展\n# - (?aiLmsux)\n# - (?:...) 不捕获\n# - (?P\u003cquote\u003e...) 正则内引用 (?P=quote);python 内获取 m.group('quote') ,m.end('quote');re.sub 内 repl 参数为、g\u003cquote\u003e \\g\u003c1\u003e \\1\n\n```\n\n### 1.3. Python 中使用正则的方法\n\n#### 1.3.1. re 模块的用法\n\n- sub 替换\n- match / fullmatch 匹配\n- search 搜索\n- split 分片\n\n```python\nre.split('(\\W+)', '...words, words...')\n# ['', '...', 'words', ', ', 'words', '...', '']\n```\n\n\u003e match 为匹配起始字符 / fullmatch 为全部字符 / search 为搜索\n\n#### 1.3.2. match object 的用法\n\n```python\nm.group(0)\nm.group(1, 2)\n\u003e\u003e\u003e m = re.match(r\"(?P\u003cfirst_name\u003e\\w+) (?P\u003clast_name\u003e\\w+)\", \"Malcolm Reynolds\")\n\u003e\u003e\u003e m.group('first_name')\n'Malcolm'\n\u003e\u003e\u003e m.group('last_name')\n'Reynolds'\nm.start() # 起始\nm.end()   # 结尾\n```\n\n## 1.4. 正则表达式性能\n\n```python\n# 编译优于不编译\nprog = re.compile(pattern)\nresult = prog.match(string)\nre.match(pattern,string)\n```\n\n## 0x02 HTML/XML 处理相关\n\n### 2.1. Beautifulsoup 处理 HTML\n\n解析往往伴随着各种各样奇葩的不奇葩的，诡异的不诡异的网页数据抽取，这个过程中，我们常使用两个库来解决问题，一个库叫做 lxml, 另一个库叫做 BeautifulSoup.\n\nbeautifulsoup 可是让我们通过直接手动编写遍历 dom 树的方法来快速遍历 dom 树从而获得数据。相比自己写解析器而言，可以算得上非常的节省时间了。\n\n只要能手动遍历 dom 树，基本上所有的数据都是可以获取的。痛点就是手动编写遍历 Dom 树并且完成测试的时间可能长一些。\n\n但是开发效率就比较低了。\n\n举个例子：\n\n```html\n\u003cdiv id=\"lal\"\u003e\n  \u003cspan class=\"item\" itemprop=\"street-address\" title=\"浦东南路八佰伴西面\"\u003e\n    地址：浦东南路八佰伴西面\n  \u003c/span\u003e\n  \u003cdiv class=\"item\" itemprop=\"street-address\" title=\"浦东南路\"\u003e名称：xxxx\u003c/div\u003e\n\u003c/div\u003e\n```\n\n我想要地址属性，如果是 beautifulsoup, 则我们需要先定位到 id 为 lal 的 div 元素。然后获取每个元素的 text 部分，然后使用 if 判断地址属性，然后提取 text.\n\n**但是如果用 xpath, 则可以把对元素的简单定位简单判断直接写在 xpath 表达式。**\n\n```python\nsel.xpath('//div[@id=\"lal\"]/*[contains(text(),\"地址\")]/text()').extract_first()\n# 如果还需要添加筛选名称，则可是使用\nsel.xpath('//div[@id=\"lal\"]/*[contains(text(),\"名称\")]/text()').extract_first()\n```\n\n这样可以极大的提升开发效率。\n\n页面的结构越复杂，则 xpath 带来的开发效率越高。\n\n### 2.2. XPath 处理 HTML\n\n#### 2.2.1. 概念\n\nXPath 是一种通过路径表达式定位 XML 文档内容的语法。\n由于内置了大量的表达式函数，可以通过极少的代码完成定位。\n有七种**节点类型**:\n\n- element\n- attribute\n- text\n- namespace\n- processing-instruction\n- comment\n- document nodes\n\n有五种**节点间关系**:\n\n- 父节点 Parent\n- 子节点 Children\n- 兄弟节点 Siblings\n- 先祖节点，即父与父父节点。Ancestors\n- 后代节点，即子与子子节点。Descendants\n\n| 语法     | 描述       | 例子                     |\n| -------- | ---------- | ------------------------ |\n| nodename | 节点名称   | a                        |\n| /        | 根节点     | /                        |\n| //       | 匹配所有   | bookstore//book          |\n| .        | 当前节点   |                          |\n| ..       | 父节点     | a/../a/..                |\n| @        | 属性       | a/@href                  |\n| []       | 谓语       | book[1] , book[last()-1] |\n| func()   | 表达式函数 | postion()                |\n\n```python\nresponse.xpath(\"//*[@id=\\\"landlb_B04_04\\\"]/span[2]/a[contains(@href,'market')]\")\nresponse.xpath(\"//*[@id=\\\"landlb_B04_04\\\"]/span[2]/a[not(@class)]\")\nresponse.xpath(\"//ul/li/b[contains(text(),'什么玩意')]/following-sibling::span/text()\")\nresponse.xpath(\"//div[@class='address']/text()[preceding::span[@class='item' and contains(text(),'地址：')]]\")\nresponse.xpath(\"//ul/li/b[contains(text(),'什么玩意：')]/following-sibling::a/text()\")\n```\n\n```bash\n//*[contains(text(),'ABC')]\n# http://stackoverflow.com/questions/3655549/xpath-containstext-some-string-doesnt-work-when-used-with-node-with-more/3655588#3655588\n\n\u003cdiv class=\"atag btag\" /\u003e\n//div[contains(@class, 'atag') and contains(@class ,'btag')]\n```\n\n#### 2.2.2. lxml parsel\n\n这两个库是 Python 中常用的解析表达式， parsel 依赖于 lxml , 安装完 lxml 后直接安装即可。\n\n#### 2.2.3. lxml 的番外\n\n众所周知，Mac 的 Homebrew 很方便，每一次遇到需要下载编译的组件的时候，只需要执行 brew install xxx, 很快就可以使用了。\n\n但 homebrew 安装的软件都是最新的，这很容易导致部分软件由于版本更新带来的兼容性问题。\n\n这不，最近在 Mac 上进行开发的时候每次调用初始化 lxml 的时候总是无法进行解析，最后经过排查发现问题是 lxml 在编译的时候使用的 libxml 2.9.4 但是 使用的版本为 2.9.2 , 于是每当我使用 lxml 的时候，就会报错。\n\n不得已，找到 lxml 的 F\u0026Q 部分发现提 issue 之前需要先查看依赖版本。\n\n于是进入 IPython 排查。\n\n```Python\nimport sys\nfrom lxml import etree\n\nprint(\"%-20s: %s\" % ('Python', sys.version_info))\nprint(\"%-20s: %s\" % ('lxml.etree', etree.LXML_VERSION))\nprint(\"%-20s: %s\" % ('libxml used', etree.LIBXML_VERSION))\nprint(\"%-20s: %s\" % ('libxml compiled', etree.LIBXML_COMPILED_VERSION))\nprint(\"%-20s: %s\" % ('libxslt used', etree.LIBXSLT_VERSION))\nprint(\"%-20s: %s\" % ('libxslt compiled', etree.LIBXSLT_COMPILED_VERSION))\n\n# Python : sys.version_info(major=3, minor=5, micro=1, releaselevel='final', serial=0)\n# lxml.etree : (3, 6, 2, 0)\n# libxml used : (2, 9, 2)\n# libxml compiled : (2, 9, 4) # 注意问题出在这里。\n# libxslt used : (1, 1, 28)\n# libxslt compiled : (1, 1, 28)\n```\n\n于是使用 pip 强制进行安装升级。\n\n```\nSTATIC_DEPS=true pip install -i http://pypi.douban.com/simple/ –trusted-host pypi.douban.com lxml –ignore-installed –no-cache-dir –upgrade -vvv\n```\n\n安装完毕即可。\n\n### 2.3. 标准库处理 HTML\n"},{"tags":["清单"],"path":"20161126_Pythonista_List.md","title":"Awesome-Python","slug":"Awesome-Python","date":"2016-11-26","category":"Python","lastMod":"2021-06-30","description":"Awesome-Python","thumbnail":"","content":"\n# Python Awesome\n\n清单入选标准\n\n1. 笔者正在使用的，即，过时的东西不入选\n2. 并不拘泥于 Python, 即如果在其他语言里有更好的解决方案，我会在其他语言的 Awesome list 里推荐\n\n## 0x01 环境搭建\n\n- pyenv\n- pyenv virtualenv\n- poetry\n- pipenv （更推荐 poetry)\n\n## 0x02 爬虫\n\n爬虫的流程如下，获取 - 解析 - 分析 - 入库\n\n扩展的时候需要各自做好拆分\n\n- 获取\n- 解析\n- 分析\n- 入库\n\n社区爱用 PySpider Scrapy 这类框架\n\n也有喜欢直接手动组装的库来做爬虫的\n\n分析\n\n- charles 用于抓包和测试\n- mitmproxy\n\n请求\n\n- requests\n- headless-chrome\n- socket\n\nApp 模拟点击\n\n- appnium\n\n解析\n\n- json\n- nodejs 配合 v8 引擎可以复用一部分 js 代码得出真实数据。\n- beautifulsoup\n- lxml\n- pyquery\n\n清洗与入库\n\n并发\n\n- multiprocessing\n- threading\n- asyncio\n- gevent\n\n## 0x03 Flask Web\n\n```bash\nflask-sqlalchemy\nflask-migrate\n```\n\n## 0x04 Django Web\n\n```bash\nDjango\ncelery\ndjango-debug-toolbar\ndjango-extensions\ndjango-filter\ndjango-grappelli\nxadmin\ndjango-mptt\ndjango-redis\ndjangorestframework\n```\n\n## 0x04 FastApi Web\n\n```bash\nfastapi\nuvicorn\njwt\npsycopg2-binary\naiofiles\norjson\ntortoise-orm\nasyncpg\naioredis\naiokafka\n```\n\n## 0x07 调试与测试\n\n```\nipython\njupyter notebook\nipdb\nhttps://github.com/joerick/pyinstrument\nhttps://github.com/joerick/pyinstrument_cext\nspeedscope\npyspeedscope\n```\n\n## 0x08 dry python\n\n- https://github.com/dry-python/returns\n- https://github.com/jd/tenacity\n\n## 0x09 clear code\n\n## 0x08 工具\n\n## 0xBB News\n\n- https://github.com/markshannon/faster-cpython\n\n## 0xCC 推荐源码\n\n### 简单\n\n- kennethreitz/records: SQL for Humans™\n- chrisallenlane/cheat\n- jek/blinker: A fast Python in-process signal/event dispatching system.\n- mitsuhiko/platter: A useful helper for wheel deployments.\n- kennethreitz/tablib: Python Module for Tabular Datasets in XLS, CSV, JSON, YAML, \u0026c.\n\n### 中级\n\n- faif/python-patterns 使用 Python 实现一些设计模式的例子。\n- pallets/werkzeug flask 的 WSGI 工具集。其中包含了实现非常好的 LocalProxy,cached_property,import_string,find_modules,TypeConversionDict 等。\n- msiemens/tinydb 了解用 Python 实现数据库。\n\n### 高级\n\n以及一个非常神奇的进阶项目 500lines https://github.com/aosabook/500lines\n\n### 其他\n\n- https://github.com/howie6879/ruia\n\n## 0xDD 书籍\n\n- [x] CPython Internals\n- [x] Python Cookbook\n- [x] Python Web 开发实战\n- [x] Python For Data Analysis\n- [x] 深入浅出 MySQL\n- [x] 大型网站技术架构 - 核心原理与案例分析\n\n## 0xEE 结语\n\n---\n\nChangeLog:\n\n- **2020-10-24** 重修文字\n"},{"tags":["Python"],"path":"20160923_IPynb和ECharts.md","title":"IPython Notebook 引入 ECharts 做可视化","slug":"IPython Notebook 引入 ECharts 做可视化","date":"2016-09-23","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# IPython Notebook 引入 ECharts 做可视化\n\n## 0x01 前言\n\nPython 的开发生态圈有相当多的好用的数据分析挖掘工具。Pandas,Numpy,Scikit-Learn 等等。\n\n在进行数据分析挖掘的方面，我们选用 IPython Notebook 对数据进行前期的探索和挖掘。以及内部的可视化交流。\n\n也需要经常新的进行一些可视化来使得探索过程更加的顺利。面对海量的数据可视化，也依照目的使用不同的工具。\n\n- 对于后台开发 / 数据挖掘 / 爬虫工程师而言，内部沟通的过程中注重信息交流沟通的快捷和准确，而不需要考虑可视化的美观程度，所以使用 IPython Notebook 配上 Matplotlib 或者是 Seaborn 进行可视化。\n- 与其他非开发的技术人员交流沟通的时候，这个时候优美的图表就成为了重中之重。\n\n\u003e 可是 Seaborn Matplotlib 这些库画出来的图，如同那些其貌不扬的高手，包含大量信息，美中不足的就是**不美**。那可不可以使用更加漂亮的图来可视化呢？\n\n有，ECharts[案例地址戳这里](http://echarts.baidu.com/examples.html)\n\n\u003e 想拥有 IPython Notebook 的优点上，还能够最大化 IPython Notebook 的美观程度，这就是我们想在 IPython Notebook 中引入 ECharts 作为可视化的初衷。\n\n\u003e 如果你使用过 IPython Notebook，细心的你一定大致了解，核心困难点在于如何在 IPython Notebook 中引入 ECharts.\n\n今天我们使用 IPython NoteBook 来演示一个简单的 ECharts 饼图案例。本文的数据来自大众点评闵行区部分美食店铺。\n\n## 0x01 代码思路\n\nIPython 中，我们知道，可以通过 IPython.display 导入 HTML.\n\n```python\nfrom IPython.display import HTML\nHTML(\"\"\"\n\u003cdiv\u003e这是一小块 HTML\u003c/div\u003e\n\"\"\")\n```\n\n执行就 IPython Notebook 中看到：\n\n```\n\u003cdiv\u003e这是一小块 HTML\u003c/div\u003e\n```\n\n![显示 HTML](http://upload-images.jianshu.io/upload_images/52890-e7646baa6145766b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n但问题来了，我们知道，在通常的情况下，是不能动态引入 JS 脚本的。因此我们在开发 HTML 静态页面的时候，往往脚本都是在 Head 或者 Body 结束标签之前就写死了。如果要在 IPython 中增加 ECharts, 是不是需要修改一些配置文件，让 IPython Notebook 在 Header 部分引入 ECharts 脚本呢？\n\n答案是**不需要**.\n\n\u003e 为何？因为 IPython Notebook 本身自带一个 Js 模块，叫做 RequireJS. 通过这个模块**可以动态引入并执行 JS.**\n\n具体原理不详细介绍，但是这个模块为 IPython Notebook 动态引入其他 JS 框架和代码带来了无限的可能性。注意，再次强调，这个模块可以帮助我们**可以动态引入并执行 JS.**\n\n于是通过下面的代码，我们就轻松的将 ECharts 引入到 IPython Notebook 中。\n\n```python\nchart_header_html = \"\"\"\n\u003cdiv id=\"chart\" style=\"width:800px; height:600px;\"\u003e\u003c/div\u003e\n\u003cscript\u003e\n    require.config({\n         paths:{\n            echarts: '//cdn.bootcss.com/echarts/3.2.3/echarts.min',\n         }\n    });\n    require(['echarts'],function(ec){\nvar myChart = ec.init(document.getElementById('chart'));\n                var option = {\n                    title: {\n                        text: '闵行区美食类人均消费餐馆分布',\n                        subtext: '数据来自大众点评',\n                        x: 'center'\n                    },\n                    tooltip: {\n                        trigger: 'item',\n                        formatter: \"{a} \u003cbr/\u003e{b} : {c} ({d}%)\"\n                    },\n                    legend: {\n                        orient: 'vertical',\n                        left: 'left',\n                        data: ['人均消费不明','人均消费 0~50 元', '人均消费 50~100 元', '人均消费 100~150 元', '人均消费 150~200 元', '人均消费 200 元以上']\n                    },\n                    series: [\n                        {\n                            name: '店铺比例',\n                            type: 'pie',\n                            radius: '55%',\n                            center: ['50%', '60%'],\n                            data: [\n\n\"\"\"\nchart_content_html = \"\"\"\n                                {value: %s, name: '人均消费不明'},\n                                {value: %s, name: '人均消费 0~50 元'},\n                                {value: %s, name: '人均消费 50~100 元'},\n                                {value: %s, name: '人均消费 100~150 元'},\n                                {value: %s, name: '人均消费 150~200 元'},\n                                {value: %s, name: '人均消费 200 元以上'}\n\"\"\" % (consume_unknown_restaurant_count,consume_0_50_restaurant_count,consume_50_100_restaurant_count,consume_100_150_restaurant_count,consume_150_200_restaurant_count,consume_200_greater_restaurant_count)\nchart_footer_html = \"\"\"\n                            ],\n                            itemStyle: {\n                                emphasis: {\n                                    shadowBlur: 10,\n                                    shadowOffsetX: 0,\n                                    shadowColor: 'rgba(0, 0, 0, 0.5)'\n                                }\n                            }\n                        }\n                    ]\n                };\n                myChart.setOption(option);\n    });\n\u003c/script\u003e\n\"\"\"\n\nHTML(\n chart_header_html + chart_content_html + chart_footer_html\n)\n\n```\n\n看一看代码，首先，配置对应的脚本。引入 requirejs 的配置模块。\n\n```javascript\nrequire.config({\n  paths: {\n    echarts: \"//cdn.bootcss.com/echarts/3.2.3/echarts.min\",\n  },\n})\n```\n\n接着使用如下代码进行引入和执行代码，具体的 Demo 可以参考文章末尾的代码：\n\n```javascript\nrequire(['echarts'],function(ec){\n var option = {\n//... 图表配置\n}\n//... 获取图表 div\n//... 为所获取的图表 DIV 设置\n}\n```\n\n## 0x03 效果\n\n于是，美观漂亮的可视化图就出来了。\n\n![ECharts 饼图](http://upload-images.jianshu.io/upload_images/52890-59bffc49212928be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n## 0x04 代码\n\n附上 IPythonNotebook 以及 Excel 表用于大家分析。\n\n- [对应的 IPythonNotebook](https://github.com/twocucao/DataScience/blob/master/project_03_dianpin/simple_stat.ipynb)\n- [对应的 Excel 表](https://github.com/twocucao/DataScience/blob/master/project_03_dianpin/%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84%E9%97%B5%E8%A1%8C%E5%8C%BA%E7%BE%8E%E9%A3%9F%E9%A4%90%E5%8E%85%E7%AE%80%E5%8D%95%E7%BB%9F%E8%AE%A1.xlsx)\n"},{"tags":["Python"],"path":"20160315_如何发布一个Py命令行工具.md","title":"如何发布一个 Python 命令行工具","slug":"如何发布一个 Python 命令行工具","date":"2016-03-15","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# 如何发布一个 Python 命令行工具\n\n## 0x01 本文简介\n\n上次写的一个终端里面斗鱼 TV 弹幕 Python 版本和 Ruby 版本，并且发布到 PIP 和 RubyGems 上面。在发布 PIP 包的时候，居然 Google 不到一篇可以非常好的讲解这个流程的文章。于是整理这篇文章，并且方便后来自己检索，并且方便他人找资料。\n\n自推荐下依照本文定制的命令行工具 danmu.fm 的 github 地址：\n\nhttps://github.com/twocucao/danmu.fm\n\n本文的目的也是非常简单：\n\n\u003e **写一个 Python 命令行工具，并且发布到 PIP 上面.**并且在这个过程中给出我自己的一些思考。\n\n\u003c!-- more --\u003e\n\n## 0x02 如何分解这个发布任务？\n\n只需要进行如下的两个步骤便可以：\n\n- 1.  写好一个 Python 命令行工具。\n- 2.  发布它。\n\n当然，这样不够细致。再细分一下。\n\n- 1.  写好一个 Python 命令行工具\n  - 1.1. 命令行的特点，以及 Python 的如何编写命令行\n  - 1.2. 如何组织代码结构。\n- 2.  发布\n- 2.1. 注册 pypi 账户\n  - 2.2. 注册在账户下面注册 Python 包\n  - 2.3. 上传**打包**好的 Python 命令行工具。\n- 3. 完善代码\n\n## 0x03 写好一个 Python 命令行工具\n\n写好一个命令行工具首先要知道命令行工具是什么？\n\n\u003e 在我看来，命令行工具就是一种完成某种类型的任务的终端程序。\n\n也就是基本上没有什么用户界面的程序。\n\n由于基本上没有什么用户界面，所以导致单个命令行的交互能力及其低下。但这种低下的交互性对于一些固定工作而言，简直就是最灵活的工具。只需要输入一些命令便可以完成某种类型的工作。实在是方便的很。\n\n所以，某种程度上，终端程序低交互的缺点反而成了优点。\n\n### 1.1.Python 的如何编写一个简单的命令行\n\n对于 Python 和命令行交互，我们很容易想出一个比较方便的方案。\n\nsys.argv 就是这样的嘛！\n\n我们很容易这样写代码。\n\n```bash\n python testargv.py thisisaargv1\n```\n\n甚至我们也可以这样写命令行，\n\n```bash\n python testargv.py thisisaargv1 -d -f 0\n```\n\n那么，这样写的后果就是，不方便解析出（不是不能，是不方便） -d -f 0 以及 thisisaargv1.\n\n不信的话，你解析一个下面场景的命令行试试，\n\n```bash\n# 用户可能这样输入\ndanmu.fm http://www.douyutv.com/xiaocang -q 1 -v 2\ndanmu.fm -q 1 -v 2 http://www.douyutv.com/xiaocang\n# 当然，肯定还有漏写啦，等等，你得需要转类型，增加各种 blablabla 的描述吧，添加默认的参数值吧。\n```\n\n于是 Python 就提供了一个非常好用的模块可以使用。叫做 argparse.\n\n上面的描述就变成了这个样子\n\n```python\nimport argparse\n\nAPP_DESC=\"\"\"\n这就是描述\n\"\"\"\nprint(APP_DESC)\nif len(sys.argv) == 1:\n    sys.argv.append('--help')\nparser = argparse.ArgumentParser()\nparser.add_argument('-q','--quality',type=int,default=0,help=\"download video quality : 1 for the standard-definition; 3 for the super-definition\")\nparser.add_argument('-v','--verbose', default=0,help=\"print more debuging information\")\nparser.add_argument('-s','--store',help=\"保存流媒体文件到指定位置\")\nparser.add_argument('-c','--config',default=0,help=\"读取~/.danmu.fm 配置，请~/.danmu.fm 指定数据库\")\nparser.add_argument('url',metavar='URL',nargs='+', help=\"zhubo page URL (http://www.douyutv.com/*/)\")\nargs = parser.parse_args()\n# 获取对应参数只需要 args.quality,args.url 之类。\nurl = (args.url)[0]\nprint(url)\n#其他执行逻辑\n```\n\n保存为 danmu.py\n\n这样就可以执行命令\n\n```bash\npython danmu.py http://www.douyutv.com/xiaocang -q 1 -v 2\n```\n\n通过 args 就可以获取参数，然后进行终端程序的参数初始化。\n\n可是这和我们的要求还是不同嘛，我们不想多写 Python XXX, 我们想直接 XXX. 就像这样。\n\n```bash\ndanmu.fm -q 1 -v 2 http://www.douyutv.com/xiaocang\n```\n\n不急，下面就是了。\n\n### 1.2. 如何组织代码结构。\n\n于是，现在就要开始组织代码结构了。\n\n我们在最终的代码目录大概是这样的。\n\n```bash\ndanmu.fm\n├── README.md\n├── danmufm\n│   ├── __init__.py\n│   ├── client\n│   │   ├── __init__.py\n│   │   ├── __init__.pyc\n│   │   ├── douyu_client.py\n│   │   └── douyu_danmu_client.py\n│   ├── danmu.py\n│   ├── misc\n│   │   ├── __init__.py\n│   │   ├── color_printer.py\n│   │   ├── downloaders.py\n│   │   └── player.py\n│   └── model\n│       ├── __init__.py\n│       └── douyu_msg.py\n├── docs\n├── setup.cfg\n├── setup.py\n├── sh.py\n└── tests\n```\n\n这就是我上次写的 danmu.fm 的代码目录。\n\n聪明的你这时候你注意到了：\n\n1. 主要的程序不是放在根目录下面，而是放在第二目录 danmufm 下面。\n2. setup.cfg 是什么鬼东西\n3. setup.py 是什么鬼东西\n\n对于上面几点，我们分别进行解释\n\n### 1.2.1 为什么主要程序在第二目录下\n\n为了把主要的程序分离出来，放在第二目录下面，这样的待会打包以后多出很多文件夹就不会对源码造成干扰。\n\n当然，由于把程序放在了第二目录下面，所以，脚本里面的 from import 语句应该使用相对路径导入。\n\n相对路径导入的的时候需要注意运行的时候使用如下命令\n\n```bash\npython3 -m danmufm.danmu [xxxx]\n```\n\n### 1.2.2 setup.cfg\n\n填写如下内容即可。\n\n```\n[metadata]\ndescription-file = README.md\n```\n\n然后去写 Markdown 的 Readme 就好了。\n\n### 1.2.3 setup.py\n\n这个是重头戏了。\n\nsetup 这个 py 文件就是打包配置文件。对这个程序是谁的，有什么依赖，入口是什么，等等等等的配置。\n\n```python\n#-*- encoding: UTF-8 -*-\nfrom setuptools import setup, find_packages\n\"\"\"\n打包的用的 setup 必须引入，\n\"\"\"\n\nVERSION = '0.1.1'\n\nsetup(name='danmu.fm',\n      version=VERSION,\n      description=\"a tiny and smart cli player of douyutv,ximalayad,anmu based on Python\",\n      long_description='just enjoy',\n      classifiers=[], # Get strings from http://pypi.python.org/pypi?%3Aaction=list_classifiers\n      keywords='python douyu danmu danmu.fm terminal',\n      author='twocucao',\n      author_email='twocucao@gmail.com',\n      url='https://github.com/twocucao/doumu.fm',\n      license='MIT',\n      packages=find_packages(),\n      include_package_data=True,\n      zip_safe=True,\n      install_requires=[\n        'requests',\n      ],\n      entry_points={\n        'console_scripts':[\n            'danmu.fm = danmufm.danmu:main'\n        ]\n      },\n)\n\n```\n\n官方有 distutils 这个包管理器工具，设置也非常的简单，只是，它不支持 entry_points 属性，由于无法使用 entry_point, 也就无法通过命令来跳转到指定模块运行程序，这也就意味着，官方工具不方便写成命令行。还是 setuptools 好。\n\n上面需要注意的就是 install_requires 可以添加依赖。其他的你猜都可以猜出来是做什么的。自己去看代码，我就不多说了。\n\n## 2. 发布\n\n所谓的发布，就是将打包好的程序的某个版本发布到某个仓库中。\n\n### 2.1. 注册 pypi 账户\n\n到这个上面注册账号：\nhttps://pypi.python.org/pypi\n\n### 2.2. 注册在账户下面注册 Python 包\n\n进入对应项目根文件，然后执行\n\n```bash\npython3 setup.py register\n```\n\n这一步程序会让你输入刚刚注册的账号和密码，然后注册该包。注册该包以后，你就有了一个小仓库。可以存放不同版本的 danmu.fm.\n\n注册的仓库是可以在这个地址看到的，\nhttps://pypi.python.org/pypi?%3Aaction=pkg_edit\u0026name=danmu.fm\n\n### 2.3. 上传**打包**好的 Python 命令行工具。\n\n这里需要借助一个小工具，twine.twine 是一个更加安全方便上传打包好的代码的工具。\n\n```bash\npip3 install twine\n```\n\n接着开始打包，打包成两个版本，一个是不需要 build 的版本，另一个是需要 build 的版本（顺带吐槽下，这两个诡异的命名）.\n\n```bash\npython setup.py sdist bdist_wheel\n```\n\n于是剩下来的就显而易见了，上传 build 完毕的程序到仓库中。\n\n```bash\ntwine upload dist/danmu.fm-0.1.2*\n```\n\n于是，安装一下，测试是否成功\n\n```bash\npip3 install danmu.fm --upgrade\n```\n\n命令行的工具是这样使用的。\n\n```bash\ndanmu.fm -q 2 -v 1 http://www.douyutv.com/16789\n```\n\n## 3. 完善\n\n不断的完善代码，然后打包终端程序发布到仓库给别人用，这就是整个的 PIP 打包发布流程。\n\n- 这个时候，你可能需要使用版本控制软件。\n- 你可能需要增多的代码的测试。\n"},{"tags":["Python"],"path":"20160215_Python斗鱼弹幕助手.md","title":"Python 程序员如何优雅的看斗鱼 TV","slug":"Python 程序员如何优雅的看斗鱼 TV","date":"2016-02-15","category":"Python","lastMod":"2020-01-01","description":"这篇文章展示了基本的 Markdown 语法和格式.","thumbnail":"","content":"\n# Python 程序员如何优雅的看斗鱼 TV\n\n## 0x00 前言\n\n过年的一段时间抽空研究写了一些关于斗鱼 TV 的弹幕的获取。分别使用 Python 和 Ruby 写了弹幕获取的客户端。\n\n文章地址为：\n\nPython 版本：\nhttp://www.jianshu.com/p/2e0d14978ae9\n\nRuby 版本附加原理讲解：\nhttp://www.jianshu.com/p/ef0225b6bb0e\n\n文章末尾写到了我有一个痛点 --rtmp 直播视频无法获取，后来在网友 [往事侞湮](http://www.jianshu.com/users/0675b42ac3ba)] 的友善提醒下，终于 Get 到了。\n\n于是，稍微完善了一下，我就发布了第一个命令行版本的斗鱼 TV 浏览弹幕小助手。\n\n如果你是 MacOSX 的用户，你只需要\n\n```bash\nbrew install mplayer\npip3 install danmu.fm\n# danmu.fm -q 1 -v 1 [url]\n# 比如\ndanmu.fm -q 2 -v 1 http://www.douyutv.com/16789\n# -q 参数 0 为不调用 mplayer 进行播放，1 为使用 mplayer 进行普清视频的播放，2 为使用 mplayer 进行高清视频的播放，3 为使用 mplayer 进行超清视频的播放\n```\n\n如果你是 Ubuntu 用户，你只需要\n\n```bash\nsudo apt-get install mplayer\npip3 install danmu.fm\n# danmu.fm  -v 1 [url]\n# 比如\ndanmu.fm  -v 1 -q http://www.douyutv.com/16789\n#ubuntu 上 mplayer 播放器可以正常播放\n```\n\n如果你是 Win 用户，\n\n\u003e 唉，windows 上面糟糕的编码问题。那单纯来看字幕的话也不是不可以的。只是我暂时没有对 Win 进行兼容。还是换 Linux 吧。\n\n## 0x01 演示效果\n\n![1123.gif](http://upload-images.jianshu.io/upload_images/52890-396d6451c68d2a83.gif?imageMogr2/auto-orient/strip)\n\n## 0xEE 代码地址\n\nhttps://github.com/twocucao/danmu.fm\n\n如果喜欢，请点个喜欢或者 star 一下\n\n---\n\nChangeLog:\n\n- **Update 20160609 : ** 更新 Python 客户端，修复由于斗鱼网页版面修改带来的小问题，直接开启海量弹幕模式（请大家不要问我为什么端午节这一天为什么闲着没事更新代码，这个真的和情人节是同一个原因）.\n- **Update 20160220 : **更新 Python 客户端，增加直播视频的 Live 获取，以及 Mac 平台下面的 Mplayer 的视频播放。代码均放在 Github 上面。[GitHub - twocucao/danmu.fm: douyutv danmu 斗鱼 TV 弹幕助手\\*\\*](//link.zhihu.com/?target=https%3A//github.com/twocucao/danmu.fm)\n- **Update 20160214 : **更新 Python 和 Ruby 客户端（请大家不要问我为什么情人节这一天为什么闲着没事更新代码）\\*\\*\n"}],"total":20}},"__N_SSG":true},"page":"/category/[slug]","query":{"slug":"Python"},"buildId":"oDi_oBCBuu3qj6v7hDnrL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>