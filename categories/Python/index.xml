<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - 分类 - 海拉鲁编程客</title>
        <link>http://twocucao.xyz/categories/python/</link>
        <description>Python - 分类 - 海拉鲁编程客</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-cn</language><managingEditor>twocucao@gmail.com (twocucao)</managingEditor>
            <webMaster>twocucao@gmail.com (twocucao)</webMaster><lastBuildDate>Mon, 30 Nov 2020 18:16:34 &#43;0800</lastBuildDate><atom:link href="http://twocucao.xyz/categories/python/" rel="self" type="application/rss+xml" /><item>
    <title>Python Type Hint</title>
    <link>http://twocucao.xyz/posts/20201201_pythontypehint/</link>
    <pubDate>Mon, 30 Nov 2020 18:16:34 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20201201_pythontypehint/</guid>
    <description><![CDATA[0x00 前言 本文是《提升你的 Python 项目代码健壮性和性能》系列的第一篇文章。
本系列仅仅从笔者的项目经历来讲解一些提升代码健壮性的姿势和小技巧。
本文目录如下：
▼ 0x00 前言 : section ▼ 0x01 Gradual Typing : section 静态类型 VS 动态类型 : section Gradual Typing = 静态类型 + 动态类型 : section ▼ 0x02 Python Typing 实战 - MyPY : section MyPy : section 快速入门 : section ▼ 0x03 常见问题 : section 如何忽略 mypy 警告 : section 循环导入 : section 0x04 Typing Anotation 项目最佳实践 : section ▼ 0xEE 参考 : section PEP : section 扩展文章 : section  当我刚知道 Python 要添加类型的时候，我的内心是拒绝的。]]></description>
</item><item>
    <title>Python Profiling/Tracing Tools</title>
    <link>http://twocucao.xyz/posts/20201201_pythonprofiling/</link>
    <pubDate>Mon, 30 Nov 2020 18:14:14 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20201201_pythonprofiling/</guid>
    <description><![CDATA[Profiling 定位与优化耗时、内存使用、CPU 使用 Tracing 用于追踪内存布局  0x00 前言 本篇讨论的是优化
当我们在谈优化的的时候，首先要背诵下面三个口诀
优化口诀 1: 先做对，布监控，再做好。 优化口诀 2: 过早优化是万恶之源。 优化口诀 3: 去优化那些需要优化的地方。  可以参考之前的文章 https://zhuanlan.zhihu.com/p/58754459
本文讨论的是基于现有代码的诊断。也顺带讨论了无侵入线上 trace 的原理和技巧
优化分为两种：
 侵入性诊断 侵入性诊断  0x01 侵入性诊断 基础工具  print logging timeit  Profile vs cProfile cProfile overhead 较高，
import cProfile import re cProfile.run(&#39;re.compile(&#34;foo|bar&#34;)&#39;) 197 function calls (192 primitive calls) in 0.002 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.]]></description>
</item><item>
    <title>一文解决你的 Python ORM 选择困难症</title>
    <link>http://twocucao.xyz/posts/20190412_pythonorm/</link>
    <pubDate>Fri, 12 Apr 2019 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20190412_pythonorm/</guid>
    <description><![CDATA[0x00 前言 Python 圈内三大 ORM SQLAlchemy VS Django ORM VS Peewee
 SQLAlchemy 复杂程度最高，同时，这也意味着 SQLAlchemy 可以做更多的事情。使用 DataMapper 方式实现 Django ORM 个人最喜欢，使用 ActiveRecord 实现 如果不是因为现在 Flask 项目已经是用了 SQLAlchemy , 否则的话我甚至会考虑将 Django ORM 配置到 Flask 项目中。当然，也有蛋疼的 SqlAlchemy 使用者已经移植给 django 配置了 SQLAlchemy 的库。 Peewee 没用过，不好评论。以后有机会试试。  0x01 如何访问数据库 那，既然已经可以访问数据库，本着『如无必要，勿增实体』的原则，为什么要不辞劳苦的用个库呢？
0x02 数据库抽象的两种理论 理论一：Active Record 理论二：Data Mapper 0x03 数据库抽象的两种实现 实现一：Django ORM 实现二：Sqlalchemy 0x04 工具的强弱 https://www.thoughtfulcode.com/orm-active-record-vs-data-mapper/
2.0 SQLAlchemy VS DjangoORM ORM 通常有 DataMapper 实现和 ActiveRecord 实现两种。]]></description>
</item><item>
    <title>用 Type Anotation 提升你的 Python 代码健壮性</title>
    <link>http://twocucao.xyz/posts/20181210_pythontypeanotation/</link>
    <pubDate>Mon, 10 Dec 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20181210_pythontypeanotation/</guid>
    <description><![CDATA[0x00 前言 本文是《提升你的 Python 项目代码健壮性和性能》系列的第一篇文章。
本系列仅仅从笔者的项目经历来讲解一些提升代码健壮性的姿势和小技巧。
本文目录如下：
▼ 0x00 前言 : section ▼ 0x01 Gradual Typing : section 静态类型 VS 动态类型 : section Gradual Typing = 静态类型 + 动态类型 : section ▼ 0x02 Python Typing 实战 - MyPY : section MyPy : section 快速入门 : section ▼ 0x03 常见问题 : section 如何忽略 mypy 警告 : section 循环导入 : section 0x04 Typing Anotation 项目最佳实践 : section ▼ 0xEE 参考 : section PEP : section 扩展文章 : section 当我刚知道 Python 要添加类型的时候，我的内心是拒绝的。]]></description>
</item><item>
    <title>CPython 源码初步阅读笔记</title>
    <link>http://twocucao.xyz/posts/20180606_cpython/</link>
    <pubDate>Wed, 06 Jun 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20180606_cpython/</guid>
    <description><![CDATA[0x00 前言 先挖坑，以后有机会填
├── Grammar # 语法 ├── Include # C 语言头文件，如果需要自定义模块扩展 Python, 也需要这块。 ├── Modules # C 语言编写的模块，对速度要求高，比如 random ├── Objects # 内建对象 包含整数，list,dict 等。 ├── Parser # Scanner 和 parser ├── Python # 各种 Python 共享库 ├── Lib # Python 自带的所有标准库 ├── Doc # 文档 ├── Tools # 一些 Python 程序，方便扩展 Python ├── Misc # 不清楚放哪，就放这里好了 ├── PC # Windows 编译姿势 ├── PCbuild # Windows 编译姿势 ├── Mac # Mac 上编译姿势 ├── Programs ├── README.]]></description>
</item><item>
    <title>PyCon 2018 之 pipenv -- 未来的 Python 依赖管理工具</title>
    <link>http://twocucao.xyz/posts/20180523_pipenv/</link>
    <pubDate>Wed, 23 May 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20180523_pipenv/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://user-images.githubusercontent.com/5625783/100601457-8efe8a80-333d-11eb-803e-861352bd1715.jpg" referrerpolicy="no-referrer">
            </div>0x00 前言 PyCon 2018 有很多精彩的演讲，今天的文章里，介绍一下 K 神的演讲 『Python 未来的包管理工具 pipenv』
Kenneth Reitz 出品，必属精品。
Python 打包历史 刚开始的时候，我们是这样安装包的。
curl http://pypi.python.org/packages/alsdasdl/requests.tar.gz | tar zxf cd requests/ python setup.py install 这个问题初看起来不是问题，但是随着你安装程序的增多就知道有多么痛苦了。
 有的依赖库依赖别的库你怎么解决？比如 pandas 需要安装 numpy 有的依赖库依赖 c 库怎么办？比如 LXML 在 python2.6.5 下，如果我需要安装两个不同版本的 Django 开发不同的软件怎么办？难道只能动态复制文件到 site-packages 里面？  后来，我们是这样安装包的。
easy_install requests 我们可以直接从 pypi 进行安装了。但尼玛，为什么 easy_install 安装很 easy, 但是没有 easy_uninstall?
好，2010 年后，我们继续前进：
 可以通过 pip 替代 easy_install 了。 可以通过 virtualenv 管理项目的依赖库了。虽然说，还是不能像 ruby gem 一样同时把多个版本的的软件装在同一个系统里。 可以通过 requirements 锁依赖了。  但，同期的其他编程语言社区分别出现了如下的包管理工具：]]></description>
</item><item>
    <title>NumPy CheatSheet</title>
    <link>http://twocucao.xyz/posts/20180203_numpycheatsheet/</link>
    <pubDate>Sat, 03 Feb 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20180203_numpycheatsheet/</guid>
    <description><![CDATA[0x00 前言 本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Numpy 相关语句。
主要包含：
Numpy 库 0x00 前言 本文为 Cheatsheet 类型文章，用于记录我在日常编程中经常使用的 Numpy 相关语句。
对于数据分析应用而言，最应该关注：
 用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。 常用的数组算法，如排序、唯一化、集合运算等。 高效的描述统计和数据聚合 / 摘要运算。 用于异构数据集的合并 / 连接运算的数据对齐和关系型数据运算。 将条件逻辑表述为数组表达式（而不是带有 if-else-if 分支的循环） 数据的分组运算（聚合、转换、函数应用等）。   学习 Numpy 本质上是为了更好的使用 Pandas
 0x01 ndarray 1.1 数据类型 1.2 创建 ndarray 1.3 数组和标量之间的运算 当我们把数组当做矢量的时候。
 两个大小相同的矢量将运算到元素级 矢量和标量将作用与每一个元素 不同大小的矢量之间的运算叫做广播  1.4 索引和切片 1.4.1 一般索引和一般切片 对于一维数组的话，如果没有显式 copy 则会修改原来的值。
切片语法与 Python 相近
1.4.2 切片型索引 a[:2,1:] a[2,1:] 1.4.3 布尔型索引 参考 pandas 语法]]></description>
</item><item>
    <title>Celery 快速入门指北</title>
    <link>http://twocucao.xyz/posts/20180220_celerycheatsheet/</link>
    <pubDate>Fri, 02 Feb 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20180220_celerycheatsheet/</guid>
    <description><![CDATA[0x00 前言 本文编写于 2018 年初，于 2019 四月进行修订，也是笔者对 Celery 的系统梳理。
在我的文章如何保证 Django 项目的数据一致性中，提到了这么一个解决超卖的方案。
 在 Redis 里面直接生成 200 个订单号 然后用户来一个取走一个订单号码 通过 Celery 削峰 排队走异步任务 最后通过数据表的 uniq 约束来防止下单超过 200 个。  https://zhuanlan.zhihu.com/p/57668068
有朋友和我讲，你这个方法是有问题的，走异步任务容易并发量太大，容易把数据库打爆。
其实是可以的，Celery 可以对 Worker 的 Task 限流 (ratelimit)。
0x01 Celery 为什么需要 Celery 在日常开发的时候，常常有一些『任务』需要处理。
 为了提升系统的响应速度，比如发送短信 / 发送邮箱，这类的『任务』可以走异步。 为了在某个时间执行耗时操作，比如统计用户的文章 / 点赞 / 活跃度。 为了削减峰值，比如秒杀系统的削峰走异步 为了业务代码解耦，比如当我在知乎上更新文章，可能就会触发『推荐系统』,『文章管理系统』,『用户通知系统』  不用 Celery 的话，其实上面的业务也是能做的。 比如 1 中，可以直接启一个线程来做。比如 2 完全可以 Crontab 做一个定时任务。
那为什么要用 Celery 呢？
 把目光聚焦在 Task 的分发上面。而非线程，Deamon 之类细节的处理。 方便，简单，易维护，高可用。 便于监控。 扩展性好。  基本上满足了你九成的需求。]]></description>
</item><item>
    <title>Python 中的数据压缩和存档</title>
    <link>http://twocucao.xyz/posts/20180123_pythoncompression/</link>
    <pubDate>Tue, 23 Jan 2018 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20180123_pythoncompression/</guid>
    <description><![CDATA[0x00 前言 在一次数据分析过程中，对方扔过来 40GB 的数据 &ndash; data.tar.gz .
我想着能不能直接用 pandas 直接读取这个文件呢？查找了一些资料，于是有了本文。
Python 中支持如下：
 数据压缩算法：zlib, gzip, bzip2 and lzma 存档格式：zip 以及 tar  0x01 压缩是怎么回事？ 0x02 zlib 与 gzip gzip 依赖于 zlib
# 读取压缩文件 import gzip with gzip.open('/home/joe/file.txt.gz', 'rb') as f: file_content = f.read() # 写入压缩文件 import gzip content = b&quot;Lots of content here&quot; with gzip.open('/home/joe/file.txt.gz', 'wb') as f: f.write(content) # 拷贝压缩文件 import gzip import shutil with open('/home/joe/file.txt', 'rb') as f_in: with gzip.]]></description>
</item><item>
    <title>记一次小机器的 Python 大数据分析</title>
    <link>http://twocucao.xyz/posts/20171207_anotewithsmallmachineandbigdata/</link>
    <pubDate>Thu, 07 Dec 2017 21:57:40 &#43;0800</pubDate>
    <author>作者</author>
    <guid>http://twocucao.xyz/posts/20171207_anotewithsmallmachineandbigdata/</guid>
    <description><![CDATA[0x00 前言 机缘巧合，最近公司突然要搞一波大量数据的分析。属于客流类的分析。
数据量级也还算不错，经过 gzip 压缩，接近 400 个 点位的 SQL 文件 (MySQL innoDB)，大小接近 100GB 左右，原始记录数据估测在 180 亿左右。
解压后&hellip;&hellip; 差不多一个 T 吧。
如果是人民币玩家，自然是直接购置几十台高配置机器，做个 mysql shard 或者直接上大数据全家桶比如 hadoop 和 hive 之类，让程序员去往死里折腾吧。
 嗯，然而对于我这种非人民币玩家，就要用单机硬扛。
 那就硬扛呗。
我手上的机器配置如下：
  局域网服务器 （ Ubuntu 16.04 LTS ）
 Xeon(R) CPU E3-1225 v5 @ 3.30GHz 16G 内存 1T 硬盘    苹果电脑 2016 年 15 寸 最高配
 1T 硬盘 i7 四核    0x01 准备数据阶段 用低配机器分析大数据的首要原则，就是不要分析大数据。]]></description>
</item></channel>
</rss>
